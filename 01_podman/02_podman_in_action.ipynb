{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a92153d-b928-469e-a2c9-6070ba2b3ebe",
   "metadata": {},
   "source": [
    "# PODMAN IN ACTION: Secure, rootless containers for Kubernetes, microservices, and more\n",
    "\n",
    "by Daniel Walsh\n",
    "\n",
    "- Publisher : Manning (February 7, 2023)\n",
    "- Language : English\n",
    "- Paperback : 312 pages\n",
    "- ISBN-10 : `1633439682`\n",
    "- ISBN-13 : `978-1633439689`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a6310-af4b-4844-85fc-a5484cc20add",
   "metadata": {},
   "source": [
    "# 1. <b>Podman: A next-generation container engine</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a7c14-8a60-4940-a6ae-506ab73cc3c4",
   "metadata": {},
   "source": [
    "## 1.1 About all these terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178cb16f-4021-4cbc-8c2a-0c9d435b7378",
   "metadata": {},
   "source": [
    "Before you go further, I think it is important to define the terminology that will be used throughout this book. In the container world, terms like container orchestrator, container engine, and container runtime are often used interchangeably, which commonly leads to confusion. The following list is a summary of what each of these terms refers to in the context of this text:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc611491-2134-4a78-a91d-e0eae3b73552",
   "metadata": {},
   "source": [
    "### Container orchestrators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51a9c4-1c40-4bdb-a078-b97e4d56f550",
   "metadata": {},
   "source": [
    "Software projects and products that orchestrate containers onto multiple different machines or nodes. These orchestrators communicate with **container engines** to run containers. The primary container orchestrator is **Kubernetes**, which was originally designed to talk to the Docker daemon container engine, but using Docker is becoming obsolete because Kubernetes primarily uses CRI-O or containerd as its container engine. **CRI-O** and **containerd** are purpose built for running orchestrated Kubernetes containers (CRI-O is covered in appendix A). Docker Swarm and Apache Mesos are other examples of container orchestrators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f896b6-4110-45fe-a24b-e1866e1a9383",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### CRI-O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98c7b1-319c-4572-a318-e42e170a5441",
   "metadata": {},
   "source": [
    "_ChatGPT:_  \n",
    "**CRI-O** is an open-source, lightweight container runtime for Kubernetes. It is designed to provide a stable, secure, and scalable environment for running containers in a Kubernetes cluster. CRI-O is optimized for use with Kubernetes and supports the **container runtime interface (CRI)** standard, allowing it to seamlessly integrate with the Kubernetes ecosystem. It is an alternative to other container runtimes like Docker and is specifically built to meet the requirements of Kubernetes container orchestration. CRI-O focuses on minimalism, performance, and security, making it a popular choice for running containers in production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40baca15-999a-4065-bc4b-8f24357b0b4f",
   "metadata": {},
   "source": [
    "#### Container Runtime Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c9c7c-1b6d-4e8d-9f07-62b007af9cce",
   "metadata": {},
   "source": [
    "_ChatGPT:_  \n",
    "**Container Runtime Interface (CRI)** is an interface between \n",
    "- container runtimes and \n",
    "- container management systems (e.g. Kubernetes). \n",
    "\n",
    "It allows container runtimes to be pluggable and allows different container runtimes to be used with the same container management system. This flexibility enables organizations to choose the best container runtime for their needs and easily switch between runtimes as necessary. CRI defines a set of APIs that container runtimes must implement in order to be compatible with container orchestration systems like Kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8bf89e-dd2b-41bb-ae51-55d4fa9ec6a8",
   "metadata": {},
   "source": [
    "#### Containerd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffca3f3-72e4-45b2-b548-16583ac54e28",
   "metadata": {},
   "source": [
    "_ChatGPT:_  \n",
    "**Containerd** is an open-source container runtime that provides a runtime environment for running containerized applications. It is designed to be lightweight, portable, and platform agnostic, making it suitable for use in various environments, including cloud, on-premises, and edge computing.\n",
    "\n",
    "Containerd is used as the container runtime within Docker, as well as by other container orchestration platforms such as Kubernetes. It provides core container runtime functionalities, such as image distribution, container execution, and storage management. Containerd is designed with a modular architecture, allowing it to be integrated into different container management systems and to support various container formats.\n",
    "\n",
    "In summary, Containerd is a fundamental component in the container ecosystem, providing essential container runtime functionalities while enabling interoperability and versatility across different container platforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b161bc-80f1-4ad6-9e75-b070cdfea241",
   "metadata": {},
   "source": [
    "#### Containerd vs CRI-O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a6b583-7e6f-46c2-9966-ee85babd5de6",
   "metadata": {},
   "source": [
    "- Architecture:\n",
    "    - **Containerd:** Containerd is a core container runtime that provides a runtime environment for running containerized applications. It is designed to be lightweight and platform-agnostic, focusing on managing the container lifecycle, including \n",
    "        - image distribution, \n",
    "        - container execution, and \n",
    "        - storage management.  \n",
    "        Containerd can be used as a building block for higher-level container orchestration systems.\n",
    "    - **CRI-O:** CRI-O, on the other hand, is specifically designed for Kubernetes container runtimes. It implements the Container Runtime Interface (CRI) and focuses on creating an optimized runtime for Kubernetes pods and containers. CRI-O is specifically tailored for integrating with Kubernetes and adheres to the Kubernetes container runtime standards.<br><br>\n",
    "- Integration with Kubernetes:\n",
    "    - **Containerd:** Containerd can be integrated with Kubernetes as a container runtime, providing the core functionality required for running containers within a Kubernetes cluster.\n",
    "    - **CRI-O:** CRI-O is designed as a lightweight and optimized runtime for Kubernetes. It directly implements the CRI, allowing Kubernetes to use CRI-O as a container runtime without the need for additional layers.<br><br>\n",
    "- Feature Set:\n",
    "    - **Containerd:** As a fundamental container runtime, Containerd provides core container lifecycle management functionalities, including image distribution, container execution, and storage management. It focuses on being modular and platform-agnostic, suitable for use in various container management systems.\n",
    "    - **CRI-O:** CRI-O is specifically tailored to address the requirements of Kubernetes. It is designed to efficiently handle Kubernetes pod and container management, adhering closely to the Kubernetes container runtime standards while providing essential container runtime features.\n",
    "\n",
    "In summary, Containerd is a general-purpose, lightweight container runtime suitable for various container management systems, while CRI-O is specifically optimized for Kubernetes, providing a streamlined and Kubernetes-focused runtime environment. Both container runtimes have unique strengths based on their intended use cases and integrations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26792306-3b51-463a-b2e1-4b99ffbb5e05",
   "metadata": {},
   "source": [
    "### Container engines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d4d9c-b004-4746-ac13-0c6750c21b4f",
   "metadata": {},
   "source": [
    "Primarily used for configuring containerized applications to run _on a single local node_. They can be launched directly by users, administrators, and developers. They can also be launched out of systemd unit files at boot as well as launched by **container orchestrators** like Kubernetes. As previously mentioned, `CRI-O` and `containerd` are container engines (_runtimes_ - VR) used by Kubernetes to manage containers locally. They really are not intended to be used directly by users. `Docker` and `Podman` are the primary **container engines** used by users to develop, manage, and run containerized applications on a single machine. Podman is seldom used to launch containers for Kubernetes; therefore, Kubernetes is not generally covered in this book. `Buildah` is another container engine, although it is only used for building container images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800a4ff-c9f4-47b5-bb75-413dfd5c2b28",
   "metadata": {},
   "source": [
    "### Open Container Initiative (OCI) container runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d500c7-abf1-4ba3-a612-e9e96cc7e01d",
   "metadata": {},
   "source": [
    "Configure different parts of the Linux kernel and then, finally, launch the containerized application. The two most commonly used container runtimes are `runc` and `crun`. `Kata` and `gVisor` are other examples of container runtimes. See appendix B to understand the differences between the OCI container runtimes.\n",
    "\n",
    "_ChatGPT:_  \n",
    "`runc` is not a full-fledged container runtime, but a lightweight command-line tool for spawning and running containers. It is a low-level tool used by higher-level container runtimes (like CRI-O and containerd) to create and run containers based on OCI (Open Container Initiative) specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49906c-a681-4234-ba4a-4d8e4fc23f4d",
   "metadata": {},
   "source": [
    "### Podman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b9e164-7d12-4955-9849-31f31c155549",
   "metadata": {},
   "source": [
    "**Podman** is short for _Pod Manager_. A **pod**, a concept popularized by the Kubernetes project, is one or more containers sharing the same namespaces and cgroups (resource constraints). Pods are covered in greater depth in **chapter 4**. Podman runs individual containers as well as pods. The Podman logo is a group of Selkies, the Irish concept of a mermaid. Groups of Selkies are called pods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ede181-ddb1-49be-965d-4a1a6e01fb14",
   "metadata": {},
   "source": [
    "![](../data/images/podman-logo-2009470014.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd48032-64fc-4f1d-9119-d701b0b89001",
   "metadata": {},
   "source": [
    "![](../data/images/fgfff54fdgdg.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c00ab0b-82b4-403c-96b6-2ae820ff1e70",
   "metadata": {},
   "source": [
    "![](../data/images/048c64b76bdb2b40157dc81f6d246e96.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e27fea-ac55-48b4-9967-220b5c642822",
   "metadata": {},
   "source": [
    "## 1.2 A brief overview of containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e0fd8-2fa9-4172-a452-24142bf449f3",
   "metadata": {},
   "source": [
    "### Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c361e0e-8e2a-4a16-8168-ed40c4fce112",
   "metadata": {},
   "source": [
    "**Containers** are groups of _processes_ running on a Linux system that are isolated from each other. \n",
    "\n",
    "Containers make sure one group of processes does not interfere with other processes on the system. Rogue processes can’t dominate system resources, which might prevent other processes from performing their task. Hostile containers are also prevented from attacking other containers, stealing data, or causing denial of service attacks. \n",
    "\n",
    "> A final goal of containers is allowing applications to be installed with their own versions of shared libraries that do not conflict with applications requiring different versions of the same libraries. \n",
    "\n",
    "Instead they allow applications to live in a virtualized environment, giving the impression that they own the entire system.\n",
    "\n",
    "Containers are isolated via the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f87325-bf53-4fe1-a8e7-c578e615efd7",
   "metadata": {},
   "source": [
    "#### Resource constraints (cgroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3882dd-4d66-4794-a497-b0c182337e40",
   "metadata": {},
   "source": [
    "The [cgroup man page](https://man7.org/linux/man-pages/man7/cgroups.7.html) defines cgroups as the following: \n",
    "\n",
    "_“Control groups, usually referred to as cgroups, are a Linux kernel feature which allow processes to be organized into hierarchical groups whose usage of various types of resources can then be limited and monitored.”_\n",
    "\n",
    "Examples of resources controlled by cgroups include the following:\n",
    "\n",
    "- The amount of **memory** a group of processes can use,\n",
    "- The amount of **CPU** processes can use,\n",
    "- The amount of **network** resources a process can use.\n",
    "\n",
    "The basic idea of cgroups is \n",
    "\n",
    "> preventing one group of processes from dominating certain system resources in such a way that another group of processes can’t make progress on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "315e46df-b93b-4e67-9a96-9e1de2bfceeb",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-15T14:48:39.442109Z",
     "iopub.status.busy": "2024-01-15T14:48:39.439385Z",
     "iopub.status.idle": "2024-01-15T14:48:40.395079Z",
     "shell.execute_reply": "2024-01-15T14:48:40.393043Z",
     "shell.execute_reply.started": "2024-01-15T14:48:39.441881Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cgroups(7)             Miscellaneous Information Manual             cgroups(7)\n",
      "\n",
      "NAME\n",
      "       cgroups - Linux control groups\n",
      "\n",
      "DESCRIPTION\n",
      "       Control groups, usually referred to as cgroups, are a Linux kernel fea‐\n",
      "       ture which allow processes to be  organized  into  hierarchical  groups\n",
      "       whose usage of various types of resources can then be limited and moni‐\n",
      "       tored.  The kernel's cgroup interface is  provided  through  a  pseudo-\n",
      "       filesystem called cgroupfs.  Grouping is implemented in the core cgroup\n",
      "       kernel code, while resource tracking and limits are  implemented  in  a\n",
      "       set of per-resource-type subsystems (memory, CPU, and so on).\n",
      "\n",
      "   Terminology\n",
      "       A cgroup is a collection of processes that are bound to a set of limits\n",
      "       or parameters defined via the cgroup filesystem.\n",
      "\n",
      "       A subsystem is a kernel component that modifies  the  behavior  of  the\n",
      "       processes  in a cgroup.  Various subsystems have been implemented, mak‐\n",
      "       ing it possible to do things such as limiting the amount  of  CPU  time\n",
      "       and memory available to a cgroup, accounting for the CPU time used by a\n",
      "       cgroup, and freezing and resuming  execution  of  the  processes  in  a\n",
      "       cgroup.   Subsystems  are  sometimes also known as resource controllers\n",
      "       (or simply, controllers).\n",
      "\n",
      "       The cgroups for a controller are arranged in a hierarchy.  This hierar‐\n",
      "       chy  is  defined  by  creating,  removing,  and renaming subdirectories\n",
      "       within the cgroup filesystem.  At each  level  of  the  hierarchy,  at‐\n",
      "       tributes  (e.g.,  limits) can be defined.  The limits, control, and ac‐\n",
      "       counting provided by cgroups generally have effect throughout the  sub‐\n",
      "       hierarchy  underneath  the  cgroup  where  the  attributes are defined.\n",
      "       Thus, for example, the limits placed on a cgroup at a higher  level  in\n",
      "       the hierarchy cannot be exceeded by descendant cgroups.\n",
      "\n",
      "   Cgroups version 1 and version 2\n",
      "       The  initial release of the cgroups implementation was in Linux 2.6.24.\n",
      "       Over time, various cgroup controllers have been added to allow the man‐\n",
      "       agement  of  various  types  of resources.  However, the development of\n",
      "       these controllers was largely uncoordinated, with the result that  many\n",
      "       inconsistencies  arose between controllers and management of the cgroup\n",
      "       hierarchies became rather complex.  A longer description of these prob‐\n",
      "       lems   can  be  found  in  the  kernel  source  file  Documentation/ad‐\n",
      "       min-guide/cgroup-v2.rst (or Documentation/cgroup-v2.txt in  Linux  4.17\n",
      "       and earlier).\n",
      "\n",
      "       Because  of  the  problems  with  the  initial  cgroups  implementation\n",
      "       (cgroups version 1), starting in Linux 3.10, work began on a  new,  or‐\n",
      "       thogonal implementation to remedy these problems.  Initially marked ex‐\n",
      "       perimental, and hidden behind the -o __DEVEL__sane_behavior  mount  op‐\n",
      "       tion,  the new version (cgroups version 2) was eventually made official\n",
      "       with the release of Linux 4.5.  Differences between  the  two  versions\n",
      "       are  described  in  the  text  below.   The  file cgroup.sane_behavior,\n",
      "       present in cgroups v1, is a relic of this mount option.  The  file  al‐\n",
      "       ways reports \"0\" and is only retained for backward compatibility.\n",
      "\n",
      "       Although  cgroups  v2  is intended as a replacement for cgroups v1, the\n",
      "       older system continues to exist (and for compatibility reasons  is  un‐\n",
      "       likely  to be removed).  Currently, cgroups v2 implements only a subset\n",
      "       of the controllers available in cgroups v1.  The two systems are imple‐\n",
      "       mented so that both v1 controllers and v2 controllers can be mounted on\n",
      "       the same system.  Thus, for example, it is possible to use  those  con‐\n",
      "       trollers that are supported under version 2, while also using version 1\n",
      "       controllers where version 2 does not  yet  support  those  controllers.\n",
      "       The  only restriction here is that a controller can't be simultaneously\n",
      "       employed in both a cgroups v1 hierarchy and in the cgroups  v2  hierar‐\n",
      "       chy.\n",
      "\n",
      "CGROUPS VERSION 1\n",
      "       Under  cgroups  v1,  each  controller may be mounted against a separate\n",
      "       cgroup filesystem that provides its own  hierarchical  organization  of\n",
      "       the  processes  on the system.  It is also possible to comount multiple\n",
      "       (or even all) cgroups v1 controllers against the same  cgroup  filesys‐\n",
      "       tem,  meaning that the comounted controllers manage the same hierarchi‐\n",
      "       cal organization of processes.\n",
      "\n",
      "       For each mounted hierarchy, the  directory  tree  mirrors  the  control\n",
      "       group  hierarchy.   Each  control  group is represented by a directory,\n",
      "       with each of its child control cgroups represented as  a  child  direc‐\n",
      "       tory.   For  instance,  /user/joe/1.session  represents  control  group\n",
      "       1.session, which is a child of cgroup joe, which is a child  of  /user.\n",
      "       Under  each  cgroup  directory  is  a set of files which can be read or\n",
      "       written to, reflecting resource limits and a few general cgroup proper‐\n",
      "       ties.\n",
      "\n",
      "   Tasks (threads) versus processes\n",
      "       In  cgroups v1, a distinction is drawn between processes and tasks.  In\n",
      "       this view, a process can  consist  of  multiple  tasks  (more  commonly\n",
      "       called  threads,  from a user-space perspective, and called such in the\n",
      "       remainder of this man page).  In cgroups v1, it is possible to indepen‐\n",
      "       dently manipulate the cgroup memberships of the threads in a process.\n",
      "\n",
      "       The cgroups v1 ability to split threads across different cgroups caused\n",
      "       problems in some cases.  For example, it made no sense for  the  memory\n",
      "       controller,  since  all  of the threads of a process share a single ad‐\n",
      "       dress space.  Because of these problems, the ability  to  independently\n",
      "       manipulate  the  cgroup memberships of the threads in a process was re‐\n",
      "       moved in the initial cgroups v2 implementation,  and  subsequently  re‐\n",
      "       stored  in a more limited form (see the discussion of \"thread mode\" be‐\n",
      "       low).\n",
      "\n",
      "   Mounting v1 controllers\n",
      "       The use of cgroups requires a kernel built with the  CONFIG_CGROUP  op‐\n",
      "       tion.   In  addition, each of the v1 controllers has an associated con‐\n",
      "       figuration option that must be set in order to employ that controller.\n",
      "\n",
      "       In order to use a v1 controller, it must be mounted  against  a  cgroup\n",
      "       filesystem.   The  usual  place  for  such  mounts  is under a tmpfs(5)\n",
      "       filesystem mounted at /sys/fs/cgroup.  Thus, one might  mount  the  cpu\n",
      "       controller as follows:\n",
      "\n",
      "           mount -t cgroup -o cpu none /sys/fs/cgroup/cpu\n",
      "\n",
      "       It is possible to comount multiple controllers against the same hierar‐\n",
      "       chy.  For example, here the cpu and cpuacct controllers  are  comounted\n",
      "       against a single hierarchy:\n",
      "\n",
      "           mount -t cgroup -o cpu,cpuacct none /sys/fs/cgroup/cpu,cpuacct\n",
      "\n",
      "       Comounting  controllers  has  the  effect that a process is in the same\n",
      "       cgroup for all of the comounted controllers.  Separately mounting  con‐\n",
      "       trollers  allows  a  process  to  be in cgroup /foo1 for one controller\n",
      "       while being in /foo2/foo3 for another.\n",
      "\n",
      "       It is possible to comount all v1 controllers against the  same  hierar‐\n",
      "       chy:\n",
      "\n",
      "           mount -t cgroup -o all cgroup /sys/fs/cgroup\n",
      "\n",
      "       (One  can  achieve  the same result by omitting -o all, since it is the\n",
      "       default if no controllers are explicitly specified.)\n",
      "\n",
      "       It is not possible to mount the same controller against multiple cgroup\n",
      "       hierarchies.  For example, it is not possible to mount both the cpu and\n",
      "       cpuacct controllers against one hierarchy, and to mount  the  cpu  con‐\n",
      "       troller alone against another hierarchy.  It is possible to create mul‐\n",
      "       tiple mount with exactly the same set of comounted  controllers.   How‐\n",
      "       ever,  in this case all that results is multiple mount points providing\n",
      "       a view of the same hierarchy.\n",
      "\n",
      "       Note that on many systems, the v1 controllers are automatically mounted\n",
      "       under  /sys/fs/cgroup;  in particular, systemd(1) automatically creates\n",
      "       such mounts.\n",
      "\n",
      "   Unmounting v1 controllers\n",
      "       A mounted cgroup filesystem can be unmounted using the  umount(8)  com‐\n",
      "       mand, as in the following example:\n",
      "\n",
      "           umount /sys/fs/cgroup/pids\n",
      "\n",
      "       But note well: a cgroup filesystem is unmounted only if it is not busy,\n",
      "       that is, it has no child cgroups.  If this is not the  case,  then  the\n",
      "       only  effect of the umount(8) is to make the mount invisible.  Thus, to\n",
      "       ensure that the mount is really removed,  one  must  first  remove  all\n",
      "       child  cgroups,  which  in  turn can be done only after all member pro‐\n",
      "       cesses have been moved from those cgroups to the root cgroup.\n",
      "\n",
      "   Cgroups version 1 controllers\n",
      "       Each of the cgroups version 1 controllers is governed by a kernel  con‐\n",
      "       figuration  option  (listed  below).  Additionally, the availability of\n",
      "       the cgroups feature is governed by the CONFIG_CGROUPS kernel configura‐\n",
      "       tion option.\n",
      "\n",
      "       cpu (since Linux 2.6.24; CONFIG_CGROUP_SCHED)\n",
      "              Cgroups  can be guaranteed a minimum number of \"CPU shares\" when\n",
      "              a system is busy.  This does not limit a cgroup's CPU  usage  if\n",
      "              the  CPUs are not busy.  For further information, see Documenta‐\n",
      "              tion/scheduler/sched-design-CFS.rst   (or   Documentation/sched‐\n",
      "              uler/sched-design-CFS.txt in Linux 5.2 and earlier).\n",
      "\n",
      "              In Linux 3.2, this controller was extended to provide CPU \"band‐\n",
      "              width\"  control.   If  the  kernel  is  configured   with   CON‐\n",
      "              FIG_CFS_BANDWIDTH,  then  within each scheduling period (defined\n",
      "              via a file in the cgroup directory), it is possible to define an\n",
      "              upper  limit  on  the  CPU  time allocated to the processes in a\n",
      "              cgroup.  This upper limit applies even if there is no other com‐\n",
      "              petition  for  the CPU.  Further information can be found in the\n",
      "              kernel  source  file  Documentation/scheduler/sched-bwc.rst  (or\n",
      "              Documentation/scheduler/sched-bwc.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       cpuacct (since Linux 2.6.24; CONFIG_CGROUP_CPUACCT)\n",
      "              This provides accounting for CPU usage by groups of processes.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/cpuacct.rst    (or    Documenta‐\n",
      "              tion/cgroup-v1/cpuacct.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       cpuset (since Linux 2.6.24; CONFIG_CPUSETS)\n",
      "              This  cgroup  can be used to bind the processes in a cgroup to a\n",
      "              specified set of CPUs and NUMA nodes.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/cpusets.rst    (or    Documenta‐\n",
      "              tion/cgroup-v1/cpusets.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       memory (since Linux 2.6.25; CONFIG_MEMCG)\n",
      "              The memory controller supports reporting and limiting of process\n",
      "              memory, kernel memory, and swap used by cgroups.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/memory.rst    (or     Documenta‐\n",
      "              tion/cgroup-v1/memory.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       devices (since Linux 2.6.26; CONFIG_CGROUP_DEVICE)\n",
      "              This supports controlling which processes may create (mknod) de‐\n",
      "              vices as well as open them for reading or writing.  The policies\n",
      "              may  be  specified  as allow-lists and deny-lists.  Hierarchy is\n",
      "              enforced, so new rules must not violate existing rules  for  the\n",
      "              target or ancestor cgroups.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/devices.rst    (or    Documenta‐\n",
      "              tion/cgroup-v1/devices.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       freezer (since Linux 2.6.28; CONFIG_CGROUP_FREEZER)\n",
      "              The  freezer  cgroup  can  suspend and restore (resume) all pro‐\n",
      "              cesses in a cgroup.  Freezing a cgroup /A also causes its  chil‐\n",
      "              dren, for example, processes in /A/B, to be frozen.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/freezer-subsystem.rst (or  Docu‐\n",
      "              mentation/cgroup-v1/freezer-subsystem.txt  in Linux 5.2 and ear‐\n",
      "              lier).\n",
      "\n",
      "       net_cls (since Linux 2.6.29; CONFIG_CGROUP_NET_CLASSID)\n",
      "              This places a classid, specified  for  the  cgroup,  on  network\n",
      "              packets created by a cgroup.  These classids can then be used in\n",
      "              firewall rules, as well as used to shape  traffic  using  tc(8).\n",
      "              This  applies only to packets leaving the cgroup, not to traffic\n",
      "              arriving at the cgroup.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/net_cls.rst    (or    Documenta‐\n",
      "              tion/cgroup-v1/net_cls.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       blkio (since Linux 2.6.33; CONFIG_BLK_CGROUP)\n",
      "              The blkio cgroup controls and limits access to  specified  block\n",
      "              devices by applying IO control in the form of throttling and up‐\n",
      "              per limits against leaf nodes  and  intermediate  nodes  in  the\n",
      "              storage hierarchy.\n",
      "\n",
      "              Two  policies are available.  The first is a proportional-weight\n",
      "              time-based division of disk implemented with CFQ.   This  is  in\n",
      "              effect  for  leaf  nodes  using CFQ.  The second is a throttling\n",
      "              policy which specifies upper I/O rate limits on a device.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/blkio-controller.rst  (or  Docu‐\n",
      "              mentation/cgroup-v1/blkio-controller.txt in Linux 5.2  and  ear‐\n",
      "              lier).\n",
      "\n",
      "       perf_event (since Linux 2.6.39; CONFIG_CGROUP_PERF)\n",
      "              This  controller  allows perf monitoring of the set of processes\n",
      "              grouped in a cgroup.\n",
      "\n",
      "              Further information can be found in the kernel source files\n",
      "\n",
      "       net_prio (since Linux 3.3; CONFIG_CGROUP_NET_PRIO)\n",
      "              This allows priorities to be specified, per  network  interface,\n",
      "              for cgroups.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/net_prio.rst   (or    Documenta‐\n",
      "              tion/cgroup-v1/net_prio.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       hugetlb (since Linux 3.5; CONFIG_CGROUP_HUGETLB)\n",
      "              This supports limiting the use of huge pages by cgroups.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/hugetlb.rst    (or    Documenta‐\n",
      "              tion/cgroup-v1/hugetlb.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       pids (since Linux 4.3; CONFIG_CGROUP_PIDS)\n",
      "              This  controller permits limiting the number of process that may\n",
      "              be created in a cgroup (and its descendants).\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/pids.rst      (or     Documenta‐\n",
      "              tion/cgroup-v1/pids.txt in Linux 5.2 and earlier).\n",
      "\n",
      "       rdma (since Linux 4.11; CONFIG_CGROUP_RDMA)\n",
      "              The RDMA controller permits limiting the use of RDMA/IB-specific\n",
      "              resources per cgroup.\n",
      "\n",
      "              Further information can be found in the kernel source file Docu‐\n",
      "              mentation/admin-guide/cgroup-v1/rdma.rst     (or      Documenta‐\n",
      "              tion/cgroup-v1/rdma.txt in Linux 5.2 and earlier).\n",
      "\n",
      "   Creating cgroups and moving processes\n",
      "       A cgroup filesystem initially contains a single root cgroup, '/', which\n",
      "       all processes belong to.  A new cgroup is created by creating a  direc‐\n",
      "       tory in the cgroup filesystem:\n",
      "\n",
      "           mkdir /sys/fs/cgroup/cpu/cg1\n",
      "\n",
      "       This creates a new empty cgroup.\n",
      "\n",
      "       A  process  may  be  moved  to  this cgroup by writing its PID into the\n",
      "       cgroup's cgroup.procs file:\n",
      "\n",
      "           echo $$ > /sys/fs/cgroup/cpu/cg1/cgroup.procs\n",
      "\n",
      "       Only one PID at a time should be written to this file.\n",
      "\n",
      "       Writing the value 0 to a cgroup.procs file causes the  writing  process\n",
      "       to be moved to the corresponding cgroup.\n",
      "\n",
      "       When  writing  a  PID into the cgroup.procs, all threads in the process\n",
      "       are moved into the new cgroup at once.\n",
      "\n",
      "       Within a hierarchy, a process can be a member of  exactly  one  cgroup.\n",
      "       Writing a process's PID to a cgroup.procs file automatically removes it\n",
      "       from the cgroup of which it was previously a member.\n",
      "\n",
      "       The cgroup.procs file can be read to obtain a  list  of  the  processes\n",
      "       that are members of a cgroup.  The returned list of PIDs is not guaran‐\n",
      "       teed to be in order.  Nor is it guaranteed to be  free  of  duplicates.\n",
      "       (For example, a PID may be recycled while reading from the list.)\n",
      "\n",
      "       In  cgroups  v1, an individual thread can be moved to another cgroup by\n",
      "       writing its thread ID (i.e., the kernel thread ID returned by  clone(2)\n",
      "       and  gettid(2)) to the tasks file in a cgroup directory.  This file can\n",
      "       be read to discover the set of threads that are members of the cgroup.\n",
      "\n",
      "   Removing cgroups\n",
      "       To remove a cgroup, it must first have no child cgroups and contain  no\n",
      "       (nonzombie) processes.  So long as that is the case, one can simply re‐\n",
      "       move the corresponding directory pathname.  Note that files in a cgroup\n",
      "       directory cannot and need not be removed.\n",
      "\n",
      "   Cgroups v1 release notification\n",
      "       Two  files can be used to determine whether the kernel provides notifi‐\n",
      "       cations when a cgroup becomes empty.  A  cgroup  is  considered  to  be\n",
      "       empty when it contains no child cgroups and no member processes.\n",
      "\n",
      "       A  special  file  in  the  root directory of each cgroup hierarchy, re‐\n",
      "       lease_agent, can be used to register the pathname of a program that may\n",
      "       be  invoked when a cgroup in the hierarchy becomes empty.  The pathname\n",
      "       of the newly empty cgroup (relative to the cgroup mount point) is  pro‐\n",
      "       vided  as the sole command-line argument when the release_agent program\n",
      "       is invoked.  The release_agent program might remove the  cgroup  direc‐\n",
      "       tory, or perhaps repopulate it with a process.\n",
      "\n",
      "       The  default  value of the release_agent file is empty, meaning that no\n",
      "       release agent is invoked.\n",
      "\n",
      "       The content of the release_agent file can also be specified via a mount\n",
      "       option when the cgroup filesystem is mounted:\n",
      "\n",
      "           mount -o release_agent=pathname ...\n",
      "\n",
      "       Whether  or  not the release_agent program is invoked when a particular\n",
      "       cgroup becomes empty is determined by the value  in  the  notify_on_re‐\n",
      "       lease  file  in  the corresponding cgroup directory.  If this file con‐\n",
      "       tains the value 0, then the release_agent program is not  invoked.   If\n",
      "       it contains the value 1, the release_agent program is invoked.  The de‐\n",
      "       fault value for this file in the root cgroup is 0.  At the time when  a\n",
      "       new  cgroup  is  created,  the value in this file is inherited from the\n",
      "       corresponding file in the parent cgroup.\n",
      "\n",
      "   Cgroup v1 named hierarchies\n",
      "       In cgroups v1, it is possible to mount a cgroup hierarchy that  has  no\n",
      "       attached controllers:\n",
      "\n",
      "           mount -t cgroup -o none,name=somename none /some/mount/point\n",
      "\n",
      "       Multiple  instances  of such hierarchies can be mounted; each hierarchy\n",
      "       must have a unique name.  The only purpose of such  hierarchies  is  to\n",
      "       track  processes.   (See the discussion of release notification below.)\n",
      "       An example of this is the name=systemd cgroup hierarchy that is used by\n",
      "       systemd(1) to track services and user sessions.\n",
      "\n",
      "       Since  Linux 5.0, the cgroup_no_v1 kernel boot option (described below)\n",
      "       can be used to disable  cgroup  v1  named  hierarchies,  by  specifying\n",
      "       cgroup_no_v1=named.\n",
      "\n",
      "CGROUPS VERSION 2\n",
      "       In cgroups v2, all mounted controllers reside in a single unified hier‐\n",
      "       archy.  While (different) controllers may be simultaneously mounted un‐\n",
      "       der  the  v1  and  v2 hierarchies, it is not possible to mount the same\n",
      "       controller simultaneously under both the v1 and the v2 hierarchies.\n",
      "\n",
      "       The new behaviors in cgroups v2 are summarized here, and in some  cases\n",
      "       elaborated in the following subsections.\n",
      "\n",
      "       •  Cgroups  v2  provides  a  unified  hierarchy  against which all con‐\n",
      "          trollers are mounted.\n",
      "\n",
      "       •  \"Internal\" processes are not permitted.  With the exception  of  the\n",
      "          root  cgroup,  processes may reside only in leaf nodes (cgroups that\n",
      "          do not themselves contain child cgroups).  The details are  somewhat\n",
      "          more subtle than this, and are described below.\n",
      "\n",
      "       •  Active  cgroups  must  be specified via the files cgroup.controllers\n",
      "          and cgroup.subtree_control.\n",
      "\n",
      "       •  The   tasks   file   has   been   removed.    In    addition,    the\n",
      "          cgroup.clone_children file that is employed by the cpuset controller\n",
      "          has been removed.\n",
      "\n",
      "       •  An improved mechanism for notification of empty cgroups is  provided\n",
      "          by the cgroup.events file.\n",
      "\n",
      "       For  more changes, see the Documentation/admin-guide/cgroup-v2.rst file\n",
      "       in the kernel source (or Documentation/cgroup-v2.txt in Linux 4.17  and\n",
      "       earlier).\n",
      "\n",
      "       Some of the new behaviors listed above saw subsequent modification with\n",
      "       the addition in Linux 4.14 of \"thread mode\" (described below).\n",
      "\n",
      "   Cgroups v2 unified hierarchy\n",
      "       In cgroups v1, the ability to mount different controllers against  dif‐\n",
      "       ferent hierarchies was intended to allow great flexibility for applica‐\n",
      "       tion design.  In practice, though, the flexibility  turned  out  to  be\n",
      "       less  useful than expected, and in many cases added complexity.  There‐\n",
      "       fore, in cgroups v2, all available controllers are  mounted  against  a\n",
      "       single hierarchy.  The available controllers are automatically mounted,\n",
      "       meaning that it is not necessary (or  possible)  to  specify  the  con‐\n",
      "       trollers when mounting the cgroup v2 filesystem using a command such as\n",
      "       the following:\n",
      "\n",
      "           mount -t cgroup2 none /mnt/cgroup2\n",
      "\n",
      "       A cgroup v2 controller is available only if it is not currently in  use\n",
      "       via  a  mount against a cgroup v1 hierarchy.  Or, to put things another\n",
      "       way, it is not possible to employ the same controller against both a v1\n",
      "       hierarchy and the unified v2 hierarchy.  This means that it may be nec‐\n",
      "       essary first to unmount a v1 controller  (as  described  above)  before\n",
      "       that  controller  is available in v2.  Since systemd(1) makes heavy use\n",
      "       of some v1 controllers by default, it can in some cases be  simpler  to\n",
      "       boot  the  system  with  selected v1 controllers disabled.  To do this,\n",
      "       specify the cgroup_no_v1=list option on the kernel boot  command  line;\n",
      "       list  is a comma-separated list of the names of the controllers to dis‐\n",
      "       able, or the word all to disable all v1 controllers.   (This  situation\n",
      "       is correctly handled by systemd(1), which falls back to operating with‐\n",
      "       out the specified controllers.)\n",
      "\n",
      "       Note that on many modern systems, systemd(1) automatically  mounts  the\n",
      "       cgroup2 filesystem at /sys/fs/cgroup/unified during the boot process.\n",
      "\n",
      "   Cgroups v2 mount options\n",
      "       The  following  options  (mount  -o) can be specified when mounting the\n",
      "       group v2 filesystem:\n",
      "\n",
      "       nsdelegate (since Linux 4.15)\n",
      "              Treat cgroup namespaces as delegation boundaries.  For  details,\n",
      "              see below.\n",
      "\n",
      "       memory_localevents (since Linux 5.2)\n",
      "              The memory.events should show statistics only for the cgroup it‐\n",
      "              self, and not for any descendant cgroups.  This was the behavior\n",
      "              before  Linux  5.2.  Starting in Linux 5.2, the default behavior\n",
      "              is  to  include  statistics  for  descendant  cgroups  in   mem‐\n",
      "              ory.events,  and  this mount option can be used to revert to the\n",
      "              legacy behavior.  This option is system wide and can be  set  on\n",
      "              mount  or  modified  through remount only from the initial mount\n",
      "              namespace; it is silently ignored in noninitial namespaces.\n",
      "\n",
      "   Cgroups v2 controllers\n",
      "       The following controllers, documented in the kernel source  file  Docu‐\n",
      "       mentation/admin-guide/cgroup-v2.rst  (or Documentation/cgroup-v2.txt in\n",
      "       Linux 4.17 and earlier), are supported in cgroups version 2:\n",
      "\n",
      "       cpu (since Linux 4.15)\n",
      "              This is the successor to the version  1  cpu  and  cpuacct  con‐\n",
      "              trollers.\n",
      "\n",
      "       cpuset (since Linux 5.0)\n",
      "              This is the successor of the version 1 cpuset controller.\n",
      "\n",
      "       freezer (since Linux 5.2)\n",
      "              This is the successor of the version 1 freezer controller.\n",
      "\n",
      "       hugetlb (since Linux 5.6)\n",
      "              This is the successor of the version 1 hugetlb controller.\n",
      "\n",
      "       io (since Linux 4.5)\n",
      "              This is the successor of the version 1 blkio controller.\n",
      "\n",
      "       memory (since Linux 4.5)\n",
      "              This is the successor of the version 1 memory controller.\n",
      "\n",
      "       perf_event (since Linux 4.11)\n",
      "              This is the same as the version 1 perf_event controller.\n",
      "\n",
      "       pids (since Linux 4.5)\n",
      "              This is the same as the version 1 pids controller.\n",
      "\n",
      "       rdma (since Linux 4.11)\n",
      "              This is the same as the version 1 rdma controller.\n",
      "\n",
      "       There  is  no direct equivalent of the net_cls and net_prio controllers\n",
      "       from cgroups version 1.  Instead, support has been added to iptables(8)\n",
      "       to  allow  eBPF  filters that hook on cgroup v2 pathnames to make deci‐\n",
      "       sions about network traffic on a per-cgroup basis.\n",
      "\n",
      "       The v2 devices controller provides no interface files; instead,  device\n",
      "       control  is gated by attaching an eBPF (BPF_CGROUP_DEVICE) program to a\n",
      "       v2 cgroup.\n",
      "\n",
      "   Cgroups v2 subtree control\n",
      "       Each cgroup in the v2 hierarchy contains the following two files:\n",
      "\n",
      "       cgroup.controllers\n",
      "              This read-only file exposes a list of the controllers  that  are\n",
      "              available  in  this cgroup.  The contents of this file match the\n",
      "              contents  of  the  cgroup.subtree_control  file  in  the  parent\n",
      "              cgroup.\n",
      "\n",
      "       cgroup.subtree_control\n",
      "              This  is  a list of controllers that are active (enabled) in the\n",
      "              cgroup.  The set of controllers in this file is a subset of  the\n",
      "              set in the cgroup.controllers of this cgroup.  The set of active\n",
      "              controllers is modified by writing strings to this file contain‐\n",
      "              ing  space-delimited  controller names, each preceded by '+' (to\n",
      "              enable a controller) or '-' (to disable a controller), as in the\n",
      "              following example:\n",
      "\n",
      "                  echo '+pids -memory' > x/y/cgroup.subtree_control\n",
      "\n",
      "              An  attempt  to  enable  a  controller  that  is  not present in\n",
      "              cgroup.controllers leads to an ENOENT error when writing to  the\n",
      "              cgroup.subtree_control file.\n",
      "\n",
      "       Because  the  list of controllers in cgroup.subtree_control is a subset\n",
      "       of those cgroup.controllers, a controller that has been disabled in one\n",
      "       cgroup  in  the  hierarchy can never be re-enabled in the subtree below\n",
      "       that cgroup.\n",
      "\n",
      "       A cgroup's cgroup.subtree_control  file  determines  the  set  of  con‐\n",
      "       trollers  that  are  exercised in the child cgroups.  When a controller\n",
      "       (e.g., pids) is present in the cgroup.subtree_control file of a  parent\n",
      "       cgroup,   then  the  corresponding  controller-interface  files  (e.g.,\n",
      "       pids.max) are automatically created in the children of that cgroup  and\n",
      "       can be used to exert resource control in the child cgroups.\n",
      "\n",
      "   Cgroups v2 \"no internal processes\" rule\n",
      "       Cgroups  v2 enforces a so-called \"no internal processes\" rule.  Roughly\n",
      "       speaking, this rule means that, with the exception of the root  cgroup,\n",
      "       processes may reside only in leaf nodes (cgroups that do not themselves\n",
      "       contain child cgroups).  This avoids the need to decide how  to  parti‐\n",
      "       tion resources between processes which are members of cgroup A and pro‐\n",
      "       cesses in child cgroups of A.\n",
      "\n",
      "       For instance, if cgroup /cg1/cg2 exists, then a process may  reside  in\n",
      "       /cg1/cg2, but not in /cg1.  This is to avoid an ambiguity in cgroups v1\n",
      "       with respect to the delegation of resources between processes  in  /cg1\n",
      "       and  its  child  cgroups.  The recommended approach in cgroups v2 is to\n",
      "       create a subdirectory called leaf for any nonleaf cgroup  which  should\n",
      "       contain  processes, but no child cgroups.  Thus, processes which previ‐\n",
      "       ously would have gone into /cg1 would now go into /cg1/leaf.  This  has\n",
      "       the  advantage of making explicit the relationship between processes in\n",
      "       /cg1/leaf and /cg1's other children.\n",
      "\n",
      "       The \"no internal processes\" rule is in fact  more  subtle  than  stated\n",
      "       above.   More precisely, the rule is that a (nonroot) cgroup can't both\n",
      "       (1) have member processes, and  (2)  distribute  resources  into  child\n",
      "       cgroups—that is, have a nonempty cgroup.subtree_control file.  Thus, it\n",
      "       is possible for a cgroup  to  have  both  member  processes  and  child\n",
      "       cgroups,  but  before  controllers  can be enabled for that cgroup, the\n",
      "       member processes must be moved out of the cgroup  (e.g.,  perhaps  into\n",
      "       the child cgroups).\n",
      "\n",
      "       With  the  Linux  4.14 addition of \"thread mode\" (described below), the\n",
      "       \"no internal processes\" rule has been relaxed in some cases.\n",
      "\n",
      "   Cgroups v2 cgroup.events file\n",
      "       Each nonroot cgroup in the v2  hierarchy  contains  a  read-only  file,\n",
      "       cgroup.events, whose contents are key-value pairs (delimited by newline\n",
      "       characters, with the key and value separated by spaces) providing state\n",
      "       information about the cgroup:\n",
      "\n",
      "           $ cat mygrp/cgroup.events\n",
      "           populated 1\n",
      "           frozen 0\n",
      "\n",
      "       The following keys may appear in this file:\n",
      "\n",
      "       populated\n",
      "              The  value of this key is either 1, if this cgroup or any of its\n",
      "              descendants has member processes, or otherwise 0.\n",
      "\n",
      "       frozen (since Linux 5.2)\n",
      "              The value of this key is 1 if this cgroup is  currently  frozen,\n",
      "              or 0 if it is not.\n",
      "\n",
      "       The  cgroup.events file can be monitored, in order to receive notifica‐\n",
      "       tion when the value of one of its keys changes.  Such monitoring can be\n",
      "       done  using  inotify(7), which notifies changes as IN_MODIFY events, or\n",
      "       poll(2), which notifies changes by returning the  POLLPRI  and  POLLERR\n",
      "       bits in the revents field.\n",
      "\n",
      "   Cgroup v2 release notification\n",
      "       Cgroups  v2  provides a new mechanism for obtaining notification when a\n",
      "       cgroup becomes empty.  The cgroups v1 release_agent  and  notify_on_re‐\n",
      "       lease  files  are  removed,  and  replaced  by the populated key in the\n",
      "       cgroup.events file.  This key either has the value 0, meaning that  the\n",
      "       cgroup  (and  its descendants) contain no (nonzombie) member processes,\n",
      "       or 1, meaning that the cgroup (or one of its descendants) contains mem‐\n",
      "       ber processes.\n",
      "\n",
      "       The  cgroups v2 release-notification mechanism offers the following ad‐\n",
      "       vantages over the cgroups v1 release_agent mechanism:\n",
      "\n",
      "       •  It allows for cheaper notification, since a single process can moni‐\n",
      "          tor  multiple  cgroup.events  files  (using the techniques described\n",
      "          earlier).  By contrast, the cgroups v1 mechanism  requires  the  ex‐\n",
      "          pense of creating a process for each notification.\n",
      "\n",
      "       •  Notification for different cgroup subhierarchies can be delegated to\n",
      "          different processes.  By contrast, the cgroups v1  mechanism  allows\n",
      "          only one release agent for an entire hierarchy.\n",
      "\n",
      "   Cgroups v2 cgroup.stat file\n",
      "       Each  cgroup  in the v2 hierarchy contains a read-only cgroup.stat file\n",
      "       (first introduced in Linux 4.14) that consists of lines containing key-\n",
      "       value pairs.  The following keys currently appear in this file:\n",
      "\n",
      "       nr_descendants\n",
      "              This  is  the  total number of visible (i.e., living) descendant\n",
      "              cgroups underneath this cgroup.\n",
      "\n",
      "       nr_dying_descendants\n",
      "              This is the total number of dying descendant cgroups  underneath\n",
      "              this  cgroup.   A  cgroup  enters  the  dying  state after being\n",
      "              deleted.  It remains in  that  state  for  an  undefined  period\n",
      "              (which will depend on system load) while resources are freed be‐\n",
      "              fore the cgroup is destroyed.  Note that the  presence  of  some\n",
      "              cgroups  in  the dying state is normal, and is not indicative of\n",
      "              any problem.\n",
      "\n",
      "              A process can't be made a member of a dying cgroup, and a  dying\n",
      "              cgroup can't be brought back to life.\n",
      "\n",
      "   Limiting the number of descendant cgroups\n",
      "       Each cgroup in the v2 hierarchy contains the following files, which can\n",
      "       be used to view and set limits on the number of descendant cgroups  un‐\n",
      "       der that cgroup:\n",
      "\n",
      "       cgroup.max.depth (since Linux 4.14)\n",
      "              This  file defines a limit on the depth of nesting of descendant\n",
      "              cgroups.  A value of 0 in this file  means  that  no  descendant\n",
      "              cgroups can be created.  An attempt to create a descendant whose\n",
      "              nesting level exceeds the limit fails (mkdir(2) fails  with  the\n",
      "              error EAGAIN).\n",
      "\n",
      "              Writing the string \"max\" to this file means that no limit is im‐\n",
      "              posed.  The default value in this file is \"max\" .\n",
      "\n",
      "       cgroup.max.descendants (since Linux 4.14)\n",
      "              This file defines a limit  on  the  number  of  live  descendant\n",
      "              cgroups  that  this  cgroup may have.  An attempt to create more\n",
      "              descendants than allowed by the limit fails (mkdir(2) fails with\n",
      "              the error EAGAIN).\n",
      "\n",
      "              Writing the string \"max\" to this file means that no limit is im‐\n",
      "              posed.  The default value in this file is \"max\".\n",
      "\n",
      "CGROUPS DELEGATION: DELEGATING A HIERARCHY TO A LESS PRIVILEGED USER\n",
      "       In the context of cgroups, delegation means passing management of  some\n",
      "       subtree  of  the  cgroup hierarchy to a nonprivileged user.  Cgroups v1\n",
      "       provides support for delegation based on file permissions in the cgroup\n",
      "       hierarchy  but with less strict containment rules than v2 (as noted be‐\n",
      "       low).  Cgroups v2 supports delegation with containment by explicit  de‐\n",
      "       sign.   The focus of the discussion in this section is on delegation in\n",
      "       cgroups v2, with some differences for cgroups v1 noted along the way.\n",
      "\n",
      "       Some terminology is required in order to describe delegation.  A  dele‐\n",
      "       gater  is  a  privileged user (i.e., root) who owns a parent cgroup.  A\n",
      "       delegatee is a nonprivileged user who will be granted  the  permissions\n",
      "       needed  to  manage some subhierarchy under that parent cgroup, known as\n",
      "       the delegated subtree.\n",
      "\n",
      "       To perform delegation, the  delegater  makes  certain  directories  and\n",
      "       files writable by the delegatee, typically by changing the ownership of\n",
      "       the objects to be the user ID of the delegatee.  Assuming that we  want\n",
      "       to  delegate the hierarchy rooted at (say) /dlgt_grp and that there are\n",
      "       not yet any child cgroups under that cgroup, the ownership of the  fol‐\n",
      "       lowing is changed to the user ID of the delegatee:\n",
      "\n",
      "       /dlgt_grp\n",
      "              Changing the ownership of the root of the subtree means that any\n",
      "              new cgroups created under the subtree (and the files  they  con‐\n",
      "              tain) will also be owned by the delegatee.\n",
      "\n",
      "       /dlgt_grp/cgroup.procs\n",
      "              Changing the ownership of this file means that the delegatee can\n",
      "              move processes into the root of the delegated subtree.\n",
      "\n",
      "       /dlgt_grp/cgroup.subtree_control (cgroups v2 only)\n",
      "              Changing the ownership of this file means that the delegatee can\n",
      "              enable  controllers  (that  are present in /dlgt_grp/cgroup.con‐\n",
      "              trollers) in order to further redistribute  resources  at  lower\n",
      "              levels  in the subtree.  (As an alternative to changing the own‐\n",
      "              ership of this file, the delegater might  instead  add  selected\n",
      "              controllers to this file.)\n",
      "\n",
      "       /dlgt_grp/cgroup.threads (cgroups v2 only)\n",
      "              Changing  the  ownership of this file is necessary if a threaded\n",
      "              subtree is being  delegated  (see  the  description  of  \"thread\n",
      "              mode\",  below).   This permits the delegatee to write thread IDs\n",
      "              to the file.  (The ownership of this file can  also  be  changed\n",
      "              when  delegating  a domain subtree, but currently this serves no\n",
      "              purpose, since, as described below, it is not possible to move a\n",
      "              thread  between  domain  cgroups by writing its thread ID to the\n",
      "              cgroup.threads file.)\n",
      "\n",
      "              In cgroups v1, the corresponding file  that  should  instead  be\n",
      "              delegated is the tasks file.\n",
      "\n",
      "       The  delegater should not change the ownership of any of the controller\n",
      "       interfaces files (e.g.,  pids.max,  memory.high)  in  dlgt_grp.   Those\n",
      "       files are used from the next level above the delegated subtree in order\n",
      "       to distribute resources into the subtree, and the delegatee should  not\n",
      "       have  permission  to change the resources that are distributed into the\n",
      "       delegated subtree.\n",
      "\n",
      "       See also the discussion  of  the  /sys/kernel/cgroup/delegate  file  in\n",
      "       NOTES for information about further delegatable files in cgroups v2.\n",
      "\n",
      "       After  the  aforementioned steps have been performed, the delegatee can\n",
      "       create child cgroups within the delegated subtree (the cgroup subdirec‐\n",
      "       tories  and  the files they contain will be owned by the delegatee) and\n",
      "       move processes between cgroups in the subtree.  If some controllers are\n",
      "       present  in  dlgt_grp/cgroup.subtree_control,  or the ownership of that\n",
      "       file was passed to the delegatee, the delegatee can  also  control  the\n",
      "       further  redistribution  of  the corresponding resources into the dele‐\n",
      "       gated subtree.\n",
      "\n",
      "   Cgroups v2 delegation: nsdelegate and cgroup namespaces\n",
      "       Starting with Linux 4.13, there is a second way to perform cgroup dele‐\n",
      "       gation  in  the  cgroups v2 hierarchy.  This is done by mounting or re‐\n",
      "       mounting the cgroup v2 filesystem with  the  nsdelegate  mount  option.\n",
      "       For  example,  if the cgroup v2 filesystem has already been mounted, we\n",
      "       can remount it with the nsdelegate option as follows:\n",
      "\n",
      "           mount -t cgroup2 -o remount,nsdelegate \\\n",
      "                            none /sys/fs/cgroup/unified\n",
      "\n",
      "       The effect of this mount option is to cause cgroup namespaces to  auto‐\n",
      "       matically become delegation boundaries.  More specifically, the follow‐\n",
      "       ing restrictions apply for processes inside the cgroup namespace:\n",
      "\n",
      "       •  Writes to controller interface files in the root  directory  of  the\n",
      "          namespace  will  fail  with  the  error EPERM.  Processes inside the\n",
      "          cgroup namespace can still write to delegatable files  in  the  root\n",
      "          directory   of   the  cgroup  namespace  such  as  cgroup.procs  and\n",
      "          cgroup.subtree_control, and can create subhierarchy  underneath  the\n",
      "          root directory.\n",
      "\n",
      "       •  Attempts  to migrate processes across the namespace boundary are de‐\n",
      "          nied (with the error ENOENT).  Processes inside the cgroup namespace\n",
      "          can  still  (subject  to the containment rules described below) move\n",
      "          processes between cgroups within the subhierarchy  under  the  name‐\n",
      "          space root.\n",
      "\n",
      "       The  ability to define cgroup namespaces as delegation boundaries makes\n",
      "       cgroup namespaces more useful.  To understand why, suppose that we  al‐\n",
      "       ready  have one cgroup hierarchy that has been delegated to a nonprivi‐\n",
      "       leged user, cecilia, using the  older  delegation  technique  described\n",
      "       above.   Suppose further that cecilia wanted to further delegate a sub‐\n",
      "       hierarchy under the existing delegated hierarchy.   (For  example,  the\n",
      "       delegated  hierarchy might be associated with an unprivileged container\n",
      "       run by cecilia.)  Even if a cgroup namespace was employed, because both\n",
      "       hierarchies  are  owned by the unprivileged user cecilia, the following\n",
      "       illegitimate actions could be performed:\n",
      "\n",
      "       •  A process in the inferior hierarchy could change the  resource  con‐\n",
      "          troller  settings  in  the root directory of that hierarchy.  (These\n",
      "          resource controller settings are intended to allow control to be ex‐\n",
      "          ercised  from  the  parent cgroup; a process inside the child cgroup\n",
      "          should not be allowed to modify them.)\n",
      "\n",
      "       •  A process inside the inferior hierarchy could  move  processes  into\n",
      "          and out of the inferior hierarchy if the cgroups in the superior hi‐\n",
      "          erarchy were somehow visible.\n",
      "\n",
      "       Employing the nsdelegate mount option prevents both of these possibili‐\n",
      "       ties.\n",
      "\n",
      "       The  nsdelegate  mount  option only has an effect when performed in the\n",
      "       initial mount namespace; in  other  mount  namespaces,  the  option  is\n",
      "       silently ignored.\n",
      "\n",
      "       Note:  On  some  systems, systemd(1) automatically mounts the cgroup v2\n",
      "       filesystem.  In order to experiment with the nsdelegate  operation,  it\n",
      "       may  be  useful  to boot the kernel with the following command-line op‐\n",
      "       tions:\n",
      "\n",
      "           cgroup_no_v1=all systemd.legacy_systemd_cgroup_controller\n",
      "\n",
      "       These options cause the kernel to boot with the cgroups v1  controllers\n",
      "       disabled  (meaning that the controllers are available in the v2 hierar‐\n",
      "       chy), and tells systemd(1) not to mount and use the cgroup  v2  hierar‐\n",
      "       chy,  so that the v2 hierarchy can be manually mounted with the desired\n",
      "       options after boot-up.\n",
      "\n",
      "   Cgroup delegation containment rules\n",
      "       Some delegation containment rules ensure that the  delegatee  can  move\n",
      "       processes  between cgroups within the delegated subtree, but can't move\n",
      "       processes from outside the delegated subtree into the subtree  or  vice\n",
      "       versa.  A nonprivileged process (i.e., the delegatee) can write the PID\n",
      "       of a \"target\" process into a cgroup.procs file only if all of the  fol‐\n",
      "       lowing are true:\n",
      "\n",
      "       •  The writer has write permission on the cgroup.procs file in the des‐\n",
      "          tination cgroup.\n",
      "\n",
      "       •  The writer has write permission on  the  cgroup.procs  file  in  the\n",
      "          nearest common ancestor of the source and destination cgroups.  Note\n",
      "          that in some cases, the nearest common ancestor may be the source or\n",
      "          destination  cgroup  itself.   This  requirement is not enforced for\n",
      "          cgroups v1 hierarchies, with the consequence that containment in  v1\n",
      "          is  less  strict  than  in v2.  (For example, in cgroups v1 the user\n",
      "          that owns two distinct delegated subhierarchies can move  a  process\n",
      "          between the hierarchies.)\n",
      "\n",
      "       •  If  the cgroup v2 filesystem was mounted with the nsdelegate option,\n",
      "          the writer must be able to see the source  and  destination  cgroups\n",
      "          from its cgroup namespace.\n",
      "\n",
      "       •  In cgroups v1: the effective UID of the writer (i.e., the delegatee)\n",
      "          matches the real user ID or the  saved  set-user-ID  of  the  target\n",
      "          process.   Before  Linux  4.11,  this  requirement  also  applied in\n",
      "          cgroups v2 (This was a historical requirement inherited from cgroups\n",
      "          v1  that was later deemed unnecessary, since the other rules suffice\n",
      "          for containment in cgroups v2.)\n",
      "\n",
      "       Note: one consequence of these delegation containment rules is that the\n",
      "       unprivileged delegatee can't place the first process into the delegated\n",
      "       subtree; instead, the delegater must place the first process (a process\n",
      "       owned by the delegatee) into the delegated subtree.\n",
      "\n",
      "CGROUPS VERSION 2 THREAD MODE\n",
      "       Among  the  restrictions imposed by cgroups v2 that were not present in\n",
      "       cgroups v1 are the following:\n",
      "\n",
      "       •  No thread-granularity control: all of the threads of a process  must\n",
      "          be in the same cgroup.\n",
      "\n",
      "       •  No internal processes: a cgroup can't both have member processes and\n",
      "          exercise controllers on child cgroups.\n",
      "\n",
      "       Both of these restrictions were added because the  lack  of  these  re‐\n",
      "       strictions  had  caused  problems  in  cgroups  v1.  In particular, the\n",
      "       cgroups v1 ability to allow thread-level granularity for cgroup member‐\n",
      "       ship  made  no  sense for some controllers.  (A notable example was the\n",
      "       memory controller: since threads share an address  space,  it  made  no\n",
      "       sense to split threads across different memory cgroups.)\n",
      "\n",
      "       Notwithstanding  the  initial design decision in cgroups v2, there were\n",
      "       use cases for certain controllers,  notably  the  cpu  controller,  for\n",
      "       which  thread-level  granularity  of control was meaningful and useful.\n",
      "       To accommodate such use cases, Linux 4.14 added thread mode for cgroups\n",
      "       v2.\n",
      "\n",
      "       Thread mode allows the following:\n",
      "\n",
      "       •  The  creation of threaded subtrees in which the threads of a process\n",
      "          may be spread across cgroups inside the tree.  (A  threaded  subtree\n",
      "          may contain multiple multithreaded processes.)\n",
      "\n",
      "       •  The  concept of threaded controllers, which can distribute resources\n",
      "          across the cgroups in a threaded subtree.\n",
      "\n",
      "       •  A relaxation of the \"no internal processes rule\", so that, within  a\n",
      "          threaded subtree, a cgroup can both contain member threads and exer‐\n",
      "          cise resource control over child cgroups.\n",
      "\n",
      "       With the addition of thread mode, each nonroot cgroup  now  contains  a\n",
      "       new  file,  cgroup.type, that exposes, and in some circumstances can be\n",
      "       used to change, the \"type\" of a cgroup.  This file contains one of  the\n",
      "       following type values:\n",
      "\n",
      "       domain This  is  a  normal  v2 cgroup that provides process-granularity\n",
      "              control.  If a process is a member  of  this  cgroup,  then  all\n",
      "              threads  of  the process are (by definition) in the same cgroup.\n",
      "              This is the default cgroup type, and provides the same  behavior\n",
      "              that  was  provided for cgroups in the initial cgroups v2 imple‐\n",
      "              mentation.\n",
      "\n",
      "       threaded\n",
      "              This cgroup is a member of a threaded subtree.  Threads  can  be\n",
      "              added  to  this  cgroup,  and controllers can be enabled for the\n",
      "              cgroup.\n",
      "\n",
      "       domain threaded\n",
      "              This is a domain cgroup that serves as the root  of  a  threaded\n",
      "              subtree.  This cgroup type is also known as \"threaded root\".\n",
      "\n",
      "       domain invalid\n",
      "              This  is  a  cgroup inside a threaded subtree that is in an \"in‐\n",
      "              valid\" state.  Processes can't be added to the cgroup, and  con‐\n",
      "              trollers  can't  be enabled for the cgroup.  The only thing that\n",
      "              can be done with this cgroup (other than deleting it) is to con‐\n",
      "              vert it to a threaded cgroup by writing the string \"threaded\" to\n",
      "              the cgroup.type file.\n",
      "\n",
      "              The rationale for the existence of this  \"interim\"  type  during\n",
      "              the  creation of a threaded subtree (rather than the kernel sim‐\n",
      "              ply immediately converting all cgroups under the  threaded  root\n",
      "              to the type threaded) is to allow for possible future extensions\n",
      "              to the thread mode model\n",
      "\n",
      "   Threaded versus domain controllers\n",
      "       With the addition of threads mode, cgroups  v2  now  distinguishes  two\n",
      "       types of resource controllers:\n",
      "\n",
      "       •  Threaded  controllers:  these controllers support thread-granularity\n",
      "          for resource control and can be enabled  inside  threaded  subtrees,\n",
      "          with  the  result  that the corresponding controller-interface files\n",
      "          appear inside the cgroups in the  threaded  subtree.   As  at  Linux\n",
      "          4.19,  the  following controllers are threaded: cpu, perf_event, and\n",
      "          pids.\n",
      "\n",
      "       •  Domain controllers: these controllers support only process granular‐\n",
      "          ity  for  resource  control.   From the perspective of a domain con‐\n",
      "          troller, all threads of a process are always  in  the  same  cgroup.\n",
      "          Domain controllers can't be enabled inside a threaded subtree.\n",
      "\n",
      "   Creating a threaded subtree\n",
      "       There are two pathways that lead to the creation of a threaded subtree.\n",
      "       The first pathway proceeds as follows:\n",
      "\n",
      "       (1)  We write the string \"threaded\" to the cgroup.type file of a cgroup\n",
      "            y/z  that  currently  has the type domain.  This has the following\n",
      "            effects:\n",
      "\n",
      "            •  The type of the cgroup y/z becomes threaded.\n",
      "\n",
      "            •  The type of the parent cgroup, y, becomes domain threaded.  The\n",
      "               parent  cgroup is the root of a threaded subtree (also known as\n",
      "               the \"threaded root\").\n",
      "\n",
      "            •  All other cgroups  under  y  that  were  not  already  of  type\n",
      "               threaded  (because  they  were inside already existing threaded\n",
      "               subtrees under the new threaded root) are converted to type do‐\n",
      "               main  invalid.   Any  subsequently created cgroups under y will\n",
      "               also have the type domain invalid.\n",
      "\n",
      "       (2)  We write the string \"threaded\"  to  each  of  the  domain  invalid\n",
      "            cgroups  under  y,  in order to convert them to the type threaded.\n",
      "            As a consequence of this step, all threads under the threaded root\n",
      "            now  have  the type threaded and the threaded subtree is now fully\n",
      "            usable.  The requirement to write  \"threaded\"  to  each  of  these\n",
      "            cgroups is somewhat cumbersome, but allows for possible future ex‐\n",
      "            tensions to the thread-mode model.\n",
      "\n",
      "       The second way of creating a threaded subtree is as follows:\n",
      "\n",
      "       (1)  In an existing cgroup, z, that currently has the type  domain,  we\n",
      "            (1.1)  enable  one  or  more threaded controllers and (1.2) make a\n",
      "            process a member of z.  (These two steps can be done in either or‐\n",
      "            der.)  This has the following consequences:\n",
      "\n",
      "            •  The type of z becomes domain threaded.\n",
      "\n",
      "            •  All  of  the  descendant  cgroups of x that were not already of\n",
      "               type threaded are converted to type domain invalid.\n",
      "\n",
      "       (2)  As before, we make the threaded  subtree  usable  by  writing  the\n",
      "            string  \"threaded\"  to each of the domain invalid cgroups under y,\n",
      "            in order to convert them to the type threaded.\n",
      "\n",
      "       One of the consequences of the above pathways to  creating  a  threaded\n",
      "       subtree  is  that  the  threaded  root  cgroup  can be a parent only to\n",
      "       threaded (and domain invalid) cgroups.  The threaded root cgroup  can't\n",
      "       be  a  parent  of  a domain cgroups, and a threaded cgroup can't have a\n",
      "       sibling that is a domain cgroup.\n",
      "\n",
      "   Using a threaded subtree\n",
      "       Within a threaded subtree, threaded controllers can be enabled in  each\n",
      "       subgroup  whose  type  has been changed to threaded; upon doing so, the\n",
      "       corresponding controller interface files appear in the children of that\n",
      "       cgroup.\n",
      "\n",
      "       A  process  can  be moved into a threaded subtree by writing its PID to\n",
      "       the cgroup.procs file in one of the cgroups inside the tree.  This  has\n",
      "       the  effect  of making all of the threads in the process members of the\n",
      "       corresponding cgroup and makes the process a  member  of  the  threaded\n",
      "       subtree.   The  threads  of  the  process can then be spread across the\n",
      "       threaded subtree by writing their thread IDs  (see  gettid(2))  to  the\n",
      "       cgroup.threads  files  in  different  cgroups  inside the subtree.  The\n",
      "       threads of a process must all reside in the same threaded subtree.\n",
      "\n",
      "       As with writing to cgroup.procs,  some  containment  rules  apply  when\n",
      "       writing to the cgroup.threads file:\n",
      "\n",
      "       •  The  writer must have write permission on the cgroup.threads file in\n",
      "          the destination cgroup.\n",
      "\n",
      "       •  The writer must have write permission on the  cgroup.procs  file  in\n",
      "          the common ancestor of the source and destination cgroups.  (In some\n",
      "          cases, the common ancestor may be the source or  destination  cgroup\n",
      "          itself.)\n",
      "\n",
      "       •  The source and destination cgroups must be in the same threaded sub‐\n",
      "          tree.  (Outside a threaded subtree, an attempt to move a  thread  by\n",
      "          writing  its thread ID to the cgroup.threads file in a different do‐\n",
      "          main cgroup fails with the error EOPNOTSUPP.)\n",
      "\n",
      "       The cgroup.threads file is present in  each  cgroup  (including  domain\n",
      "       cgroups)  and  can be read in order to discover the set of threads that\n",
      "       is present in the cgroup.  The set of thread IDs obtained when  reading\n",
      "       this file is not guaranteed to be ordered or free of duplicates.\n",
      "\n",
      "       The  cgroup.procs  file in the threaded root shows the PIDs of all pro‐\n",
      "       cesses that are members of  the  threaded  subtree.   The  cgroup.procs\n",
      "       files in the other cgroups in the subtree are not readable.\n",
      "\n",
      "       Domain  controllers  can't  be  enabled  in a threaded subtree; no con‐\n",
      "       troller-interface  files  appear  inside  the  cgroups  underneath  the\n",
      "       threaded root.  From the point of view of a domain controller, threaded\n",
      "       subtrees are invisible: a multithreaded process inside a threaded  sub‐\n",
      "       tree  appears  to  a domain controller as a process that resides in the\n",
      "       threaded root cgroup.\n",
      "\n",
      "       Within a threaded subtree, the \"no internal processes\"  rule  does  not\n",
      "       apply: a cgroup can both contain member processes (or thread) and exer‐\n",
      "       cise controllers on child cgroups.\n",
      "\n",
      "   Rules for writing to cgroup.type and creating threaded subtrees\n",
      "       A number of rules apply when writing to the cgroup.type file:\n",
      "\n",
      "       •  Only the string \"threaded\" may be written.  In other words, the only\n",
      "          explicit  transition  that is possible is to convert a domain cgroup\n",
      "          to type threaded.\n",
      "\n",
      "       •  The effect of writing \"threaded\" depends on  the  current  value  in\n",
      "          cgroup.type, as follows:\n",
      "\n",
      "          •  domain  or domain threaded: start the creation of a threaded sub‐\n",
      "             tree (whose root is the parent of this cgroup) via the  first  of\n",
      "             the pathways described above;\n",
      "\n",
      "          •  domain invalid:  convert  this cgroup (which is inside a threaded\n",
      "             subtree) to a usable (i.e., threaded) state;\n",
      "\n",
      "          •  threaded: no effect (a \"no-op\").\n",
      "\n",
      "       •  We can't write to a cgroup.type file if the parent's type is  domain\n",
      "          invalid.   In other words, the cgroups of a threaded subtree must be\n",
      "          converted to the threaded state in a top-down manner.\n",
      "\n",
      "       There are also some constraints that must be satisfied in order to cre‐\n",
      "       ate a threaded subtree rooted at the cgroup x:\n",
      "\n",
      "       •  There  can  be  no  member processes in the descendant cgroups of x.\n",
      "          (The cgroup x can itself have member processes.)\n",
      "\n",
      "       •  No domain controllers may be enabled in  x's  cgroup.subtree_control\n",
      "          file.\n",
      "\n",
      "       If  any  of the above constraints is violated, then an attempt to write\n",
      "       \"threaded\" to a cgroup.type file fails with the error ENOTSUP.\n",
      "\n",
      "   The \"domain threaded\" cgroup type\n",
      "       According to the pathways described above, the type  of  a  cgroup  can\n",
      "       change to domain threaded in either of the following cases:\n",
      "\n",
      "       •  The string \"threaded\" is written to a child cgroup.\n",
      "\n",
      "       •  A  threaded controller is enabled inside the cgroup and a process is\n",
      "          made a member of the cgroup.\n",
      "\n",
      "       A domain threaded cgroup, x, can revert to the type domain if the above\n",
      "       conditions  no  longer hold true—that is, if all threaded child cgroups\n",
      "       of x are removed and either x no longer has  threaded  controllers  en‐\n",
      "       abled or no longer has member processes.\n",
      "\n",
      "       When a domain threaded cgroup x reverts to the type domain:\n",
      "\n",
      "       •  All  domain  invalid  descendants  of  x that are not in lower-level\n",
      "          threaded subtrees revert to the type domain.\n",
      "\n",
      "       •  The root cgroups in any lower-level threaded subtrees revert to  the\n",
      "          type domain threaded.\n",
      "\n",
      "   Exceptions for the root cgroup\n",
      "       The root cgroup of the v2 hierarchy is treated exceptionally: it can be\n",
      "       the parent  of  both  domain  and  threaded  cgroups.   If  the  string\n",
      "       \"threaded\" is written to the cgroup.type file of one of the children of\n",
      "       the root cgroup, then\n",
      "\n",
      "       •  The type of that cgroup becomes threaded.\n",
      "\n",
      "       •  The type of any descendants of that cgroup  that  are  not  part  of\n",
      "          lower-level threaded subtrees changes to domain invalid.\n",
      "\n",
      "       Note  that  in  this case, there is no cgroup whose type becomes domain\n",
      "       threaded.  (Notionally, the  root  cgroup  can  be  considered  as  the\n",
      "       threaded root for the cgroup whose type was changed to threaded.)\n",
      "\n",
      "       The aim of this exceptional treatment for the root cgroup is to allow a\n",
      "       threaded cgroup that employs the cpu controller to be placed as high as\n",
      "       possible  in  the  hierarchy,  so  as  to  minimize the (small) cost of\n",
      "       traversing the cgroup hierarchy.\n",
      "\n",
      "   The cgroups v2 \"cpu\" controller and realtime threads\n",
      "       As at Linux 4.19, the cgroups v2 cpu controller does not  support  con‐\n",
      "       trol  of  realtime threads (specifically threads scheduled under any of\n",
      "       the  policies  SCHED_FIFO,  SCHED_RR,  described  SCHED_DEADLINE;   see\n",
      "       sched(7)).   Therefore,  the  cpu controller can be enabled in the root\n",
      "       cgroup only if all realtime threads are in the root cgroup.  (If  there\n",
      "       are  realtime threads in nonroot cgroups, then a write(2) of the string\n",
      "       \"+cpu\" to the cgroup.subtree_control file fails with the error EINVAL.)\n",
      "\n",
      "       On some systems, systemd(1) places certain realtime threads in  nonroot\n",
      "       cgroups in the v2 hierarchy.  On such systems, these threads must first\n",
      "       be moved to the root cgroup before the cpu controller can be enabled.\n",
      "\n",
      "ERRORS\n",
      "       The following errors can occur for mount(2):\n",
      "\n",
      "       EBUSY  An attempt to mount a cgroup version 1 filesystem specified nei‐\n",
      "              ther  the  name=  option (to mount a named hierarchy) nor a con‐\n",
      "              troller name (or all).\n",
      "\n",
      "NOTES\n",
      "       A child process created via fork(2) inherits its parent's  cgroup  mem‐\n",
      "       berships.   A  process's  cgroup  memberships  are preserved across ex‐\n",
      "       ecve(2).\n",
      "\n",
      "       The clone3(2) CLONE_INTO_CGROUP flag can be  used  to  create  a  child\n",
      "       process  that  begins its life in a different version 2 cgroup from the\n",
      "       parent process.\n",
      "\n",
      "   /proc files\n",
      "       /proc/cgroups (since Linux 2.6.24)\n",
      "              This file contains information about the  controllers  that  are\n",
      "              compiled  into  the  kernel.  An example of the contents of this\n",
      "              file (reformatted for readability) is the following:\n",
      "\n",
      "                  #subsys_name    hierarchy      num_cgroups    enabled\n",
      "                  cpuset          4              1              1\n",
      "                  cpu             8              1              1\n",
      "                  cpuacct         8              1              1\n",
      "                  blkio           6              1              1\n",
      "                  memory          3              1              1\n",
      "                  devices         10             84             1\n",
      "                  freezer         7              1              1\n",
      "                  net_cls         9              1              1\n",
      "                  perf_event      5              1              1\n",
      "                  net_prio        9              1              1\n",
      "                  hugetlb         0              1              0\n",
      "                  pids            2              1              1\n",
      "\n",
      "              The fields in this file are, from left to right:\n",
      "\n",
      "              [1]  The name of the controller.\n",
      "\n",
      "              [2]  The unique ID of the cgroup hierarchy on  which  this  con‐\n",
      "                   troller is mounted.  If multiple cgroups v1 controllers are\n",
      "                   bound to the same hierarchy, then each will show  the  same\n",
      "                   hierarchy  ID  in this field.  The value in this field will\n",
      "                   be 0 if:\n",
      "\n",
      "                   •  the controller is not mounted on a cgroups v1 hierarchy;\n",
      "\n",
      "                   •  the controller is bound to the cgroups v2 single unified\n",
      "                      hierarchy; or\n",
      "\n",
      "                   •  the controller is disabled (see below).\n",
      "\n",
      "              [3]  The  number  of control groups in this hierarchy using this\n",
      "                   controller.\n",
      "\n",
      "              [4]  This field contains the value 1 if this controller  is  en‐\n",
      "                   abled, or 0 if it has been disabled (via the cgroup_disable\n",
      "                   kernel command-line boot parameter).\n",
      "\n",
      "       /proc/[pid]/cgroup (since Linux 2.6.24)\n",
      "              This file describes control groups to which the process with the\n",
      "              corresponding  PID  belongs.   The displayed information differs\n",
      "              for cgroups version 1 and version 2 hierarchies.\n",
      "\n",
      "              For each cgroup hierarchy of which  the  process  is  a  member,\n",
      "              there is one entry containing three colon-separated fields:\n",
      "\n",
      "                  hierarchy-ID:controller-list:cgroup-path\n",
      "\n",
      "              For example:\n",
      "\n",
      "                  5:cpuacct,cpu,cpuset:/daemons\n",
      "\n",
      "              The colon-separated fields are, from left to right:\n",
      "\n",
      "              [1]  For  cgroups  version  1 hierarchies, this field contains a\n",
      "                   unique hierarchy ID number that can be matched to a hierar‐\n",
      "                   chy ID in /proc/cgroups.  For the cgroups version 2 hierar‐\n",
      "                   chy, this field contains the value 0.\n",
      "\n",
      "              [2]  For cgroups version 1 hierarchies, this  field  contains  a\n",
      "                   comma-separated  list of the controllers bound to the hier‐\n",
      "                   archy.  For the cgroups version 2 hierarchy, this field  is\n",
      "                   empty.\n",
      "\n",
      "              [3]  This  field  contains  the pathname of the control group in\n",
      "                   the hierarchy to which the process belongs.  This  pathname\n",
      "                   is relative to the mount point of the hierarchy.\n",
      "\n",
      "   /sys/kernel/cgroup files\n",
      "       /sys/kernel/cgroup/delegate (since Linux 4.15)\n",
      "              This  file exports a list of the cgroups v2 files (one per line)\n",
      "              that are delegatable (i.e., whose ownership should be changed to\n",
      "              the  user ID of the delegatee).  In the future, the set of dele‐\n",
      "              gatable files may change or grow, and this file provides  a  way\n",
      "              for  the kernel to inform user-space applications of which files\n",
      "              must be delegated.  As at Linux 4.15,  one  sees  the  following\n",
      "              when inspecting this file:\n",
      "\n",
      "                  $ cat /sys/kernel/cgroup/delegate\n",
      "                  cgroup.procs\n",
      "                  cgroup.subtree_control\n",
      "                  cgroup.threads\n",
      "\n",
      "       /sys/kernel/cgroup/features (since Linux 4.15)\n",
      "              Over  time,  the set of cgroups v2 features that are provided by\n",
      "              the kernel may change or grow, or some features may not  be  en‐\n",
      "              abled  by  default.  This file provides a way for user-space ap‐\n",
      "              plications to discover what features the running kernel supports\n",
      "              and has enabled.  Features are listed one per line:\n",
      "\n",
      "                  $ cat /sys/kernel/cgroup/features\n",
      "                  nsdelegate\n",
      "                  memory_localevents\n",
      "\n",
      "              The entries that can appear in this file are:\n",
      "\n",
      "              memory_localevents (since Linux 5.2)\n",
      "                     The kernel supports the memory_localevents mount option.\n",
      "\n",
      "              nsdelegate (since Linux 4.15)\n",
      "                     The kernel supports the nsdelegate mount option.\n",
      "\n",
      "              memory_recursiveprot (since Linux 5.7)\n",
      "                     The  kernel  supports  the memory_recursiveprot mount op‐\n",
      "                     tion.\n",
      "\n",
      "SEE ALSO\n",
      "       prlimit(1), systemd(1),  systemd-cgls(1),  systemd-cgtop(1),  clone(2),\n",
      "       ioprio_set(2),  perf_event_open(2), setrlimit(2), cgroup_namespaces(7),\n",
      "       cpuset(7), namespaces(7), sched(7), user_namespaces(7)\n",
      "\n",
      "       The kernel source file Documentation/admin-guide/cgroup-v2.rst.\n",
      "\n",
      "Linux man-pages 6.03              2023-02-05                        cgroups(7)\n"
     ]
    }
   ],
   "source": [
    "man cgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb173ad-ab43-4316-885c-096d02fb0582",
   "metadata": {},
   "source": [
    "#### Security constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718886a1-83d6-4a92-936d-0d45adc46fbc",
   "metadata": {},
   "source": [
    "Containers are isolated from each other using many security tools available in the kernel. The goal is \n",
    "\n",
    "> blocking privilege escalation and preventing a rogue group of processes from committing hostile acts against the system, including the following examples:\n",
    "\n",
    "- Dropped Linux capabilities limit the power of root.\n",
    "- SELinux controls access to the filesystem.\n",
    "- There is read-only access to kernel filesystems.\n",
    "- Seccomp limits the system calls available in the kernel.\n",
    "- A user namespace to map one group of UIDs in the host to another allows access to limited root environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66825cfb-24b5-4526-9c93-43a65651fec3",
   "metadata": {},
   "source": [
    "### Namespaces - Virtualization technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd65eb-6853-4698-a830-ee519aadddff",
   "metadata": {},
   "source": [
    "The Linux kernel employs a concept called **namespaces**, which creates virtualized environments, where one set of processes sees one set of resources, while another set of processes sees a different set of resources. These **virtualized environments** eliminate processes’ views into the rest of the system, giving them the feel of a virtual machine (VM) without the overhead. Examples of namespaces include the following:\n",
    "\n",
    "- **Network namespace** — Eliminates the access to the host network but gives access to virtual network devices,\n",
    "- **Mount namespace** — Eliminates the view of all the filesystem, except the containers filesystem,\n",
    "- **PID namespace** — Eliminates the view of other processes on the system; container processes only see the processes within the container.\n",
    "\n",
    "These container technologies have existed in the Linux kernel for many years. Security tools for isolating processes started in Unix back in the 1970s, and SELinux started in 2001. Namespaces were introduced around 2004, and cgroups were introduced around 2006."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb77240-f30f-4535-ba8b-fadf96accf1f",
   "metadata": {},
   "source": [
    "### Container image format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608def7-240c-4ed7-b62c-e34288d1272d",
   "metadata": {},
   "source": [
    "A **container image** consists of three components:\n",
    "\n",
    "- A **directory tree** containing all the software required to run your application,\n",
    "- A JSON file that describes the contents of the **rootfs**,\n",
    "- Another JSON file called a **manifest list** that links multiple images together to support different architectures.\n",
    "\n",
    "The directory tree is called a **rootfs** (root filesystem). The software is laid out like it was the root (`/`) of a Linux system.\n",
    "\n",
    "The executable to be run within the `rootfs`, the working directory, the environment variables to be used, the maintainer of the executable, and other labels to help identify the content of the image are defined in the first JSON file. You can see this JSON file using the `podman inspect` command:\n",
    "\n",
    "```sh\n",
    "$ podman inspect docker://registry.access.redhat.com/ubi8\n",
    "```\n",
    "```json\n",
    "{\n",
    "...\n",
    "  \"created\": \"2022-01-27T16:00:30.397689Z\",      ❶\n",
    "  \"architecture\": \"amd64\",                       ❷\n",
    "  \"os\": \"linux\",                                 ❸\n",
    "  \"config\": {\n",
    "         \"Env\": [                                ❹\n",
    "            \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
    "            \"container=oci\"\n",
    "         ],\n",
    "         \"Cmd\": [                                ❺\n",
    "                   \"/bin/bash\"\n",
    "         ],\n",
    "         \"Labels\": {                             ❻\n",
    "                     \"architecture\": \"x86_64\",\n",
    "                     \"build-date\": \"2022-01-27T15:59:52.415605\",\n",
    "       ...\n",
    "}\n",
    "```\n",
    "\n",
    "1. Date the image was created\n",
    "1. Architecture for this image\n",
    "1. Operating system for this image\n",
    "1. Environment variables that the developer of the image wants to be set within the container\n",
    "1. Default command to be executed when the container starts\n",
    "1. Labels to help describe the contents of the image. These fields can be free-form and do not affect the way images are run but can be used to search for and describe the image.\n",
    "\n",
    "The second JSON file, the **manifest list**, allows users on an arm64 machine to pull an image with the same name as they would if they were on an arm64 machine. Podman pulls the image based on the default architecture of the machine, using this manifest list:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"manifests\": [\n",
    "      {\n",
    "              \"digest\": \"sha256:cbc1e8cea\n",
    "➥ 8c78cfa1490c4f01b2be59d43ddbb\n",
    "➥ ad6987d938def1960f64bcd02c\",                                                    ❶\n",
    "              \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",❷\n",
    "              \"platform\": {\n",
    "              \"architecture\": \"amd64\",                                            ❸\n",
    "              \"os\": \"linux\"                                                       ❹\n",
    "              },\n",
    "              \"size\": 737\n",
    "      },\n",
    "      {\n",
    "              \"digest\":                                                           ❺\n",
    "➥ \"sha256:f52d79a9d0a3c23e6ac4c3c8f2ed8d6337ea47f4e2dfd46201756160ca193308\",\n",
    "              \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n",
    "              \"platform\": {\n",
    "              \"architecture\": \"arm64\", \n",
    "              \"os\": \"linux\"\n",
    "              },\n",
    "              \"size\": 737\n",
    "      },\n",
    "...\n",
    "}\n",
    "```\n",
    "\n",
    "1. Digest (hash sum) of the exact image pulled when the architecture and OS match\n",
    "1. mediaType describes the type of the image, OCI, Docker, and so on.\n",
    "1. The architecture of this image digest: amd64\n",
    "1. The OS of this image digest: Linux\n",
    "1. This stanza (строка файла конфигурации) points to a different image for a different architecture: arm64."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37850ead-fb8c-4ce6-bfba-24a7adeb16e5",
   "metadata": {},
   "source": [
    "### <b>Skopeo</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f0cc62-3c29-4ade-b752-a5325372505c",
   "metadata": {},
   "source": [
    "**Skopeo** (Greek for \"remote viewing\") is a tool that uses the same underlying libraries as Podman and is available at [github.com/containers/skopeo](github.com/containers/skopeo) (see appendix A). Skopeo provides lower-level output examining the structures of a container image. \n",
    "\n",
    "Skopeo works with Podman and Buildah to manage OCI containers. Put simply, \n",
    "- **Podman** runs containers, \n",
    "- **Buildah** builds containers, and \n",
    "- **Skopeo** transports containers –– among other things. \n",
    "\n",
    "Think of these tools as a swiss army knife for your container environment. Skopeo is a deft and versatile blade at your disposal. ([source](https://www.redhat.com/en/topics/containers/what-is-skopeo))\n",
    "\n",
    "In the following example, use the `skopeo` command with the `--raw` option to examine the [registry.access.redhat.com/ubi8](registry.access.redhat.com/ubi8) image manifest specification without the need to pull the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de65f5cd-1cf6-4098-8403-bf34d04b7ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T19:35:07.728298Z",
     "iopub.status.busy": "2024-01-13T19:35:07.727127Z",
     "iopub.status.idle": "2024-01-13T19:35:08.756550Z",
     "shell.execute_reply": "2024-01-13T19:35:08.755246Z",
     "shell.execute_reply.started": "2024-01-13T19:35:07.728255Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"manifests\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:4b5ad3e7af158ded8070d4e0f1d75a3f197d065efeadddf33455f486f30e7832\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.docker.distribution.manifest.v2+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"amd64\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m429\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:5c33b45ca04495caaa41eaae45e471748480d44fd39aa09350db45bbdeb40f55\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.docker.distribution.manifest.v2+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"arm64\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m429\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:47df466911a0351a1e9744fb065bab435f7f5aec0050ad0e764fbed45b4668fd\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.docker.distribution.manifest.v2+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ppc64le\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m429\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:90a0be2052eaf5adcaff2f9ccbe2e0b4eeb4421454c7a1eb19d3c9e3d7cfc0b8\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.docker.distribution.manifest.v2+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"s390x\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m429\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.docker.distribution.manifest.list.v2+json\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"schemaVersion\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m2\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# sudo apt update && sudo apt install skopeo -y\n",
    "\n",
    "skopeo inspect --raw docker://registry.access.redhat.com/ubi8 | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0830de-945a-424c-889a-2b8b0221532e",
   "metadata": {},
   "source": [
    "#### Postgres example (VR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a621b2-ce9f-45c2-b677-379cf2f502e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T12:28:03.681290Z",
     "iopub.status.busy": "2024-01-13T12:28:03.680625Z",
     "iopub.status.idle": "2024-01-13T12:28:06.153319Z",
     "shell.execute_reply": "2024-01-13T12:28:06.152023Z",
     "shell.execute_reply.started": "2024-01-13T12:28:03.681241Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                 DESCRIPTION\n",
      "docker.io/library/postgres                           The PostgreSQL object-relational database sy...\n",
      "docker.io/bitnami/postgresql                         Bitnami PostgreSQL Docker Image\n",
      "docker.io/cimg/postgres                              \n",
      "docker.io/bitnami/postgres-exporter                  \n",
      "docker.io/bitnami/postgresql-repmgr                  \n",
      "docker.io/ubuntu/postgres                            PostgreSQL is an open source object-relation...\n",
      "docker.io/rapidfort/postgresql                       RapidFort optimized, hardened image for Post...\n",
      "docker.io/rapidfort/postgresql-official              RapidFort optimized, hardened image for Post...\n",
      "docker.io/bitnamicharts/postgresql                   \n",
      "docker.io/rapidfort/postgresql12-ib                  RapidFort optimized, hardened image for Post...\n",
      "docker.io/cockroachdb/postgres-test                  An environment to run the CockroachDB accept...\n",
      "docker.io/elestio/postgres                           Postgres, verified and packaged by Elestio\n",
      "docker.io/pachyderm/postgresql                       \n",
      "docker.io/bitnamicharts/postgresql-ha                \n",
      "docker.io/kasmweb/postgres                           Postgres image maintained by Kasm Technologi...\n",
      "docker.io/vmware/postgresql                          \n",
      "docker.io/vmware/postgresql-photon                   \n",
      "docker.io/bitnami/postgrest                          \n",
      "docker.io/hashicorp/postgres-nomad-demo              Used in Nomad-Vault integration guide\n",
      "docker.io/objectscale/postgresql-repmgr              \n",
      "docker.io/wodby/postgres                             Alpine-based PostgreSQL container image with...\n",
      "docker.io/dockette/postgres                          My PostgreSQL image with tunning and preinst...\n",
      "docker.io/airbyte/postgres-singer-source-abprotocol  \n",
      "docker.io/clearlinux/postgres                        PostgreSQL object-relational database system...\n",
      "docker.io/drud/postgres                              \n"
     ]
    }
   ],
   "source": [
    "podman search postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49eafa17-fc37-426c-a0ec-3c3a8ae4bb27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T19:31:48.717435Z",
     "iopub.status.busy": "2024-01-13T19:31:48.716640Z",
     "iopub.status.idle": "2024-01-13T19:31:48.874381Z",
     "shell.execute_reply": "2024-01-13T19:31:48.871304Z",
     "shell.execute_reply.started": "2024-01-13T19:31:48.717373Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY  TAG         IMAGE ID    CREATED     SIZE\n"
     ]
    }
   ],
   "source": [
    "podman images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b9ee0-9e1b-4e63-95cb-d289f11668d8",
   "metadata": {},
   "source": [
    "Get the manifest file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd29199-e572-49bf-b317-4c7f131b600c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T19:31:49.313218Z",
     "iopub.status.busy": "2024-01-13T19:31:49.312702Z",
     "iopub.status.idle": "2024-01-13T19:31:51.028003Z",
     "shell.execute_reply": "2024-01-13T19:31:51.026951Z",
     "shell.execute_reply.started": "2024-01-13T19:31:49.313192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"manifests\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.revision\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d416768b1a7f03919b9cf0fef6adc9dcad937888\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.source\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/docker-library/postgres.git#d416768b1a7f03919b9cf0fef6adc9dcad937888:16/bookworm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://hub.docker.com/_/postgres\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:60c91e0203ae5ccca0a251953742752cd16a129db181bc15559cca71420b188c\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"amd64\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3324\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:60c91e0203ae5ccca0a251953742752cd16a129db181bc15559cca71420b188c\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"attestation-manifest\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:d75fb3e8a4753c68a7ab34ebe8fef6b7a9c1daa76f202a9fc6fef45c9b844b82\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m841\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.revision\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d416768b1a7f03919b9cf0fef6adc9dcad937888\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.source\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/docker-library/postgres.git#d416768b1a7f03919b9cf0fef6adc9dcad937888:16/bookworm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://hub.docker.com/_/postgres\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:c5f76d46d12230623ddccc341e3d11227258e07ce1c8a11f2d30e3a5aa15627a\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"arm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"variant\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"v5\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3324\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:c5f76d46d12230623ddccc341e3d11227258e07ce1c8a11f2d30e3a5aa15627a\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"attestation-manifest\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:2e5ab144d53df4c6a2f09467713fe25fcb348ba3c54869d257443d5d4acb0565\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m841\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.revision\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d416768b1a7f03919b9cf0fef6adc9dcad937888\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.source\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/docker-library/postgres.git#d416768b1a7f03919b9cf0fef6adc9dcad937888:16/bookworm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://hub.docker.com/_/postgres\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:6441aa83a5158d075a6ac653b6af0db873a40caf640d8ba912aa6224b2d34f8e\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"arm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"variant\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"v7\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3324\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:6441aa83a5158d075a6ac653b6af0db873a40caf640d8ba912aa6224b2d34f8e\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"attestation-manifest\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:3b1a3e63949b6fbfaf714c1714039212fd7cd3dcc25400ee41c40eb19246a651\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m841\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.revision\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d416768b1a7f03919b9cf0fef6adc9dcad937888\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.source\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/docker-library/postgres.git#d416768b1a7f03919b9cf0fef6adc9dcad937888:16/bookworm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://hub.docker.com/_/postgres\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:c24ad689a4df0101e3af801f4de7adea22c38cd383d6221981044b4c21947a2b\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"arm64\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"variant\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"v8\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3324\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:c24ad689a4df0101e3af801f4de7adea22c38cd383d6221981044b4c21947a2b\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"attestation-manifest\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:2e839967422c39f217be8a9e750b7d66b8ae35cc45ad676caf7a46219d7bdd67\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m841\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.revision\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d416768b1a7f03919b9cf0fef6adc9dcad937888\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.source\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/docker-library/postgres.git#d416768b1a7f03919b9cf0fef6adc9dcad937888:16/bookworm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://hub.docker.com/_/postgres\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:5bff3da062a4e0771a20fd9b192a557ed6f9a571cd98c603ad8eedb5002ebc93\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"386\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3324\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:5bff3da062a4e0771a20fd9b192a557ed6f9a571cd98c603ad8eedb5002ebc93\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"attestation-manifest\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:7bb55ea8f63672b35b6be635d91134f5f398f2ecef8595d81413bf054e31c279\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m841\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.revision\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d416768b1a7f03919b9cf0fef6adc9dcad937888\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.source\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/docker-library/postgres.git#d416768b1a7f03919b9cf0fef6adc9dcad937888:16/bookworm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://hub.docker.com/_/postgres\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:29e9ea5dcaeb7a7971d1cb2b9a02b4a4013db0741a1b57e51a7a181238190e87\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"mips64le\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3324\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:29e9ea5dcaeb7a7971d1cb2b9a02b4a4013db0741a1b57e51a7a181238190e87\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"attestation-manifest\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:9cb2dc3263bee1342486f30fb3911ad2f9110b1b3a228a73ba44690cac1c49a2\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m567\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.revision\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d416768b1a7f03919b9cf0fef6adc9dcad937888\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.source\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/docker-library/postgres.git#d416768b1a7f03919b9cf0fef6adc9dcad937888:16/bookworm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://hub.docker.com/_/postgres\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:b63d39363873a4141b4c36f9f1b1b71698f11593ae15135d5bf483a486b31e83\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"ppc64le\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3324\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:b63d39363873a4141b4c36f9f1b1b71698f11593ae15135d5bf483a486b31e83\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"attestation-manifest\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:64772ecfb4e5c851fc5a9d3eeba5eaf44d02178b2c3be8ef7b17c31d4e8eb5d5\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m841\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.revision\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"d416768b1a7f03919b9cf0fef6adc9dcad937888\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.source\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://github.com/docker-library/postgres.git#d416768b1a7f03919b9cf0fef6adc9dcad937888:16/bookworm\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.url\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"https://hub.docker.com/_/postgres\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"org.opencontainers.image.version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:a66921e40581ad1e66f2e4a4d560d77c51275187e0c8b7f27d2e7c89b1d8fb76\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"s390x\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m3324\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[1;39m{\n",
      "      \u001b[0m\u001b[34;1m\"annotations\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:a66921e40581ad1e66f2e4a4d560d77c51275187e0c8b7f27d2e7c89b1d8fb76\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"vnd.docker.reference.type\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"attestation-manifest\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:dce2719466810705b42492975611535934a314ffb39042bd56ccbb0e8d8241d9\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.manifest.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"platform\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[34;1m\"architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[34;1m\"os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"unknown\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[34;1m\"size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m841\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"mediaType\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"application/vnd.oci.image.index.v1+json\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"schemaVersion\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m2\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "skopeo inspect --raw docker://docker.io/library/postgres | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7f56b-b721-4159-a130-d33e6884eb21",
   "metadata": {},
   "source": [
    "Get the overall information of the repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a991af7-14a7-4692-81e6-3827660d44dd",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-13T19:27:18.250671Z",
     "iopub.status.busy": "2024-01-13T19:27:18.250174Z",
     "iopub.status.idle": "2024-01-13T19:27:22.792561Z",
     "shell.execute_reply": "2024-01-13T19:27:22.791525Z",
     "shell.execute_reply.started": "2024-01-13T19:27:18.250630Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"Name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"docker.io/library/postgres\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:49c276fa02e3d61bd9b8db81dfb4784fe814f50f778dce5980a03817438293e3\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"RepoTags\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[0;32m\"10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-beta1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-beta1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-beta2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-beta3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-beta4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-beta4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-rc1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.0-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.11-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.12-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.13-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.14-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.15-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.16-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.17-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.17-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.17-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.17-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.17-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.18-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.18-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.18-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.18-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.18-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.19-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.19-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.19-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.19-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.19-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.20\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.20-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.20-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.20-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.20-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.21\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.21-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.21-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.21-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.21-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.21-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.22-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.22-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.22-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.23-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.23-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.23-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.6-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.7-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.8-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"10.9-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-beta1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-beta1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-beta2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-beta3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-beta4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-beta4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-rc1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.0-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.11-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.12-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.12-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.12-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.12-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.12-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.13-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.13-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.13-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.13-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.13-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.14-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.14-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.14-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.14-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.14-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.15-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.15-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.15-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.15-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.16-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.16-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.16-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.16-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.16-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.17-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.17-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.17-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.18-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.18-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.18-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.18-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.19-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.19-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.19-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.20-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.20-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.20-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.20-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.20-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.21-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.21-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.21-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.21-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.21-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.22-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.22-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.22-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.22-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.22-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.22-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.6-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.7-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.8-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"11.9-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-beta1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-beta1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-beta2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-beta3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-beta4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-beta4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12-rc1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.0-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.10-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.10-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.11-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.11-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.11-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.11-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.12-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.12-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.12-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.13-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.13-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.13-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.13-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.14-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.14-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.14-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.15-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.15-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.15-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.15-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.15-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.16-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.16-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.16-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.16-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.16-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.17-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.17-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.17-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.17-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.17-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.17-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.6-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.7-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.7-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.7-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.7-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.8-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.8-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.8-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.8-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.9-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.9-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.9-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"12.9-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-beta1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-beta1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-beta2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-beta3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13-rc1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.0-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.10-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.10-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.11-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.11-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.11-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.11-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.11-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.12-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.12-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.12-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.12-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.12-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.13-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.13-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.13-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.13-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.13-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.13-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.3-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.3-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.3-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.4-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.4-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.4-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.5-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.5-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.5-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.6-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.6-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.6-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.7-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.7-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.7-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.7-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.8-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.8-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.8-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.9-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.9-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.9-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"13.9-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.0-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.0-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.0-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.1-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.1-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.1-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.10-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.10-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.10-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.10-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.10-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.2-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.2-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.3-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.3-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.3-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.4-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.4-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.5-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.5-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.6-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.6-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.6-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.6-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.7-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.7-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.7-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.8-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.8-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.8-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.8-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.8-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.9-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.9-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.9-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.9-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14.9-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14beta2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14beta2-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14beta2-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14beta3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14beta3-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14beta3-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14rc1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14rc1-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"14rc1-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.0-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.0-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.0-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.1-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.1-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.1-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.2-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.2-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.3-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.3-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.3-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.3-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.4-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.4-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.4-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.4-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.5-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.5-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.5-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.5-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15.5-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta1-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta1-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta1-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta2-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta2-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta3-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta3-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta4-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15beta4-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15rc1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15rc1-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15rc1-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15rc2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15rc2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15rc2-alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"15rc2-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.0-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.0-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.0-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.0-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.0-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.1-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.1-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.1-alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.1-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16.1-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta1-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta1-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta1-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta1-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta2-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta2-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta2-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta2-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta3-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta3-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta3-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16beta3-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16rc1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16rc1-alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16rc1-alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16rc1-bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"16rc1-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"8.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"8.4.22\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.0.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.0.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.0.20\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.0.21\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.0.22\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.20\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.21\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.22\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.23\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.1.24\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.19-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.20\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.20-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.21\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.21-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.22\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.22-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.23\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.23-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.2.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.15-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.16-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.17-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.18-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.19-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.20\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.20-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.21\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.21-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.22\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.22-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.23\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.23-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.24\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.24-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.25\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.25-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.3.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4-beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4-beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4-rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.11-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.12-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.13-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.14-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.15-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.16-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.17-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.18-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.19-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.20\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.20-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.21\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.21-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.22\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.22-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.23\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.23-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.24\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.24-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.25\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.25-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.26\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.26-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.4.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5-alpha1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5-alpha2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5-beta1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5-beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5-rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.11-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.12-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.13-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.14-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.15-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.16-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.17-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.18-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.19-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.20\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.20-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.21\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.21-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.22\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.22-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.23\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.23-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.24\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.24-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.25\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.25-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.6-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.7-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.8-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.5.9-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-beta1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-beta2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-beta3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-beta4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-rc1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.0\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.1-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.10\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.10-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.11\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.11-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.12\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.12-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.13-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.14-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.15-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.16-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.17-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.18-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.19-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.2\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.2-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.20\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.20-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.21\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.21-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.22\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.22-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.22-alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.22-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.22-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.22-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.23\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.23-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.23-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.23-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.23-buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.23-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.24\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.24-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.24-alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.24-alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.24-bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.24-stretch\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.3\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.3-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.4-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.5\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.5-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.6\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.6-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.7-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.8-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.9\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"9.6.9-alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"alpine\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"alpine3.13\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"alpine3.14\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"alpine3.15\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"alpine3.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"alpine3.17\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"alpine3.18\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"alpine3.19\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"bookworm\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"bullseye\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"buster\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"latest\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Created\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"2024-01-04T21:52:40Z\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"DockerVersion\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Labels\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;30mnull\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"amd64\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Layers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[0;32m\"sha256:2f44b7a888fa005d07c031d3cfad2a1c0344207def2ab9dbb97712425ff812c1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:6d49150dabe2486c7b35dbe0ea864b690e079fa1b48ef77d1e4533d96b4051e7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:18d6a86d0fbff788e398befc7b6139bed448853e3a113ea6b2c6c97783f4d8a1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:4c9385c30bce0478ebb3d7b8cd3ae66e9b211e980669bd0d67f3bb38b8bfaa40\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:550091272acc768f00ff9a7ae977f9c558f5d3364cd5f87fabcc452d6f677b0e\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:2720859ac49e9505ac9b95a3937053a3e0c2bb623b4bb6f49468c20ef7db8bc4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:b8091cf535458ca73ced6bb49c25ec769ae88608216e721e6bd1767d36138e3f\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:f3ca5fbd89cdb8212ec43875a45b14a9f1cfda38272896347251e76e0cc383fe\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:22fbbce47a56e5ceed3d8ec4a588a1adaed23a83c230645206ec26d961f876cd\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:b3b5e3b65b9594578082fe4f45b479c2de5782344f17d74b7e34a3184000bf28\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:917e5b76e085bfd128b12de93138dc43366eefc6efe52bedea5d351a0612b50f\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:7f21ce9572c6e1750cc335372d0d1c6a893da69e3064e7efc961237c5ba63538\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:4ea3941c8572e8e5721645ca86d9b9ddc868a5276c899e036d6da84fba9890ec\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:848fee03c0344030501221daea678a4869e5b9d4da9e4899d25b328bcc3c78a4\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Env\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[0;32m\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/postgresql/16/bin\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"GOSU_VERSION=1.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"LANG=en_US.utf8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"PG_MAJOR=16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"PG_VERSION=16.1-1.pgdg120+1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"PGDATA=/var/lib/postgresql/data\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "skopeo inspect docker://docker.io/library/postgres | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dfe3cb-34c5-4a1f-8689-a325d5db2b20",
   "metadata": {},
   "source": [
    "Skip annoying tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1f25e2-a0fd-427f-8c2f-825ab82c6d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T10:23:45.626945Z",
     "iopub.status.busy": "2024-01-20T10:23:45.626318Z",
     "iopub.status.idle": "2024-01-20T10:23:50.023200Z",
     "shell.execute_reply": "2024-01-20T10:23:50.021621Z",
     "shell.execute_reply.started": "2024-01-20T10:23:45.626920Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[34;1m\"Name\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"docker.io/library/postgres\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Digest\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"sha256:49c276fa02e3d61bd9b8db81dfb4784fe814f50f778dce5980a03817438293e3\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"RepoTags\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Created\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"2024-01-04T21:52:40Z\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"DockerVersion\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Labels\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;30mnull\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Architecture\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"amd64\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Os\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"linux\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Layers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[0;32m\"sha256:2f44b7a888fa005d07c031d3cfad2a1c0344207def2ab9dbb97712425ff812c1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:6d49150dabe2486c7b35dbe0ea864b690e079fa1b48ef77d1e4533d96b4051e7\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:18d6a86d0fbff788e398befc7b6139bed448853e3a113ea6b2c6c97783f4d8a1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:4c9385c30bce0478ebb3d7b8cd3ae66e9b211e980669bd0d67f3bb38b8bfaa40\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:550091272acc768f00ff9a7ae977f9c558f5d3364cd5f87fabcc452d6f677b0e\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:2720859ac49e9505ac9b95a3937053a3e0c2bb623b4bb6f49468c20ef7db8bc4\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:b8091cf535458ca73ced6bb49c25ec769ae88608216e721e6bd1767d36138e3f\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:f3ca5fbd89cdb8212ec43875a45b14a9f1cfda38272896347251e76e0cc383fe\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:22fbbce47a56e5ceed3d8ec4a588a1adaed23a83c230645206ec26d961f876cd\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:b3b5e3b65b9594578082fe4f45b479c2de5782344f17d74b7e34a3184000bf28\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:917e5b76e085bfd128b12de93138dc43366eefc6efe52bedea5d351a0612b50f\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:7f21ce9572c6e1750cc335372d0d1c6a893da69e3064e7efc961237c5ba63538\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:4ea3941c8572e8e5721645ca86d9b9ddc868a5276c899e036d6da84fba9890ec\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"sha256:848fee03c0344030501221daea678a4869e5b9d4da9e4899d25b328bcc3c78a4\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[34;1m\"Env\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "    \u001b[0;32m\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/postgresql/16/bin\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"GOSU_VERSION=1.16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"LANG=en_US.utf8\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"PG_MAJOR=16\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"PG_VERSION=16.1-1.pgdg120+1\"\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0;32m\"PGDATA=/var/lib/postgresql/data\"\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m]\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "skopeo inspect --no-tags docker://docker.io/library/postgres | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be6f1c2-2e71-400e-8bb2-0c8542dc1484",
   "metadata": {},
   "source": [
    "Get only layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0605300-455e-4e7f-b4ef-74f90201e697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T15:06:23.044837Z",
     "iopub.status.busy": "2024-01-15T15:06:23.044240Z",
     "iopub.status.idle": "2024-01-15T15:06:27.548979Z",
     "shell.execute_reply": "2024-01-15T15:06:27.547443Z",
     "shell.execute_reply.started": "2024-01-15T15:06:23.044789Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\n",
      "  \u001b[0;32m\"sha256:2f44b7a888fa005d07c031d3cfad2a1c0344207def2ab9dbb97712425ff812c1\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:6d49150dabe2486c7b35dbe0ea864b690e079fa1b48ef77d1e4533d96b4051e7\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:18d6a86d0fbff788e398befc7b6139bed448853e3a113ea6b2c6c97783f4d8a1\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:4c9385c30bce0478ebb3d7b8cd3ae66e9b211e980669bd0d67f3bb38b8bfaa40\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:550091272acc768f00ff9a7ae977f9c558f5d3364cd5f87fabcc452d6f677b0e\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:2720859ac49e9505ac9b95a3937053a3e0c2bb623b4bb6f49468c20ef7db8bc4\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:b8091cf535458ca73ced6bb49c25ec769ae88608216e721e6bd1767d36138e3f\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:f3ca5fbd89cdb8212ec43875a45b14a9f1cfda38272896347251e76e0cc383fe\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:22fbbce47a56e5ceed3d8ec4a588a1adaed23a83c230645206ec26d961f876cd\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:b3b5e3b65b9594578082fe4f45b479c2de5782344f17d74b7e34a3184000bf28\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:917e5b76e085bfd128b12de93138dc43366eefc6efe52bedea5d351a0612b50f\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:7f21ce9572c6e1750cc335372d0d1c6a893da69e3064e7efc961237c5ba63538\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:4ea3941c8572e8e5721645ca86d9b9ddc868a5276c899e036d6da84fba9890ec\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0;32m\"sha256:848fee03c0344030501221daea678a4869e5b9d4da9e4899d25b328bcc3c78a4\"\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "skopeo inspect docker://docker.io/library/postgres | jq .Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376c0460-eb19-4f6a-8851-01942aec8179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T10:36:31.472848Z",
     "iopub.status.busy": "2024-01-20T10:36:31.472419Z",
     "iopub.status.idle": "2024-01-20T10:36:52.856230Z",
     "shell.execute_reply": "2024-01-20T10:36:52.849277Z",
     "shell.execute_reply.started": "2024-01-20T10:36:31.472808Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRECATED: skopeo layers is deprecated in favor of skopeo copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skopeo layers docker://docker.io/library/postgres | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ed90af-efa1-43c6-b263-08469e85628b",
   "metadata": {},
   "source": [
    "Count the number of tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25fb23ca-8d20-4869-9db0-606344e7e431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T10:29:20.680238Z",
     "iopub.status.busy": "2024-01-20T10:29:20.679871Z",
     "iopub.status.idle": "2024-01-20T10:29:22.481289Z",
     "shell.execute_reply": "2024-01-20T10:29:22.480137Z",
     "shell.execute_reply.started": "2024-01-20T10:29:20.680208Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828\n"
     ]
    }
   ],
   "source": [
    "skopeo list-tags docker://docker.io/library/postgres | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798564f7-ce3f-4849-b1f4-b5c49af19a9c",
   "metadata": {},
   "source": [
    "#### Mans of Skopeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d15e6888-a163-4620-9d62-3912bd446cd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-13T12:30:29.311110Z",
     "iopub.status.busy": "2024-01-13T12:30:29.308401Z",
     "iopub.status.idle": "2024-01-13T12:30:29.695022Z",
     "shell.execute_reply": "2024-01-13T12:30:29.692164Z",
     "shell.execute_reply.started": "2024-01-13T12:30:29.311080Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKOPEO(1)(Skopeo)                                            SKOPEO(1)(Skopeo)\n",
      "\n",
      "Jhon Honce August 2016\n",
      "\n",
      "NAME\n",
      "       skopeo  --  Command line utility used to interact with local and remote\n",
      "       container images and container image registries\n",
      "\n",
      "SYNOPSIS\n",
      "       skopeo [global options] command [command options]\n",
      "\n",
      "DESCRIPTION\n",
      "       skopeo is a command line utility providing various operations with con‐\n",
      "       tainer images and container image registries.\n",
      "\n",
      "       skopeo  can  copy  container  images  between  various containers image\n",
      "       stores, converting them as necessary.  For example you can  use  skopeo\n",
      "       to copy container images from one container registry to another.\n",
      "\n",
      "       skopeo  can convert a Docker schema 2 or schema 1 container image to an\n",
      "       OCI image.\n",
      "\n",
      "       skopeo can inspect a repository on a container registry  without  need‐\n",
      "       lessly  pulling  the  image.  Pulling an image from a repository, espe‐\n",
      "       cially a remote repository, is an expensive network and storage  opera‐\n",
      "       tion.  Skopeo  fetches  the repository's manifest and displays a docker\n",
      "       inspect-like json output about the repository or a tag. skopeo, in con‐\n",
      "       trast  to  docker  inspect, helps you gather useful information about a\n",
      "       repository or a tag without requiring you to run docker pull -  e.g.  -\n",
      "       Which  tags  are  available for the given repository? Which labels does\n",
      "       the image have?\n",
      "\n",
      "       skopeo can sign and verify container images.\n",
      "\n",
      "       skopeo can delete container images from a remote container registry.\n",
      "\n",
      "       Note: skopeo does not require any container runtimes to be running,  to\n",
      "       do  most  of  its functionality.  It also does not require root, unless\n",
      "       you are copying images into a container runtime storage  backend,  like\n",
      "       the docker daemon or github.com/containers/storage.\n",
      "\n",
      "IMAGE NAMES\n",
      "       Most commands refer to container images, using a transport:details for‐\n",
      "       mat. The following formats are supported:\n",
      "\n",
      "       containers-storage:docker-reference\n",
      "         An image located in a local containers/storage image store.  Both the\n",
      "       location and image store are specified in /etc/containers/storage.conf.\n",
      "       (Backend for Podman, CRI-O, Buildah and friends)\n",
      "\n",
      "       dir:path\n",
      "         An existing local directory path storing the manifest, layer tarballs\n",
      "       and  signatures as individual files. This is a non-standardized format,\n",
      "       primarily useful for debugging or noninvasive container inspection.\n",
      "\n",
      "       docker://docker-reference\n",
      "         An image in a registry implementing the  \"Docker  Registry  HTTP  API\n",
      "       V2\".  By  default,  uses  the  authorization  state in either $XDG_RUN‐\n",
      "       TIME_DIR/containers/auth.json, which is set using  (skopeo  login).  If\n",
      "       the  authorization  state is not found there, $HOME/.docker/config.json\n",
      "       is checked, which is set using (docker login).\n",
      "\n",
      "       docker-archive:path[:docker-reference]\n",
      "         An image is stored in the docker save formatted file.   docker-refer‐\n",
      "       ence  is only used when creating such a file, and it must not contain a\n",
      "       digest.\n",
      "\n",
      "       docker-daemon:docker-reference\n",
      "         An image docker-reference stored in the docker daemon internal  stor‐\n",
      "       age.  docker-reference must contain either a tag or a digest.  Alterna‐\n",
      "       tively, when reading images, the format can  be  docker-daemon:algo:di‐\n",
      "       gest (an image ID).\n",
      "\n",
      "       oci:path:tag\n",
      "         An image tag in a directory compliant with \"Open Container Image Lay‐\n",
      "       out Specification\" at path.\n",
      "\n",
      "       oci-archive:path:tag\n",
      "         An image tag in a tar archive compliant with  \"Open  Container  Image\n",
      "       Layout Specification\" at path.\n",
      "\n",
      "       See     containers-transports(5)     ⟨https://github.com/containers/im‐\n",
      "       age/blob/master/docs/containers-transports.5.md⟩ for details.\n",
      "\n",
      "OPTIONS\n",
      "       --command-timeout duration\n",
      "\n",
      "       Timeout for the command execution.\n",
      "\n",
      "       --debug\n",
      "\n",
      "       enable debug output\n",
      "\n",
      "       --help, -h\n",
      "\n",
      "       Show help\n",
      "\n",
      "       --insecure-policy\n",
      "\n",
      "       Adopt an insecure, permissive policy that allows anything.  This  obvi‐\n",
      "       ates the need for a policy file.\n",
      "\n",
      "       --override-arch arch\n",
      "\n",
      "       Use  arch  instead  of the architecture of the machine for choosing im‐\n",
      "       ages.\n",
      "\n",
      "       --override-os os\n",
      "\n",
      "       Use OS instead of the running OS for choosing images.\n",
      "\n",
      "       --override-variant variant\n",
      "\n",
      "       Use variant instead of the running architecture  variant  for  choosing\n",
      "       images.\n",
      "\n",
      "       --policy path-to-policy\n",
      "\n",
      "       Path to a policy.json file to use for verifying signatures and deciding\n",
      "       whether an image is trusted, overriding the default trust policy file.\n",
      "\n",
      "       --registries.d dir\n",
      "\n",
      "       Use registry configuration files in dir (e.g. for  container  signature\n",
      "       storage), overriding the default path.\n",
      "\n",
      "       --tmpdir dir\n",
      "\n",
      "       Directory used to store temporary files. Defaults to /var/tmp.\n",
      "\n",
      "       --version, -v\n",
      "\n",
      "       Print the version number\n",
      "\n",
      "COMMANDS\n",
      "       ┌────────────────────────────┬─────────────────────────────────────────────────────────────────────────────┐\n",
      "       │Command                     │ Description                                                                 │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-copy(1)              │ Copy  an  image (manifest, filesystem layers, signatures) from one location │\n",
      "       │                            │ to another.                                                                 │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-delete(1)            │ Mark the image-name for later deletion by the registry's garbage collector. │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-inspect(1)           │ Return low-level information about image-name in a registry.                │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-list-tags(1)         │ List image names in a transport-specific collection of images.              │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-login(1)             │ Login to a container registry.                                              │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-logout(1)            │ Logout of a container registry.                                             │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-manifest-digest(1)   │ Compute a manifest digest for a manifest-file and write it to standard out‐ │\n",
      "       │                            │ put.                                                                        │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-standalone-sign(1)   │ Debugging tool - Publish and sign an image in one step.                     │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-standalone-verify(1) │ Verify an image signature.                                                  │\n",
      "       ├────────────────────────────┼─────────────────────────────────────────────────────────────────────────────┤\n",
      "       │skopeo-sync(1)              │ Synchronize images between container registries and local directories.      │\n",
      "       └────────────────────────────┴─────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "FILES\n",
      "       /etc/containers/policy.json\n",
      "         Default trust policy file, if --policy is not specified.\n",
      "         The   policy   format   is  documented  in  containers-policy.json(5)\n",
      "       ⟨https://github.com/containers/image/blob/master/docs/containers-pol‐\n",
      "       icy.json.5.md⟩ .\n",
      "\n",
      "       /etc/containers/registries.d\n",
      "         Default   directory  containing  registry  configuration,  if  --reg‐\n",
      "       istries.d is not specified.\n",
      "         The contents of this  directory  are  documented  in  containers-pol‐\n",
      "       icy.json(5)  ⟨https://github.com/containers/image/blob/master/docs/con‐\n",
      "       tainers-policy.json.5.md⟩.\n",
      "\n",
      "SEE ALSO\n",
      "       skopeo-login(1), docker-login(1), containers-auth.json(5),  containers-\n",
      "       storage.conf(5), containers-policy.json(5), containers-transports(5)\n",
      "\n",
      "AUTHORS\n",
      "       Antonio  Murdaca runcom@redhat.com ⟨mailto:runcom@redhat.com⟩, Miloslav\n",
      "       Trmac mitr@redhat.com ⟨mailto:mitr@redhat.com⟩, Jhon Honce  jhonce@red‐\n",
      "       hat.com ⟨mailto:jhonce@redhat.com⟩\n",
      "\n",
      "Pages                                 Man                    SKOPEO(1)(Skopeo)\n"
     ]
    }
   ],
   "source": [
    "man skopeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e47f7fc-454a-4aa8-99a5-bbbf9338f4fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T10:22:11.836746Z",
     "iopub.status.busy": "2024-01-20T10:22:11.836324Z",
     "iopub.status.idle": "2024-01-20T10:22:12.221100Z",
     "shell.execute_reply": "2024-01-20T10:22:12.220033Z",
     "shell.execute_reply.started": "2024-01-20T10:22:11.836708Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skopeo-inspect(1)()                                        skopeo-inspect(1)()\n",
      "\n",
      "NAME\n",
      "       skopeo-inspect  -  Return  low-level  information about image-name in a\n",
      "       registry.\n",
      "\n",
      "SYNOPSIS\n",
      "       skopeo inspect [options] image-name\n",
      "\n",
      "DESCRIPTION\n",
      "       Return low-level information  about  image-name  in  a  registry.   See\n",
      "       skopeo(1) for the format of image-name.\n",
      "\n",
      "       The  default  output  includes  data  from  various sources: user input\n",
      "       (Name), the remote repository, if any (RepoTags), the  top-level  mani‐\n",
      "       fest  (Digest),  and  a  per-architecture/OS image matching the current\n",
      "       run-time environment (most other values).  To see values for a  differ‐\n",
      "       ent  architecture/OS,  use  the --override-os / --override-arch options\n",
      "       documented in skopeo(1).\n",
      "\n",
      "OPTIONS\n",
      "       --authfile path\n",
      "\n",
      "       Path of the authentication file. Default is ${XDG_RUNTIME_DIR}/contain‐\n",
      "       ers/auth.json,  which  is set using skopeo login.  If the authorization\n",
      "       state is not found there, $HOME/.docker/config.json is  checked,  which\n",
      "       is set using docker login.\n",
      "\n",
      "       --cert-dir path\n",
      "\n",
      "       Use  certificates at path (*.crt, *.cert, *.key) to connect to the reg‐\n",
      "       istry.\n",
      "\n",
      "       --config\n",
      "\n",
      "       Output configuration in OCI format, default is to format in  JSON  for‐\n",
      "       mat.\n",
      "\n",
      "       --creds username[:password]\n",
      "\n",
      "       Username and password for accessing the registry.\n",
      "\n",
      "       --daemon-host host\n",
      "\n",
      "       Use docker daemon host at host (docker-daemon: transport only)\n",
      "\n",
      "       --format, -f=format\n",
      "\n",
      "       Format  the  output  using  the given Go template.  The keys of the re‐\n",
      "       turned JSON can be used as the values for the --format flag (see  exam‐\n",
      "       ples below).\n",
      "\n",
      "       --help, -h\n",
      "\n",
      "       Print usage statement\n",
      "\n",
      "       --no-creds\n",
      "\n",
      "       Access the registry anonymously.\n",
      "\n",
      "       --raw\n",
      "\n",
      "       Output  raw  manifest or config data depending on --config option.  The\n",
      "       --format option is not supported with --raw option.\n",
      "\n",
      "       --registry-token Bearer token\n",
      "\n",
      "       Registry token for accessing the registry.\n",
      "\n",
      "       --retry-times\n",
      "\n",
      "       The number of times to retry; retry wait time will be exponentially in‐\n",
      "       creased based on the number of failed attempts.\n",
      "\n",
      "       --shared-blob-dir directory\n",
      "\n",
      "       Directory to use to share blobs across OCI repositories.\n",
      "\n",
      "       --tls-verify=bool\n",
      "\n",
      "       Require  HTTPS  and  verify  certificates when talking to the container\n",
      "       registry or daemon. Default to registry.conf setting.\n",
      "\n",
      "       --username\n",
      "\n",
      "       The username to access the registry.\n",
      "\n",
      "       --password\n",
      "\n",
      "       The password to access the registry.\n",
      "\n",
      "       --no-tags, -n\n",
      "\n",
      "       Do not list the available tags from the repository in the output.  When\n",
      "       true,  the  RepoTags array will be empty.  Defaults to false, which in‐\n",
      "       cludes all available tags.\n",
      "\n",
      "EXAMPLES\n",
      "       To review information for the image fedora from the docker.io registry:\n",
      "\n",
      "              $ skopeo inspect docker://docker.io/fedora\n",
      "              {\n",
      "                  \"Name\": \"docker.io/library/fedora\",\n",
      "                  \"Digest\": \"sha256:a97914edb6ba15deb5c5acf87bd6bd5b6b0408c96f48a5cbd450b5b04509bb7d\",\n",
      "                  \"RepoTags\": [\n",
      "                   \"20\",\n",
      "                   \"21\",\n",
      "                   \"22\",\n",
      "                   \"23\",\n",
      "                   \"24\",\n",
      "                   \"heisenbug\",\n",
      "                   \"latest\",\n",
      "                   \"rawhide\"\n",
      "                  ],\n",
      "                  \"Created\": \"2016-06-20T19:33:43.220526898Z\",\n",
      "                  \"DockerVersion\": \"1.10.3\",\n",
      "                  \"Labels\": {},\n",
      "                  \"Architecture\": \"amd64\",\n",
      "                  \"Os\": \"linux\",\n",
      "                  \"Layers\": [\n",
      "                   \"sha256:7c91a140e7a1025c3bc3aace4c80c0d9933ac4ee24b8630a6b0b5d8b9ce6b9d4\"\n",
      "                  ]\n",
      "              }\n",
      "\n",
      "       To inspect python from the docker.io registry and not show  the  avail‐\n",
      "       able tags:\n",
      "\n",
      "              $ skopeo inspect --no-tags docker://docker.io/library/python\n",
      "              {\n",
      "                  \"Name\": \"docker.io/library/python\",\n",
      "                  \"Digest\": \"sha256:5ca194a80ddff913ea49c8154f38da66a41d2b73028c5cf7e46bc3c1d6fda572\",\n",
      "                  \"RepoTags\": [],\n",
      "                  \"Created\": \"2021-10-05T23:40:54.936108045Z\",\n",
      "                  \"DockerVersion\": \"20.10.7\",\n",
      "                  \"Labels\": null,\n",
      "                  \"Architecture\": \"amd64\",\n",
      "                  \"Os\": \"linux\",\n",
      "                  \"Layers\": [\n",
      "                      \"sha256:df5590a8898bedd76f02205dc8caa5cc9863267dbcd8aac038bcd212688c1cc7\",\n",
      "                      \"sha256:705bb4cb554eb7751fd21a994f6f32aee582fbe5ea43037db6c43d321763992b\",\n",
      "                      \"sha256:519df5fceacdeaadeec563397b1d9f4d7c29c9f6eff879739cab6f0c144f49e1\",\n",
      "                      \"sha256:ccc287cbeddc96a0772397ca00ec85482a7b7f9a9fac643bfddd87b932f743db\",\n",
      "                      \"sha256:e3f8e6af58ed3a502f0c3c15dce636d9d362a742eb5b67770d0cfcb72f3a9884\",\n",
      "                      \"sha256:aebed27b2d86a5a3a2cbe186247911047a7e432b9d17daad8f226597c0ea4276\",\n",
      "                      \"sha256:54c32182bdcc3041bf64077428467109a70115888d03f7757dcf614ff6d95ebe\",\n",
      "                      \"sha256:cc8b7caedab13af07adf4836e13af2d4e9e54d794129b0fd4c83ece6b1112e86\",\n",
      "                      \"sha256:462c3718af1d5cdc050cfba102d06c26f78fe3b738ce2ca2eb248034b1738945\"\n",
      "                  ],\n",
      "                  \"Env\": [\n",
      "                      \"PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n",
      "                      \"LANG=C.UTF-8\",\n",
      "                      \"GPG_KEY=A035C8C19219BA821ECEA86B64E628F8D684696D\",\n",
      "                      \"PYTHON_VERSION=3.10.0\",\n",
      "                      \"PYTHON_PIP_VERSION=21.2.4\",\n",
      "                      \"PYTHON_SETUPTOOLS_VERSION=57.5.0\",\n",
      "                      \"PYTHON_GET_PIP_URL=https://github.com/pypa/get-pip/raw/d781367b97acf0ece7e9e304bf281e99b618bf10/public/get-pip.py\",\n",
      "                      \"PYTHON_GET_PIP_SHA256=01249aa3e58ffb3e1686b7141b4e9aac4d398ef4ac3012ed9dff8dd9f685ffe0\"\n",
      "                  ]\n",
      "              }\n",
      "\n",
      "              $ /bin/skopeo inspect --config docker://registry.fedoraproject.org/fedora --format \"{{ .Architecture }}\"\n",
      "              amd64\n",
      "\n",
      "              $ /bin/skopeo inspect --format '{{ .Env }}' docker://registry.access.redhat.com/ubi8\n",
      "              [PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin container=oci]\n",
      "\n",
      "SEE ALSO\n",
      "       skopeo(1), skopeo-login(1), docker-login(1), containers-auth.json(5)\n",
      "\n",
      "AUTHORS\n",
      "       Antonio  Murdaca runcom@redhat.com ⟨mailto:runcom@redhat.com⟩, Miloslav\n",
      "       Trmac mitr@redhat.com ⟨mailto:mitr@redhat.com⟩, Jhon Honce  jhonce@red‐\n",
      "       hat.com ⟨mailto:jhonce@redhat.com⟩\n",
      "\n",
      "                                                           skopeo-inspect(1)()\n"
     ]
    }
   ],
   "source": [
    "man skopeo-inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34f76d68-637a-455e-9fb8-6a3b3a6262e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T10:37:13.342180Z",
     "iopub.status.busy": "2024-01-20T10:37:13.341798Z",
     "iopub.status.idle": "2024-01-20T10:37:13.818121Z",
     "shell.execute_reply": "2024-01-20T10:37:13.816812Z",
     "shell.execute_reply.started": "2024-01-20T10:37:13.342157Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skopeo-copy(1)()                                              skopeo-copy(1)()\n",
      "\n",
      "NAME\n",
      "       skopeo-copy  -  Copy an image (manifest, filesystem layers, signatures)\n",
      "       from one location to another.\n",
      "\n",
      "SYNOPSIS\n",
      "       skopeo copy [options] source-image destination-image\n",
      "\n",
      "DESCRIPTION\n",
      "       Copy an image (manifest, filesystem layers, signatures) from one  loca‐\n",
      "       tion to another.\n",
      "\n",
      "       Uses  the  system's trust policy to validate images, rejects images not\n",
      "       trusted by the policy.\n",
      "\n",
      "       source-image use the \"image name\" format described above\n",
      "\n",
      "       destination-image use the \"image name\" format described above\n",
      "\n",
      "       source-image and destination-image are interpreted completely  indepen‐\n",
      "       dently;  e.g.  the  destination name does not automatically inherit any\n",
      "       parts of the source name.\n",
      "\n",
      "OPTIONS\n",
      "       --additional-tag=strings\n",
      "\n",
      "       Additional tags (supports docker-archive).\n",
      "\n",
      "       --all, -a\n",
      "\n",
      "       If source-image refers to a list of images, instead of copying just the\n",
      "       image which matches the current OS and architecture (subject to the use\n",
      "       of the global --override-os, --override-arch and --override-variant op‐\n",
      "       tions), attempt to copy all of the images in the list, and the list it‐\n",
      "       self.\n",
      "\n",
      "       --authfile path\n",
      "\n",
      "       Path of the authentication file. Default is ${XDG_RUNTIME_DIR}/contain‐\n",
      "       ers/auth.json,  which  is set using skopeo login.  If the authorization\n",
      "       state is not found there, $HOME/.docker/config.json is  checked,  which\n",
      "       is set using docker login.\n",
      "\n",
      "       Note: You can also override the default path of the authentication file\n",
      "       by setting the REGISTRY_AUTH_FILE  environment  variable.  export  REG‐\n",
      "       ISTRY_AUTH_FILE=path\n",
      "\n",
      "       --src-authfile path\n",
      "\n",
      "       Path  of  the  authentication  file  for the source registry. Uses path\n",
      "       given by --authfile, if not provided.\n",
      "\n",
      "       --dest-authfile path\n",
      "\n",
      "       Path of the authentication file for the destination registry. Uses path\n",
      "       given by --authfile, if not provided.\n",
      "\n",
      "       --dest-shared-blob-dir directory\n",
      "\n",
      "       Directory to use to share blobs across OCI repositories.\n",
      "\n",
      "       --digestfile path\n",
      "\n",
      "       After copying the image, write the digest of the resulting image to the\n",
      "       file.\n",
      "\n",
      "       --preserve-digests\n",
      "\n",
      "       Preserve the digests during copying. Fail if the digest cannot be  pre‐\n",
      "       served.\n",
      "\n",
      "       --encrypt-layer ints\n",
      "\n",
      "       Experimental the 0-indexed layer indices, with support for negative in‐\n",
      "       dexing (e.g. 0 is the first layer, -1 is the last layer)\n",
      "\n",
      "       --format, -f manifest-type\n",
      "\n",
      "       MANIFEST TYPE (oci, v2s1, or v2s2) to use in the  destination  (default\n",
      "       is manifest type of source, with fallbacks)\n",
      "\n",
      "       --help, -h\n",
      "\n",
      "       Print usage statement\n",
      "\n",
      "       --multi-arch option\n",
      "\n",
      "       Control  what  is copied if source-image refers to a multi-architecture\n",
      "       image. Default is system.\n",
      "\n",
      "       Options: - system: Copy only the image that matches the  system  archi‐\n",
      "       tecture  -  all:  Copy  the full multi-architecture image - index-only:\n",
      "       Copy only the index\n",
      "\n",
      "       The index-only option usually fails unless the referenced per-architec‐\n",
      "       ture  images are already present in the destination, or the target reg‐\n",
      "       istry supports sparse indexes.\n",
      "\n",
      "       --quiet, -q\n",
      "\n",
      "       Suppress output information when copying images.\n",
      "\n",
      "       --remove-signatures\n",
      "\n",
      "       Do not copy signatures, if any, from source-image. Necessary when copy‐\n",
      "       ing a signed image to a destination which does not support signatures.\n",
      "\n",
      "       --sign-by key-id\n",
      "\n",
      "       Add  a  “simple  signing” signature using that key ID for an image name\n",
      "       corresponding to destination-image\n",
      "\n",
      "       --sign-by-sigstore-private-key path\n",
      "\n",
      "       Add a sigstore signature using a private key at path for an image  name\n",
      "       corresponding to destination-image\n",
      "\n",
      "       --sign-passphrase-file path\n",
      "\n",
      "       The passphare to use when signing with --sign-by or --sign-by-sigstore-\n",
      "       private-key. Only the first line will be read. A passphrase stored in a\n",
      "       file  is of questionable security if other users can read this file. Do\n",
      "       not use this option if at all avoidable.\n",
      "\n",
      "       --sign-identity reference\n",
      "\n",
      "       The identity to use when signing the image.  The  identity  must  be  a\n",
      "       fully specified docker reference. If the identity is not specified, the\n",
      "       target docker reference will be used.\n",
      "\n",
      "       --src-shared-blob-dir directory\n",
      "\n",
      "       Directory to use to share blobs across OCI repositories.\n",
      "\n",
      "       --encryption-key protocol:keyfile\n",
      "\n",
      "       Specifies the encryption protocol, which  can  be  JWE  (RFC7516),  PGP\n",
      "       (RFC4880),  and PKCS7 (RFC2315) and the key material required for image\n",
      "       encryption. For instance, jwe:/path/to/key.pem or pgp:admin@example.com\n",
      "       or pkcs7:/path/to/x509-file.\n",
      "\n",
      "       --decryption-key key[:passphrase]\n",
      "\n",
      "       Key  to  be used for decryption of images. Key can point to keys and/or\n",
      "       certificates. Decryption will be tried with all keys.  If  the  key  is\n",
      "       protected  by a passphrase, it is required to be passed in the argument\n",
      "       and omitted otherwise.\n",
      "\n",
      "       --src-creds username[:password]\n",
      "\n",
      "       Credentials for accessing the source registry.\n",
      "\n",
      "       --dest-compress\n",
      "\n",
      "       Compress tarball image layers when saving to directory using the  'dir'\n",
      "       transport. (default is same compression type as source).\n",
      "\n",
      "       --dest-decompress\n",
      "\n",
      "       Decompress  tarball  image  layers  when  saving to directory using the\n",
      "       'dir' transport. (default is same compression type as source).\n",
      "\n",
      "       --dest-oci-accept-uncompressed-layers\n",
      "\n",
      "       Allow uncompressed image layers when saving to an OCI image  using  the\n",
      "       'oci'  transport.  (default  is  to  compress  things  that aren't com‐\n",
      "       pressed).\n",
      "\n",
      "       --dest-creds username[:password]\n",
      "\n",
      "       Credentials for accessing the destination registry.\n",
      "\n",
      "       --src-cert-dir path\n",
      "\n",
      "       Use certificates at path (*.crt,  *.cert,  *.key)  to  connect  to  the\n",
      "       source registry or daemon.\n",
      "\n",
      "       --src-no-creds\n",
      "\n",
      "       Access the registry anonymously.\n",
      "\n",
      "       --src-tls-verify=bool\n",
      "\n",
      "       Require  HTTPS and verify certificates when talking to container source\n",
      "       registry or daemon. Default to source registry setting.\n",
      "\n",
      "       --dest-cert-dir path\n",
      "\n",
      "       Use certificates at path (*.crt, *.cert, *.key) to connect to the  des‐\n",
      "       tination registry or daemon.\n",
      "\n",
      "       --dest-no-creds\n",
      "\n",
      "       Access the registry anonymously.\n",
      "\n",
      "       --dest-tls-verify=bool\n",
      "\n",
      "       Require  HTTPS and verify certificates when talking to container desti‐\n",
      "       nation registry or daemon. Default to destination registry setting.\n",
      "\n",
      "       --src-daemon-host host\n",
      "\n",
      "       Copy from docker daemon at host. If host starts with tcp://,  HTTPS  is\n",
      "       enabled by default. To use plain HTTP, use the form http:// (default is\n",
      "       unix:///var/run/docker.sock).\n",
      "\n",
      "       --dest-daemon-host host\n",
      "\n",
      "       Copy to docker daemon at host. If host starts with tcp://, HTTPS is en‐\n",
      "       abled  by  default. To use plain HTTP, use the form http:// (default is\n",
      "       unix:///var/run/docker.sock).\n",
      "\n",
      "       Existing signatures, if any, are preserved as well.\n",
      "\n",
      "       --dest-compress-format format\n",
      "\n",
      "       Specifies the compression format to use.  Supported  values  are:  gzip\n",
      "       and zstd.\n",
      "\n",
      "       --dest-compress-level format\n",
      "\n",
      "       Specifies  the  compression level to use.  The value is specific to the\n",
      "       compression algorithm used, e.g. for zstd the accepted  values  are  in\n",
      "       the range 1-20 (inclusive), while for gzip it is 1-9 (inclusive).\n",
      "\n",
      "       --src-registry-token token\n",
      "\n",
      "       Bearer token for accessing the source registry.\n",
      "\n",
      "       --dest-registry-token token\n",
      "\n",
      "       Bearer token for accessing the destination registry.\n",
      "\n",
      "       --dest-precompute-digests\n",
      "\n",
      "       Precompute digests to ensure layers are not uploaded that already exist\n",
      "       on the destination registry. Layers with initially unknown digests (ex.\n",
      "       compressing \"on the fly\") will be temporarily streamed to disk.\n",
      "\n",
      "       --retry-times\n",
      "\n",
      "       The number of times to retry. Retry wait time will be exponentially in‐\n",
      "       creased based on the number of failed attempts.\n",
      "\n",
      "       --src-username\n",
      "\n",
      "       The username to access the source registry.\n",
      "\n",
      "       --src-password\n",
      "\n",
      "       The password to access the source registry.\n",
      "\n",
      "       --dest-username\n",
      "\n",
      "       The username to access the destination registry.\n",
      "\n",
      "       --dest-password\n",
      "\n",
      "       The password to access the destination registry.\n",
      "\n",
      "EXAMPLES\n",
      "       To just copy an image from one registry to another:\n",
      "\n",
      "              $ skopeo copy docker://quay.io/skopeo/stable:latest docker://registry.example.com/skopeo:latest\n",
      "\n",
      "       To copy the layers of the docker.io busybox image to a local directory:\n",
      "\n",
      "              $ mkdir -p /var/lib/images/busybox\n",
      "              $ skopeo copy docker://busybox:latest dir:/var/lib/images/busybox\n",
      "              $ ls /var/lib/images/busybox/*\n",
      "                /tmp/busybox/2b8fd9751c4c0f5dd266fcae00707e67a2545ef34f9a29354585f93dac906749.tar\n",
      "                /tmp/busybox/manifest.json\n",
      "                /tmp/busybox/8ddc19f16526912237dd8af81971d5e4dd0587907234be2b83e249518d5b673f.tar\n",
      "\n",
      "       To copy and sign an image:\n",
      "\n",
      "              # skopeo copy --sign-by dev@example.com containers-storage:example/busybox:streaming docker://example/busybox:gold\n",
      "\n",
      "       To encrypt an image:\n",
      "\n",
      "              skopeo copy docker://docker.io/library/nginx:1.17.8 oci:local_nginx:1.17.8\n",
      "\n",
      "              openssl genrsa -out private.key 1024\n",
      "              openssl rsa -in private.key -pubout > public.key\n",
      "\n",
      "              skopeo  copy --encryption-key jwe:./public.key oci:local_nginx:1.17.8 oci:try-encrypt:encrypted\n",
      "\n",
      "       To decrypt an image:\n",
      "\n",
      "              skopeo copy --decryption-key ./private.key oci:try-encrypt:encrypted oci:try-decrypt:decrypted\n",
      "\n",
      "       To copy encrypted image without decryption:\n",
      "\n",
      "              skopeo copy oci:try-encrypt:encrypted oci:try-encrypt-copy:encrypted\n",
      "\n",
      "       To decrypt an image that requires more than one key:\n",
      "\n",
      "              skopeo copy --decryption-key ./private1.key --decryption-key ./private2.key --decryption-key ./private3.key oci:try-encrypt:encrypted oci:try-decrypt:decrypted\n",
      "\n",
      "       Container images can also be partially encrypted by specifying the  in‐\n",
      "       dex  of the layer. Layers are 0-indexed indices, with support for nega‐\n",
      "       tive indexing. i.e. 0 is the first layer, -1 is the last layer.\n",
      "\n",
      "       Let's say out of 3 layers that the image docker.io/library/nginx:1.17.8\n",
      "       is made up of, we only want to encrypt the 2nd layer,\n",
      "\n",
      "              skopeo  copy --encryption-key jwe:./public.key --encrypt-layer 1 oci:local_nginx:1.17.8 oci:try-encrypt:encrypted\n",
      "\n",
      "SEE ALSO\n",
      "       skopeo(1),  skopeo-login(1),  docker-login(1), containers-auth.json(5),\n",
      "       containers-policy.json(5), containers-transports(5),  containers-signa‐\n",
      "       ture(5)\n",
      "\n",
      "AUTHORS\n",
      "       Antonio  Murdaca runcom@redhat.com ⟨mailto:runcom@redhat.com⟩, Miloslav\n",
      "       Trmac mitr@redhat.com ⟨mailto:mitr@redhat.com⟩, Jhon Honce  jhonce@red‐\n",
      "       hat.com ⟨mailto:jhonce@redhat.com⟩\n",
      "\n",
      "                                                              skopeo-copy(1)()\n"
     ]
    }
   ],
   "source": [
    "man skopeo copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa71f78-6ff3-4525-b1b4-86b066e3004e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Container registries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba34f0-7094-4349-93ef-6c86b9fa0559",
   "metadata": {},
   "source": [
    "Images use the Linux `tar` utility to pack the `rootfs` and the JSON files together. These images are then stored on web servers called **container registries** (e.g., `docker.io`, `quay.io`, and `Artifactory`). **Container engines** like Podman can copy these images to a host and unpack them onto the filesystem. Then the engine merges \n",
    "- the image’s JSON file, \n",
    "- the engine’s built-in defaults, and \n",
    "- the user’s input \n",
    "\n",
    "to create a new container OCI runtime specification JSON file. The JSON file describes how to run the containerized application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361cd310-0c2a-4e35-aeb7-cf972ec12f23",
   "metadata": {},
   "source": [
    "### Container runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c99a57f-cd11-4cc7-bf7c-27cc8198322a",
   "metadata": {},
   "source": [
    "In the last step, the container engine launches a small program called a **container runtime** (e.g., `runc`, `crun`, `kata`, or `givisord`). The container runtime reads the \n",
    "- container’s JSON and instruments, \n",
    "- kernel cgroups, \n",
    "- security constraints, and \n",
    "- namespaces \n",
    "\n",
    "before finally launching the primary process of the container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca201f-06de-448d-ac99-71df79d2f983",
   "metadata": {},
   "source": [
    "### Container standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b40a9-a73d-41e3-a159-c447018b0110",
   "metadata": {},
   "source": [
    "The OCI standards body defined the standard formats for storing and defining container images. They also defined the standard for container engines running containers. The OCI created the OCI Image Format, which standardizes the format of the container images and the images’ JSON file. They also created the OCI Runtime Specification, which standardized the container’s JSON file to be used by OCI runtimes. The OCI standards allow other container engines, like Podman, to follow the standards and be able to work with all the images stored at container registries and to run them in the exact same way as all other container engines, including Docker (see figure 1.7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711051f-2fa0-470d-8dd5-ca0b0e5feed1",
   "metadata": {},
   "source": [
    "### Pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912f4de-8aad-42aa-8d63-22438ba675c8",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../data/images/Screenshot_20240114_010033.png\" alt=\"Figure 1.4 Physical machine running three applications in three VMs\" style=\"width: 450px\">\n",
    "    <p style=\"text-align: center\"><i>Figure 1.4 Physical machine running three applications in three VMs</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c83f3-8aad-4c9d-bdc4-cc082253cbd3",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../data/images/Screenshot_20240114_010239.png\" alt=\"Figure 1.5 Physical machine running three applications in three containerized applications\" style=\"width: 450px\">\n",
    "    <p style=\"text-align: center\"><i>Figure 1.5 Physical machine running three applications in three containerized applications</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5ef3a3-ebcc-44a3-afe1-5673ccd2fa7f",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../data/images/Screenshot_20240114_010402.png\" alt=\"Figure 1.6 Traditional LAMP stack (Linux, Apache, MariaDB, and PHP/PERL application) running on a server\" style=\"width: 450px\">\n",
    "    <p style=\"text-align: center\"><i>Figure 1.6 Traditional LAMP stack (Linux, Apache, MariaDB, and PHP/PERL application) running on a server</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024b405-9b50-49cc-b5bb-01796b89e3ff",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../data/images/Screenshot_20240114_005714.png\" alt=\"Figure 1.7 LAMP stack packaged individually into microservice containers. As containers communicate via the network, they can be easily moved to other VMs, making reuse much easier.\" style=\"width: 450px\">\n",
    "    <p style=\"text-align: center\"><i>Figure 1.7 LAMP stack packaged individually into microservice containers. As containers communicate via the network, they can be easily moved to other VMs, making reuse much easier.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c3cabd-478b-4a0b-b324-7679592b19ef",
   "metadata": {},
   "source": [
    "## 1.3 `Fork`/`exec` model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6795af-cf46-45fa-ba19-d609ec197bda",
   "metadata": {},
   "source": [
    "Docker is built as a REST API server. Fundamentally Docker is a client-server architecture including multiple daemons. When a user executes the Docker client, they execute a command-line tool that connects to the Docker daemon. The Docker daemon then pulls images to its storage and then connects to the containerd daemon, which finally executes an OCI runtime that creates the container. The Docker daemon, then, is a communication platform that communicates reads and writes of `stdin`, `stdout`, and `stderr` from the initial process (PID1) created in the container. The daemon relays all of the output back to the Docker client. Users imagine the container’s processes are just children of the current session, but there is a lot of communication going on behind the scenes. Figure 1.8 shows the Docker client-server architecture (also see [Container](../containers_nomenclature.ipynb#Container) from \"Containers Nomenclature\").\n",
    "\n",
    "The bottom line is the Docker client communicates with the Docker daemon, which then communicates with the containerd daemon, which finally launches an OCI runtime like runc to launch PID1 of the container. There is a lot of complexity involved in running containers in this way. Over the years, failures in any of the Daemons have led to all containers shutting down, and it is often difficult to diagnose what happened. The core Podman engineering team comes from an operating system background grounded in the Unix philosophy.\n",
    "\n",
    "Unix and C were designed with the **fork/exec model** of computing. Basically, when you execute a new program, a parent program like the Bash shell _forks_ a new process and then executes the new program as a child of the old program. The Podman engineering team thought they could make containers simpler by building a tool that pulls container images from a container registry, configures container storage, and then launches an OCI runtime, which starts the container as a child of your container engine.\n",
    "\n",
    "In the Unix operating system, processes can share content via the filesystem and inter-process communication (IPC) mechanisms. These features of the operating system enable multiple container engines to share storage without requiring a daemon to be running to control access and share content. The engines do not need to communicate together aside from using locking mechanisms provided by the operating system’s filesystems. Future chapters examine the advantages and disadvantages of this mechanism. Figure 1.9 shows the Podman architecture and communication flow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e4ff9a-47ca-4e4c-9a7f-fa169146d9f6",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <div style=\"display: flex; flex-direction: row\">\n",
    "        <div>\n",
    "            <img src=\"../data/images/Screenshot_20240114_015956.png\" alt=\"Figure 1.8 Docker client-server architecture. The container is a direct descendant of containerd, not the Docker client. The kernel sees no relationship between the client program and the container.\" style=\"width: 600px; padding: 5px;\">\n",
    "            <p style=\"text-align: center; padding-top: 0px\"><i>Figure 1.8 Docker client-server architecture. The container is a direct descendant of containerd, not the Docker client. The kernel sees no relationship between the client program and the container.<i></p>\n",
    "        </div>\n",
    "        <div>\n",
    "            <img src=\"../data/images/Screenshot_20240114_020023.png\" alt=\"Figure 1.9 Podman fork/exec architecture. The user launches Podman, which executes the OCI runtime, which then launches the container. The container is a direct descendant of Podman.\" style=\"width: 250px; padding: 5px;\">\n",
    "            <p style=\"text-align: center; padding-top: 0px\"><i>Figure 1.9 Podman fork/exec architecture. The user launches Podman, which executes the OCI runtime, which then launches the container. The container is a direct descendant of Podman.</i></p>\n",
    "        </div>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff64521-f422-440c-aa80-a4b320898757",
   "metadata": {},
   "source": [
    "Imagine you have a web service that you want to run at boot time. The web service is packaged in a container, so you need a container engine. In the Docker case, you need to set it up to be running on your machine with each of the daemons running and accepting connections. Next, launch the Docker client to start the web service. Now you have your containerized application running as well as all of the Docker daemons. In the Podman case, use the Podman command to launch your container, and Podman will go away. Your container will continue to run without the overhead of running the multiple daemons. Less overhead is incredibly popular on low-end machines like IOT devices and edge servers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b51d6a-add6-41d8-856a-f62ce7e8f324",
   "metadata": {},
   "source": [
    "## 1.3.7 Integration with systemd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb61138-1901-47e9-850c-872ee556bb86",
   "metadata": {},
   "source": [
    "Systemd is the fundamental init system in the operating systems. The init process on a Linux system is the first process that is started by the kernel on boot. Therefore, the init system is the ancestor of all processes and can monitor them all. Podman wants to fully integrate the running of containers with the init system. Users want to use systemd to start and stop containers at boot time. Containers should do the following:\n",
    "\n",
    "- Support systemd within a container\n",
    "- Support socket activation\n",
    "- Support systemd notifications that a containerized application is fully activated\n",
    "- Allow systemd to fully manage the cgroups and lifespan of a containerized application\n",
    "\n",
    "Basically, containers work as services in systemd unit files. Many developers want to run systemd within a container to run multiple system-defined services within a container.\n",
    "\n",
    "However, the upstream Docker community disagrees with this and has denied all pull requests that attempt to integrate systemd into Docker. They believe Docker should manage the life cycle of the container, and they do not want to accommodate users who want to run systemd in a container.\n",
    "\n",
    "The upstream Docker community believes the Docker daemon, as opposed to systemd, should be the controller of processes, it should manage the life cycle of containers, and it should start and stop them at boot time. The problem is there are many more features in systemd than in Docker, including startup ordering, socket activation, service ready notifications, and so on.\n",
    "\n",
    "When Podman was designed, the developers wanted to make sure it fully integrated with systemd. When you run systemd inside a container, Podman sets up the container the way systemd expects and allows it to simply run as PID1 of the container with limited privileges. Podman allows you to run services within the container the same way they run on a system or in a VM: via systemd unit files. Podman supports socket activation, service notifications, and many other systemd unit file features. Podman makes it simple to generate systemd unit files with best practices for running containers within a systemd service. For more information, see chapter 7 on systemd integration.\n",
    "\n",
    "The Containers project (https://github.com/containers) where Podman, container libraries, and other container management tools reside, wants to embrace all features of the operating system and fully integrate it. Chapter 7 explains Podman integration with systemd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944dab3-29e5-4dfa-ac4b-7840e106b59a",
   "metadata": {},
   "source": [
    "## 1.3.8 Pods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e12334c-8f37-4913-b7d2-b111641e07ef",
   "metadata": {},
   "source": [
    "One advantage of Podman is described in its name. As mentioned earlier, Podman is actually short for **Pod Manager**. As the official Kubernetes documentation puts it, \n",
    "\n",
    "> “A **pod** (as in a pod of seals, hence the logo, or pea pod) is a group of one or more containers, with shared storage/network resources, and a specification for how to run the containers.” \n",
    "\n",
    "Podman works with \n",
    "- either a single container at a time, like Docker, \n",
    "- or it can manage groups of containers together in a pod. \n",
    "\n",
    "One of the design goals of containers is \n",
    "\n",
    "> to separate services into single containers: **microservices**. Then you combine containers together to build larger services. \n",
    "\n",
    "Pods allow you to group multiple services together to form a larger service managed as a single entity. One of the goals of Podman is allowing you to experiment with pods. Figure 1.12 shows two pods running on a system, each pod containing three containers.\n",
    "\n",
    "Podman has the `podman generate kube` command, which allows you to generate Kubernetes YAML files from running containers and pods, as you can see in chapter 7. Similarly, it has the `podman play kube` command, which allows you to play Kubernetes YAML files and generate pods and containers on your host. \n",
    "\n",
    "> I suggest using Podman for running pods and containers on a single host and using Kubernetes to take your pods and containers and run them on multiple machines and all through your infrastructure. \n",
    "\n",
    "Other projects, like kind (https://kind.sigs.k8s.io/docs/user/rootless), are experimenting with running pods with Podman under the guidance of Kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971c0fc-3646-4860-a5cb-0d45dab8d136",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"../data/images/Screenshot_20240114_022123.png\" alt=\"Figure 1.12 Two pods running on a host. Each pod runs two different containers along with the infra container.\" style=\"width: 650px\">\n",
    "    <p style=\"text-align: center\"><i>Figure 1.12 Two pods running on a host. Each pod runs two different containers along with the infra container.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0935114-b14e-45e3-9c71-83dc4395a7e3",
   "metadata": {},
   "source": [
    "## 1.3.11 Complete customizability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4795dad5-331a-49f3-98a2-6311d36de53c",
   "metadata": {},
   "source": [
    "Container engines tend to have lots of built-in constants, like the namespaces they run with, whether or not SELinux is enabled, and which capabilities containers run with. With Docker, most of these values are hardcoded and cannot be changed by default. Podman, on the other hand, has a very customizable configuration.\n",
    "\n",
    "Podman has its built-in defaults but defines three locations for its configuration files to be stored:\n",
    "\n",
    "- `/usr/share/containers/containers.conf` — Where a distribution can define the changes the distribution likes to use\n",
    "- `/etc/containers/containers.conf` — Where they can set up system overrides\n",
    "- `$HOME/.config/containers/containers.conf` — Can be specified only in rootless mode\n",
    "\n",
    "The configuration files allow you to configure Podman to run the way you want by default. You can even run with more security by default if you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa9b260-e4b7-46f5-89e0-bd8f462952fe",
   "metadata": {},
   "source": [
    "## 1.3.12 User-namespace support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd620b33-2a51-44fe-90e3-8c2388bc918c",
   "metadata": {},
   "source": [
    "Podman is fully integrated with the user namespace. Rootless mode relies on user namespaces, which allows for multiple UIDs to be assigned to a user. User namespaces provide isolation between users on a system, so you can have multiple rootless users running containers with multiple user IDs, all isolated from each other.\n",
    "\n",
    "A user namespace can be used to isolate containers from each other. Podman makes it simple to launch multiple containers, each with a unique user namespace. The kernel then isolates the processes from host users as well as each other based on UID separation.\n",
    "\n",
    "Docker only supports running containers in a single, separate, user namespace, meaning all containers run within the same user namespace. Root in one container is the same as root in another container. It does not support running each container in a different user namespace, which means containers attack each other from a user-namespace perspective. Even though Docker supports this mode, almost no one runs containers with Docker in a separate user namespace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890ec78-e06f-43ce-aa3d-65245d82d0b7",
   "metadata": {},
   "source": [
    "# 2. <b>Command line</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965e5b6-1401-442d-87f4-375b60883c73",
   "metadata": {},
   "source": [
    "- The Podman command line\n",
    "- Running an OCI application\n",
    "- Comparing containers and images\n",
    "- Building an OCI-based image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0851960b-3ea4-44df-8ea7-038196821a84",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-17T21:43:35.004826Z",
     "iopub.status.busy": "2024-01-17T21:43:35.003266Z",
     "iopub.status.idle": "2024-01-17T21:43:35.661763Z",
     "shell.execute_reply": "2024-01-17T21:43:35.660468Z",
     "shell.execute_reply.started": "2024-01-17T21:43:35.004746Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "podman(1)                   General Commands Manual                  podman(1)\n",
      "\n",
      "NAME\n",
      "       podman - Simple management tool for pods, containers and images\n",
      "\n",
      "SYNOPSIS\n",
      "       podman [options] command\n",
      "\n",
      "DESCRIPTION\n",
      "       Podman  (Pod  Manager)  is  a fully featured container engine that is a\n",
      "       simple daemonless tool.  Podman provides a Docker-CLI  comparable  com‐\n",
      "       mand  line  that  eases the transition from other container engines and\n",
      "       allows the management of pods,  containers  and  images.   Simply  put:\n",
      "       alias  docker=podman.   Most  Podman  commands  can be run as a regular\n",
      "       user, without requiring additional privileges.\n",
      "\n",
      "       Podman uses Buildah(1) internally  to  create  container  images.  Both\n",
      "       tools share image (not container) storage, hence each can use or manip‐\n",
      "       ulate images (but not containers) created by the other.\n",
      "\n",
      "       Default settings for flags are defined in  containers.conf.  Most  set‐\n",
      "       tings  for  Remote connections use the server's containers.conf, except\n",
      "       when documented in man pages.\n",
      "\n",
      "       podman [GLOBAL OPTIONS]\n",
      "\n",
      "GLOBAL OPTIONS\n",
      "   --cgroup-manager=manager\n",
      "       The CGroup manager to use for container cgroups. Supported  values  are\n",
      "       cgroupfs  or  systemd. Default is systemd unless overridden in the con‐\n",
      "       tainers.conf file.\n",
      "\n",
      "       Note: Setting this flag can cause certain commands to break when called\n",
      "       on  containers  previously  created  by  the other CGroup manager type.\n",
      "       Note: CGroup manager is not  supported  in  rootless  mode  when  using\n",
      "       CGroups Version V1.\n",
      "\n",
      "   --conmon\n",
      "       Path  of  the  conmon  binary  (Default  path is configured in contain‐\n",
      "       ers.conf)\n",
      "\n",
      "   --connection, -c\n",
      "       Connection to use for remote podman, including Mac and Windows (exclud‐\n",
      "       ing  WSL2)  machines,  (Default  connection  is  configured in contain‐\n",
      "       ers.conf) Setting this option will switch the --remote option to  true.\n",
      "       Remote connections use local containers.conf for default.\n",
      "\n",
      "   --events-backend=type\n",
      "       Backend  to  use for storing events. Allowed values are file, journald,\n",
      "       and none. When file is specified, the  events  are  stored  under  <tm‐\n",
      "       pdir>/events/events.log (see --tmpdir below).\n",
      "\n",
      "   --help, -h\n",
      "       Print usage statement\n",
      "\n",
      "   --hooks-dir=path\n",
      "       Each  *.json  file in the path configures a hook for Podman containers.\n",
      "       For more details on the syntax of the JSON files and the  semantics  of\n",
      "       hook  injection, see oci-hooks(5).  Podman and libpod currently support\n",
      "       both the 1.0.0 and 0.1.0 hook schemas, although  the  0.1.0  schema  is\n",
      "       deprecated.\n",
      "\n",
      "       This  option  may  be set multiple times; paths from later options have\n",
      "       higher precedence (oci-hooks(5) discusses directory precedence).\n",
      "\n",
      "       For the annotation conditions, libpod uses any annotations set  in  the\n",
      "       generated OCI configuration.\n",
      "\n",
      "       For  the bind-mount conditions, only mounts explicitly requested by the\n",
      "       caller via --volume are considered.  Bind mounts that libpod inserts by\n",
      "       default (e.g. /dev/shm) are not considered.\n",
      "\n",
      "       If  --hooks-dir  is unset for root callers, Podman and libpod will cur‐\n",
      "       rently default to /usr/share/containers/oci/hooks.d  and  /etc/contain‐\n",
      "       ers/oci/hooks.d  in  order  of  increasing precedence.  Using these de‐\n",
      "       faults is deprecated, and callers should migrate to explicitly  setting\n",
      "       --hooks-dir.\n",
      "\n",
      "       Podman and libpod currently support an additional precreate state which\n",
      "       is called before the runtime's  create  operation.   Unlike  the  other\n",
      "       stages,  which  receive  the  container  state on their standard input,\n",
      "       precreate hooks receive the proposed  runtime  configuration  on  their\n",
      "       standard input.  They may alter that configuration as they see fit, and\n",
      "       write the altered form to their standard output.\n",
      "\n",
      "       WARNING: the precreate hook lets you do powerful things, such as adding\n",
      "       additional  mounts to the runtime configuration.  That power also makes\n",
      "       it easy to break things.  Before reporting libpod errors,  try  running\n",
      "       your  container  with precreate hooks disabled to see if the problem is\n",
      "       due to one of your hooks.\n",
      "\n",
      "   --identity=path\n",
      "       Path to ssh identity file. If the identity  file  has  been  encrypted,\n",
      "       podman  prompts  the  user  for the passphrase.  If no identity file is\n",
      "       provided and no user is given, podman defaults to the user running  the\n",
      "       podman  command.   Podman  prompts for the login password on the remote\n",
      "       server.\n",
      "\n",
      "       Identity value resolution precedence:\n",
      "        - command line value\n",
      "        - environment variable CONTAINER_SSHKEY, if CONTAINER_HOST is found\n",
      "        - containers.conf Remote connections use local containers.conf for de‐\n",
      "       fault.\n",
      "\n",
      "   --log-level=level\n",
      "       Log  messages  at  and above specified level: debug, info, warn, error,\n",
      "       fatal or panic (default: \"warn\")\n",
      "\n",
      "   --namespace=namespace\n",
      "       Set libpod namespace. Namespaces are used to separate  groups  of  con‐\n",
      "       tainers  and  pods  in  libpod's state.  When namespace is set, created\n",
      "       containers and pods will join the given namespace, and only  containers\n",
      "       and pods in the given namespace will be visible to Podman.\n",
      "\n",
      "   --network-cmd-path=path\n",
      "       Path to the command binary to use for setting up a network.  It is cur‐\n",
      "       rently only used for setting up a slirp4netns network.  If \"\"  is  used\n",
      "       then the binary is looked up using the $PATH environment variable.\n",
      "\n",
      "   --network-config-dir=directory\n",
      "       Path  to  the  directory where network configuration files are located.\n",
      "       For the CNI  backend  the  default  is  \"/etc/cni/net.d\"  as  root  and\n",
      "       \"$HOME/.config/cni/net.d\"   as  rootless.   For  the  netavark  backend\n",
      "       \"/etc/containers/networks\" is used as root and \"$graphroot/networks\" as\n",
      "       rootless.\n",
      "\n",
      "   --noout\n",
      "       Redirect stdout to /dev/null. This command will prevent all stdout from\n",
      "       the Podman command. The --noout  option will not block stderr or stdout\n",
      "       from containers.\n",
      "\n",
      "   --remote, -r\n",
      "       When  true,  access  to  the Podman service will be remote. Defaults to\n",
      "       false.  Settings can be modified in the containers.conf  file.  If  the\n",
      "       CONTAINER_HOST  environment  variable  is  set, the --remote option de‐\n",
      "       faults to true.\n",
      "\n",
      "   --root=value\n",
      "       Storage root dir in which data, including images, is  stored  (default:\n",
      "       \"/var/lib/containers/storage\"  for  UID 0, \"$HOME/.local/share/contain‐\n",
      "       ers/storage\"  for  other  users).   Default  root  dir  configured   in\n",
      "       /etc/containers/storage.conf.\n",
      "\n",
      "       Overriding this option will cause the storage-opt settings in /etc/con‐\n",
      "       tainers/storage.conf to be ignored.  The user must  specify  additional\n",
      "       options via the --storage-opt flag.\n",
      "\n",
      "   --runroot=value\n",
      "       Storage state directory where all state information is stored (default:\n",
      "       \"/run/containers/storage\" for UID  0,  \"/run/user/$UID/run\"  for  other\n",
      "       users).  Default state dir configured in /etc/containers/storage.conf.\n",
      "\n",
      "   --runtime=value\n",
      "       Name  of  the  OCI  runtime as specified in containers.conf or absolute\n",
      "       path to the OCI compatible binary used to run containers.\n",
      "\n",
      "   --runtime-flag=flag\n",
      "       Adds global flags for the container  runtime.  To  list  the  supported\n",
      "       flags,  please  consult  the manpages of the selected container runtime\n",
      "       (runc is the default runtime, the manpage to consult is runc(8).   When\n",
      "       the  machine  is configured for cgroup V2, the default runtime is crun,\n",
      "       the manpage to consult is crun(8).).\n",
      "\n",
      "       Note: Do not pass the leading -- to the flag. To  pass  the  runc  flag\n",
      "       --log-format json to podman build, the option given would be --runtime-\n",
      "       flag log-format=json.\n",
      "\n",
      "   --ssh=value\n",
      "       This option allows the user to change the ssh mode, meaning that rather\n",
      "       than using the default golang mode, one can instead use --ssh=native to\n",
      "       use the installed ssh binary  and  config  file  declared  in  contain‐\n",
      "       ers.conf.\n",
      "\n",
      "   --storage-driver=value\n",
      "       Storage  driver.  The default storage driver for UID 0 is configured in\n",
      "       /etc/containers/storage.conf ($HOME/.config/containers/storage.conf  in\n",
      "       rootless  mode),  and  is vfs for non-root users when fuse-overlayfs is\n",
      "       not available.  The STORAGE_DRIVER environment variable  overrides  the\n",
      "       default.  The --storage-driver specified driver overrides all.\n",
      "\n",
      "       Overriding this option will cause the storage-opt settings in /etc/con‐\n",
      "       tainers/storage.conf to be ignored.  The user must  specify  additional\n",
      "       options via the --storage-opt flag.\n",
      "\n",
      "   --storage-opt=value\n",
      "       Storage driver option, Default storage driver options are configured in\n",
      "       /etc/containers/storage.conf ($HOME/.config/containers/storage.conf  in\n",
      "       rootless mode). The STORAGE_OPTS environment variable overrides the de‐\n",
      "       fault. The --storage-opt specified options overrides all. If you  spec‐\n",
      "       ify --storage-opt=\"\", no storage options will be used.\n",
      "\n",
      "   --syslog\n",
      "       Output  logging  information  to syslog as well as the console (default\n",
      "       false).\n",
      "\n",
      "       On remote clients, including Mac and Windows (excluding WSL2) machines,\n",
      "       logging is directed to the file $HOME/.config/containers/podman.log.\n",
      "\n",
      "   --tmpdir\n",
      "       Path  to  the  tmp  directory,  for libpod runtime content. Defaults to\n",
      "       $XDG\\_RUNTIME\\_DIR/libpod/tmp as rootless and run/libpod/tmp  as  root‐\n",
      "       ful.\n",
      "\n",
      "       NOTE  --tmpdir  is not used for the temporary storage of downloaded im‐\n",
      "       ages.  Use the environment variable  TMPDIR  to  change  the  temporary\n",
      "       storage location of downloaded container images. Podman defaults to use\n",
      "       /var/tmp.\n",
      "\n",
      "   --url=value\n",
      "       URL to access Podman service (default  from  containers.conf,  rootless\n",
      "       unix://run/user/$UID/podman/podman.sock   or  as  root  unix://run/pod‐\n",
      "       man/podman.sock).  Setting this option will switch the --remote  option\n",
      "       to true.\n",
      "\n",
      "              • CONTAINER_HOST  is  of  the  format  <schema>://[<user[:<pass‐\n",
      "                word>]@]<host>[:<port>][<path>]\n",
      "\n",
      "       Details:\n",
      "        - schema is one of:\n",
      "          * ssh (default): a local unix(7) socket on the named host and  port,\n",
      "       reachable via SSH\n",
      "          *  tcp:  an unencrypted, unauthenticated TCP connection to the named\n",
      "       host and port\n",
      "          * unix: a local unix(7) socket at the specified path, or the default\n",
      "       for the user\n",
      "        -  user  will  default to either root or the current running user (ssh\n",
      "       only)\n",
      "        - password has no default (ssh only)\n",
      "        - host must be provided and is either the IP or name  of  the  machine\n",
      "       hosting the Podman service (ssh and tcp)\n",
      "        - port defaults to 22 (ssh and tcp)\n",
      "        -    path    defaults    to    either    /run/podman/podman.sock,   or\n",
      "       /run/user/$UID/podman/podman.sock if running rootless (unix),  or  must\n",
      "       be explicitly specified (ssh)\n",
      "\n",
      "       URL value resolution precedence:\n",
      "        - command line value\n",
      "        - environment variable CONTAINER_HOST\n",
      "        - containers.conf service_destinations table\n",
      "        - unix://run/podman/podman.sock\n",
      "\n",
      "       Remote connections use local containers.conf for default.\n",
      "\n",
      "       Some example URL values in valid formats:\n",
      "        - unix://run/podman/podman.sock\n",
      "        - unix://run/user/$UID/podman/podman.sock\n",
      "        - ssh://notroot@localhost:22/run/user/$UID/podman/podman.sock\n",
      "        - ssh://root@localhost:22/run/podman/podman.sock\n",
      "        - tcp://localhost:34451\n",
      "        - tcp://127.0.0.1:34451\n",
      "\n",
      "   --version, -v\n",
      "       Print the version\n",
      "\n",
      "   --volumepath=value\n",
      "       Volume  directory  where builtin volume information is stored (default:\n",
      "       \"/var/lib/containers/storage/volumes\"   for    UID    0,    \"$HOME/.lo‐\n",
      "       cal/share/containers/storage/volumes\"  for other users). Default volume\n",
      "       path can be overridden in containers.conf.\n",
      "\n",
      "Environment Variables\n",
      "       Podman can set up environment variables from env of [engine]  table  in\n",
      "       containers.conf. These variables can be overridden by passing  environ‐\n",
      "       ment variables before the podman commands.\n",
      "\n",
      "   CONTAINERS_CONF\n",
      "       Set default locations of containers.conf file\n",
      "\n",
      "   CONTAINERS_REGISTRIES_CONF\n",
      "       Set default location of the registries.conf file.\n",
      "\n",
      "   CONTAINERS_STORAGE_CONF\n",
      "       Set default location of the storage.conf file.\n",
      "\n",
      "   CONTAINER_CONNECTION\n",
      "       Override default --connection value to access Podman service. Also  en‐\n",
      "       abled --remote option.\n",
      "\n",
      "   CONTAINER_HOST\n",
      "       Set default --url value to access Podman service. Also enabled --remote\n",
      "       option.\n",
      "\n",
      "   CONTAINER_SSHKEY\n",
      "       Set default --identity path to ssh key file value used to access Podman\n",
      "       service.\n",
      "\n",
      "   STORAGE_DRIVER\n",
      "       Set default --storage-driver value.\n",
      "\n",
      "   STORAGE_OPTS\n",
      "       Set default --storage-opts value.\n",
      "\n",
      "   TMPDIR\n",
      "       Set the temporary storage location of downloaded container images. Pod‐\n",
      "       man defaults to use /var/tmp.\n",
      "\n",
      "   XDG_CONFIG_HOME\n",
      "       In Rootless mode configuration files are read from XDG_CONFIG_HOME when\n",
      "       specified,   otherwise   in  the  home  directory  of  the  user  under\n",
      "       $HOME/.config/containers.\n",
      "\n",
      "   XDG_DATA_HOME\n",
      "       In Rootless mode images are pulled under XDG_DATA_HOME when  specified,\n",
      "       otherwise   in   the  home  directory  of  the  user  under  $HOME/.lo‐\n",
      "       cal/share/containers/storage.\n",
      "\n",
      "   XDG_RUNTIME_DIR\n",
      "       In Rootless mode temporary configuration data is stored  in  ${XDG_RUN‐\n",
      "       TIME_DIR}/containers.\n",
      "\n",
      "Remote Access\n",
      "       The  Podman command can be used with remote services using the --remote\n",
      "       flag. Connections can be made using local unix domain sockets,  ssh  or\n",
      "       directly to tcp sockets. When specifying the podman --remote flag, only\n",
      "       the global options --url,  --identity,  --log-level,  --connection  are\n",
      "       used.\n",
      "\n",
      "       Connection  information  can  also be managed using the containers.conf\n",
      "       file.\n",
      "\n",
      "Exit Codes\n",
      "       The exit code from podman gives information  about  why  the  container\n",
      "       failed  to run or why it exited.  When podman commands exit with a non-\n",
      "       zero code, the exit codes follow the chroot standard, see below:\n",
      "\n",
      "       125 The error is with podman itself\n",
      "\n",
      "              $ podman run --foo busybox; echo $?\n",
      "              Error: unknown flag: --foo\n",
      "              125\n",
      "\n",
      "       126 Executing a contained command and the command cannot be invoked\n",
      "\n",
      "              $ podman run busybox /etc; echo $?\n",
      "              Error: container_linux.go:346: starting container process caused \"exec: \\\"/etc\\\": permission denied\": OCI runtime error\n",
      "              126\n",
      "\n",
      "       127 Executing a contained command and the command cannot be found\n",
      "           $ podman run busybox foo; echo $?\n",
      "           Error: container_linux.go:346: starting  container  process  caused\n",
      "       \"exec: \\\"foo\\\": executable file not found in $PATH\": OCI runtime error\n",
      "           127\n",
      "\n",
      "       Exit code contained command exit code\n",
      "\n",
      "              $ podman run busybox /bin/sh -c 'exit 3'; echo $?\n",
      "              3\n",
      "\n",
      "COMMANDS\n",
      "       ┌──────────────────────┬────────────────────────────────┐\n",
      "       │Command               │ Description                    │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-attach(1)      │ Attach to a running container. │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-auto-update(1) │ Auto update containers accord‐ │\n",
      "       │                      │ ing to their auto-update  pol‐ │\n",
      "       │                      │ icy                            │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-build(1)       │ Build  a container image using │\n",
      "       │                      │ a Containerfile.               │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-commit(1)      │ Create new image based on  the │\n",
      "       │                      │ changed container.             │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-completion(1)  │ Generate    shell   completion │\n",
      "       │                      │ scripts                        │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-container(1)   │ Manage containers.             │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-cp(1)          │ Copy files/folders  between  a │\n",
      "       │                      │ container    and   the   local │\n",
      "       │                      │ filesystem.                    │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-create(1)      │ Create a new container.        │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-diff(1)        │ Inspect changes on a container │\n",
      "       │                      │ or image's filesystem.         │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-events(1)      │ Monitor Podman events          │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-exec(1)        │ Execute a command in a running │\n",
      "       │                      │ container.                     │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-export(1)      │ Export a container's  filesys‐ │\n",
      "       │                      │ tem contents as a tar archive. │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-generate(1)    │ Generate structured data based │\n",
      "       │                      │ on containers,  pods  or  vol‐ │\n",
      "       │                      │ umes.                          │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-healthcheck(1) │ Manage  healthchecks  for con‐ │\n",
      "       │                      │ tainers                        │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-history(1)     │ Show the history of an image.  │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-image(1)       │ Manage images.                 │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-images(1)      │ List images in local storage.  │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-import(1)      │ Import a tarball and  save  it │\n",
      "       │                      │ as a filesystem image.         │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-info(1)        │ Displays Podman related system │\n",
      "       │                      │ information.                   │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-init(1)        │ Initialize one  or  more  con‐ │\n",
      "       │                      │ tainers                        │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-inspect(1)     │ Display  a  container,  image, │\n",
      "       │                      │ volume, network, or pod's con‐ │\n",
      "       │                      │ figuration.                    │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-kill(1)        │ Kill  the  main process in one │\n",
      "       │                      │ or more containers.            │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-load(1)        │ Load image(s) from a  tar  ar‐ │\n",
      "       │                      │ chive into container storage.  │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-login(1)       │ Login to a container registry. │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-logout(1)      │ Logout  of  a  container  reg‐ │\n",
      "       │                      │ istry.                         │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-logs(1)        │ Display the  logs  of  one  or │\n",
      "       │                      │ more containers.               │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-machine(1)     │ Manage  Podman's  virtual  ma‐ │\n",
      "       │                      │ chine                          │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-manifest(1)    │ Create and manipulate manifest │\n",
      "       │                      │ lists and image indexes.       │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-mount(1)       │ Mount  a  working  container's │\n",
      "       │                      │ root filesystem.               │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-network(1)     │ Manage Podman networks.        │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-pause(1)       │ Pause one or more containers.  │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-kube(1)        │ Play containers, pods or  vol‐ │\n",
      "       │                      │ umes based on a structured in‐ │\n",
      "       │                      │ put file.                      │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-pod(1)         │ Management tool for groups  of │\n",
      "       │                      │ containers, called pods.       │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-port(1)        │ List  port mappings for a con‐ │\n",
      "       │                      │ tainer.                        │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-ps(1)          │ Prints out  information  about │\n",
      "       │                      │ containers.                    │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-pull(1)        │ Pull an image from a registry. │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-push(1)        │ Push  an  image, manifest list │\n",
      "       │                      │ or  image  index  from   local │\n",
      "       │                      │ storage to elsewhere.          │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-rename(1)      │ Rename an existing container.  │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-restart(1)     │ Restart  one  or more contain‐ │\n",
      "       │                      │ ers.                           │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-rm(1)          │ Remove one or more containers. │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-rmi(1)         │ Removes one  or  more  locally │\n",
      "       │                      │ stored images.                 │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-run(1)         │ Run  a  command  in a new con‐ │\n",
      "       │                      │ tainer.                        │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-save(1)        │ Save image(s) to an archive.   │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-search(1)      │ Search a registry for  an  im‐ │\n",
      "       │                      │ age.                           │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-secret(1)      │ Manage podman secrets.         │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-start(1)       │ Start one or more containers.  │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-stats(1)       │ Display  a  live stream of one │\n",
      "       │                      │ or more  container's  resource │\n",
      "       │                      │ usage statistics.              │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-stop(1)        │ Stop  one or more running con‐ │\n",
      "       │                      │ tainers.                       │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-system(1)      │ Manage podman.                 │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-tag(1)         │ Add an additional  name  to  a │\n",
      "       │                      │ local image.                   │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-top(1)         │ Display  the running processes │\n",
      "       │                      │ of a container.                │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-unmount(1)     │ Unmount a working  container's │\n",
      "       │                      │ root filesystem.               │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-unpause(1)     │ Unpause  one  or more contain‐ │\n",
      "       │                      │ ers.                           │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-unshare(1)     │ Run a command inside of a mod‐ │\n",
      "       │                      │ ified user namespace.          │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-untag(1)       │ Removes one or more names from │\n",
      "       │                      │ a locally-stored image.        │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-update(1)      │ Updates the cgroup  configura‐ │\n",
      "       │                      │ tion of a given container.     │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-version(1)     │ Display the Podman version in‐ │\n",
      "       │                      │ formation.                     │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-volume(1)      │ Simple  management  tool   for │\n",
      "       │                      │ volumes.                       │\n",
      "       ├──────────────────────┼────────────────────────────────┤\n",
      "       │podman-wait(1)        │ Wait on one or more containers │\n",
      "       │                      │ to stop and print  their  exit │\n",
      "       │                      │ codes.                         │\n",
      "       └──────────────────────┴────────────────────────────────┘\n",
      "\n",
      "CONFIGURATION FILES\n",
      "       containers.conf  (/usr/share/containers/containers.conf,  /etc/contain‐\n",
      "       ers/containers.conf, $HOME/.config/containers/containers.conf)\n",
      "\n",
      "       Podman has builtin defaults for command line  options.  These  defaults\n",
      "       can be overridden using the containers.conf configuration files.\n",
      "\n",
      "       Distributions  ship the /usr/share/containers/containers.conf file with\n",
      "       their default settings. Administrators can override fields in this file\n",
      "       by  creating  the /etc/containers/containers.conf file.  Users can fur‐\n",
      "       ther modify defaults by creating the  $HOME/.config/containers/contain‐\n",
      "       ers.conf  file.  Podman  merges its builtin defaults with the specified\n",
      "       fields from these files, if they exist. Fields specified in  the  users\n",
      "       file  override  the administrator's file, which overrides the distribu‐\n",
      "       tion's file, which override the built-in defaults.\n",
      "\n",
      "       Podman uses builtin defaults if no containers.conf file is found.\n",
      "\n",
      "       If the CONTAINERS_CONF environment variable is set, then its  value  is\n",
      "       used for the containers.conf file rather than the default.\n",
      "\n",
      "       mounts.conf (/usr/share/containers/mounts.conf)\n",
      "\n",
      "       The  mounts.conf file specifies volume mount directories that are auto‐\n",
      "       matically mounted inside containers when executing the  podman  run  or\n",
      "       podman start commands. Administrators can override the defaults file by\n",
      "       creating /etc/containers/mounts.conf.\n",
      "\n",
      "       When Podman runs in  rootless  mode,  the  file  $HOME/.config/contain‐\n",
      "       ers/mounts.conf will override the default if it exists. Please refer to\n",
      "       containers-mounts.conf(5) for further details.\n",
      "\n",
      "       policy.json (/etc/containers/policy.json)\n",
      "\n",
      "       Signature verification policy files are used to  specify  policy,  e.g.\n",
      "       trusted  keys,  applicable when deciding whether to accept an image, or\n",
      "       individual signatures of that image, as valid.\n",
      "\n",
      "       registries.conf  (/etc/containers/registries.conf,   $HOME/.config/con‐\n",
      "       tainers/registries.conf)\n",
      "\n",
      "       registries.conf  is  the  configuration file which specifies which con‐\n",
      "       tainer registries should be consulted when completing image names which\n",
      "       do not include a registry or domain portion.\n",
      "\n",
      "       Non  root  users of Podman can create the $HOME/.config/containers/reg‐\n",
      "       istries.conf file to be used instead of the system defaults.\n",
      "\n",
      "       If the CONTAINERS_REGISTRIES_CONF environment variable is set, then its\n",
      "       value is used for the registries.conf file rather than the default.\n",
      "\n",
      "       storage.conf    (/etc/containers/storage.conf,   $HOME/.config/contain‐\n",
      "       ers/storage.conf)\n",
      "\n",
      "       storage.conf is the storage configuration file for all tools using con‐\n",
      "       tainers/storage\n",
      "\n",
      "       The storage configuration file specifies all of the available container\n",
      "       storage options for tools using shared container storage.\n",
      "\n",
      "       When Podman runs in  rootless  mode,  the  file  $HOME/.config/contain‐\n",
      "       ers/storage.conf is used instead of the system defaults.\n",
      "\n",
      "       If  the  CONTAINERS_STORAGE_CONF  environment variable is set, then its\n",
      "       value is used for the storage.conf file rather than the default.\n",
      "\n",
      "Rootless mode\n",
      "       Podman can also be used as non-root user. When podman runs in  rootless\n",
      "       mode,  a  user namespace is automatically created for the user, defined\n",
      "       in /etc/subuid and /etc/subgid.\n",
      "\n",
      "       Containers created by a non-root user are not visible  to  other  users\n",
      "       and are not seen or managed by Podman running as root.\n",
      "\n",
      "       It  is required to have multiple uids/gids set for a user.  Be sure the\n",
      "       user is present in the files /etc/subuid and /etc/subgid.\n",
      "\n",
      "       If you have a recent version of usermod, you can execute the  following\n",
      "       commands to add the ranges to the files\n",
      "\n",
      "              $ sudo usermod --add-subuids 10000-75535 USERNAME\n",
      "              $ sudo usermod --add-subgids 10000-75535 USERNAME\n",
      "\n",
      "       Or just add the content manually.\n",
      "\n",
      "              $ echo USERNAME:10000:65536 >> /etc/subuid\n",
      "              $ echo USERNAME:10000:65536 >> /etc/subgid\n",
      "\n",
      "       See the subuid(5) and subgid(5) man pages for more information.\n",
      "\n",
      "       Images  are pulled under XDG_DATA_HOME when specified, otherwise in the\n",
      "       home directory of the user under .local/share/containers/storage.\n",
      "\n",
      "       Currently the slirp4netns package is required to be installed to create\n",
      "       a network device, otherwise rootless containers need to run in the net‐\n",
      "       work namespace of the host.\n",
      "\n",
      "       In certain environments like HPC (High  Performance  Computing),  users\n",
      "       cannot  take  advantage  of  the  additional  UIDs  and  GIDs  from the\n",
      "       /etc/subuid and /etc/subgid systems.   However,  in  this  environment,\n",
      "       rootless  Podman can operate with a single UID.  To make this work, set\n",
      "       the ignore_chown_errors option in the  /etc/containers/storage.conf  or\n",
      "       in  ~/.config/containers/storage.conf  files.  This option tells Podman\n",
      "       when pulling an image to ignore chown errors when attempting to  change\n",
      "       a  file  in  a  container image to match the non-root UID in the image.\n",
      "       This means all files get saved as the user's UID. Note this could cause\n",
      "       issues when running the container.\n",
      "\n",
      "   NOTE: Unsupported file systems in rootless mode\n",
      "       The Overlay file system (OverlayFS) is not supported with kernels prior\n",
      "       to 5.12.9 in rootless mode.  The fuse-overlayfs package is a tool  that\n",
      "       provides  the  functionality of OverlayFS in user namespace that allows\n",
      "       mounting file systems in rootless environments.  It is  recommended  to\n",
      "       install  the fuse-overlayfs package.  In rootless mode, Podman will au‐\n",
      "       tomatically use the fuse-overlayfs program as the mount_program if  in‐\n",
      "       stalled,  as long as the $HOME/.config/containers/storage.conf file was\n",
      "       not previously created.  If storage.conf exists  in  the  homedir,  add\n",
      "       mount_program  = \"/usr/bin/fuse-overlayfs\" under [storage.options.over‐\n",
      "       lay] to enable this feature.\n",
      "\n",
      "       The Network File System (NFS) and other distributed file  systems  (for\n",
      "       example:  Lustre,  Spectrum  Scale,  the  General  Parallel File System\n",
      "       (GPFS)) are not supported when running in rootless mode as  these  file\n",
      "       systems do not understand user namespace.  However, rootless Podman can\n",
      "       make use of an NFS  Homedir  by  modifying  the  $HOME/.config/contain‐\n",
      "       ers/storage.conf  to  have  the  graphroot  option point to a directory\n",
      "       stored on local (Non NFS) storage.\n",
      "\n",
      "       For more information, please refer to the Podman Troubleshooting Page.\n",
      "\n",
      "SEE ALSO\n",
      "       containers-mounts.conf(5),     containers.conf(5),      containers-reg‐\n",
      "       istries.conf(5),  containers-storage.conf(5), buildah(1), oci-hooks(5),\n",
      "       containers-policy.json(5),  crun(1),  runc(8),  subuid(5),   subgid(5),\n",
      "       slirp4netns(1), conmon(8)\n",
      "\n",
      "HISTORY\n",
      "       Dec   2016,   Originally   compiled   by  Dan  Walsh  dwalsh@redhat.com\n",
      "       ⟨mailto:dwalsh@redhat.com⟩\n",
      "\n",
      "                                                                     podman(1)\n"
     ]
    }
   ],
   "source": [
    "man podman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed7c69e-db1a-4f57-ae4f-3043ee8b2456",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-17T21:44:04.175935Z",
     "iopub.status.busy": "2024-01-17T21:44:04.175271Z",
     "iopub.status.idle": "2024-01-17T21:44:04.384566Z",
     "shell.execute_reply": "2024-01-17T21:44:04.380273Z",
     "shell.execute_reply.started": "2024-01-17T21:44:04.175876Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manage pods, containers and images\n",
      "\n",
      "Usage:\n",
      "  podman [options] [command]\n",
      "\n",
      "Available Commands:\n",
      "  attach      Attach to a running container\n",
      "  auto-update Auto update containers according to their auto-update policy\n",
      "  build       Build an image using instructions from Containerfiles\n",
      "  commit      Create new image based on the changed container\n",
      "  container   Manage containers\n",
      "  cp          Copy files/folders between a container and the local filesystem\n",
      "  create      Create but do not start a container\n",
      "  diff        Display the changes to the object's file system\n",
      "  events      Show podman events\n",
      "  exec        Run a process in a running container\n",
      "  export      Export container's filesystem contents as a tar archive\n",
      "  generate    Generate structured data based on containers, pods or volumes\n",
      "  healthcheck Manage health checks on containers\n",
      "  help        Help about any command\n",
      "  history     Show history of a specified image\n",
      "  image       Manage images\n",
      "  images      List images in local storage\n",
      "  import      Import a tarball to create a filesystem image\n",
      "  info        Display podman system information\n",
      "  init        Initialize one or more containers\n",
      "  inspect     Display the configuration of object denoted by ID\n",
      "  kill        Kill one or more running containers with a specific signal\n",
      "  kube        Play containers, pods or volumes from a structured file\n",
      "  load        Load image(s) from a tar archive\n",
      "  login       Login to a container registry\n",
      "  logout      Logout of a container registry\n",
      "  logs        Fetch the logs of one or more containers\n",
      "  machine     Manage a virtual machine\n",
      "  manifest    Manipulate manifest lists and image indexes\n",
      "  mount       Mount a working container's root filesystem\n",
      "  network     Manage networks\n",
      "  pause       Pause all the processes in one or more containers\n",
      "  pod         Manage pods\n",
      "  port        List port mappings or a specific mapping for the container\n",
      "  ps          List containers\n",
      "  pull        Pull an image from a registry\n",
      "  push        Push an image to a specified destination\n",
      "  rename      Rename an existing container\n",
      "  restart     Restart one or more containers\n",
      "  rm          Remove one or more containers\n",
      "  rmi         Removes one or more images from local storage\n",
      "  run         Run a command in a new container\n",
      "  save        Save image(s) to an archive\n",
      "  search      Search registry for image\n",
      "  secret      Manage secrets\n",
      "  start       Start one or more containers\n",
      "  stats       Display a live stream of container resource usage statistics\n",
      "  stop        Stop one or more containers\n",
      "  system      Manage podman\n",
      "  tag         Add an additional name to a local image\n",
      "  top         Display the running processes of a container\n",
      "  unmount     Unmounts working container's root filesystem\n",
      "  unpause     Unpause the processes in one or more containers\n",
      "  unshare     Run a command in a modified user namespace\n",
      "  untag       Remove a name from a local image\n",
      "  update      update an existing container\n",
      "  version     Display the Podman version information\n",
      "  volume      Manage volumes\n",
      "  wait        Block on one or more containers\n",
      "\n",
      "Options:\n",
      "      --cgroup-manager string       Cgroup manager to use (\"cgroupfs\"|\"systemd\") (default \"systemd\")\n",
      "      --conmon string               Path of the conmon binary\n",
      "  -c, --connection string           Connection to use for remote Podman service\n",
      "      --events-backend string       Events backend to use (\"file\"|\"journald\"|\"none\") (default \"journald\")\n",
      "      --help                        Help for podman\n",
      "      --hooks-dir strings           Set the OCI hooks directory path (may be set multiple times) (default [/usr/share/containers/oci/hooks.d])\n",
      "      --identity string             path to SSH identity file, (CONTAINER_SSHKEY)\n",
      "      --log-level string            Log messages above specified level (trace, debug, info, warn, warning, error, fatal, panic) (default \"warn\")\n",
      "      --namespace string            Set the libpod namespace, used to create separate views of the containers and pods on the system\n",
      "      --network-cmd-path string     Path to the command for configuring the network\n",
      "      --network-config-dir string   Path of the configuration directory for networks\n",
      "      --noout                       do not output to stdout\n",
      "  -r, --remote                      Access remote Podman service\n",
      "      --root string                 Path to the root directory in which data, including images, is stored\n",
      "      --runroot string              Path to the 'run directory' where all state information is stored\n",
      "      --runtime string              Path to the OCI-compatible binary used to run containers. (default \"crun\")\n",
      "      --runtime-flag stringArray    add global flags for the container runtime\n",
      "      --ssh string                  define the ssh mode (default \"golang\")\n",
      "      --storage-driver string       Select which storage driver is used to manage storage of images and containers\n",
      "      --storage-opt stringArray     Used to pass an option to the storage driver\n",
      "      --syslog                      Output logging information to syslog as well as the console (default false)\n",
      "      --tmpdir string               Path to the tmp directory for libpod state content.\n",
      "                                    \n",
      "                                    Note: use the environment variable 'TMPDIR' to change the temporary storage location for container images, '/var/tmp'.\n",
      "                                    \n",
      "      --url string                  URL to access Podman service (CONTAINER_HOST) (default \"unix:/run/user/1000/podman/podman.sock\")\n",
      "  -v, --version                     version for podman\n",
      "      --volumepath string           Path to the volume directory in which volume data is stored\n"
     ]
    }
   ],
   "source": [
    "podman --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3d3bc-f194-4b0d-bdb3-a994b1361f38",
   "metadata": {},
   "source": [
    "## 2.1 Working with containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dba7ba-ad60-488c-bd75-fa5f67c937b8",
   "metadata": {},
   "source": [
    "Developers, administrators, quality engineers, and general users primarily use the `podman run` command to pull down and run, test, or explore these container images. To start building out containerized applications, the first thing you need to do is start working with a **base image**. In our examples, you pull and run the [registry.access.redhat.com/ubi8/httpd-24](registry.access.redhat.com/ubi8/httpd-24) image to container storage in your home directory and start exploring inside the container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39ad00-fd21-4801-8281-5a46e3b1fe44",
   "metadata": {},
   "source": [
    "### Exploring containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42134f8-da50-4e36-ab64-5415c02b1449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T19:38:37.728921Z",
     "iopub.status.busy": "2024-01-15T19:38:37.727236Z",
     "iopub.status.idle": "2024-01-15T19:39:04.977669Z",
     "shell.execute_reply": "2024-01-15T19:39:04.975980Z",
     "shell.execute_reply.started": "2024-01-15T19:38:37.728835Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "```sh\n",
    "podman run -ti --rm registry.access.redhat.com/ubi8/httpd-24 bash\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1f42be-d44d-436e-a066-3043c1984bbf",
   "metadata": {},
   "source": [
    "By default the podman run command executes the containerized command in the foreground until the container exits. In this case, you end up at a Bash prompt running within the container and showing the bash-4.4$ prompt. When you exit this Bash prompt, Podman stops the container.\n",
    "\n",
    "- You used two options: `-t` and `-i`, as `-ti`, which tells Podman to hook up to the terminal. This connects to the input, output, and error stream of the bash process within the container to your screen, which allows you to interact within the container.\n",
    "\n",
    "- The `--rm` option tells Podman to delete the container as soon as the container exits, freeing up all of the container’s storage.\n",
    "\n",
    "- Specify the container image, [registry.access.redhat.com/ubi8/httpd-24](registry.access.redhat.com/ubi8/httpd-24), you are working with. The `podman` command reaches out to the container registry at `registry.access.redhat.com` and begins copying down the `ubi8/httpd-24:latest` image. Podman copies multiple **layers** (aka **blobs**), as shown in the following listing, and stores them in the local container storage (**container host**). You see the progress as the image layers are pulled down. Some images are rather large and can take a long time while being pulled down. If you later run a different container on the same image, Podman skips the image-pulling step, since you already have the correct image in local container storage.\n",
    "\n",
    "- Finally, specify the executable to be run within the container, in this case, `bash`.\n",
    "\n",
    "```\n",
    "Trying to pull registry.access.redhat.com/ubi8/httpd-24:latest...\n",
    "Getting image source signatures\n",
    "Copying blob 89e0ad8acaf1 done  \n",
    "Copying blob c2650fe947f6 done  \n",
    "Copying blob 50ccdb01751a done  \n",
    "Copying config 203593be2e done  \n",
    "Writing manifest to image destination\n",
    "Storing signatures\n",
    "```\n",
    "```sh\n",
    "bash-4.4$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2675cd-9ace-4b2d-993f-b1e1738292ca",
   "metadata": {},
   "source": [
    "While inside the bash shell container, `cat /etc/os-release`, and notice it is likely a different OS or a different version than the `/etc/os-release` outside the container. Explore around in the container, and notice how different it is from your host environment:\n",
    "\n",
    "```sh\n",
    "bash-4.4$ grep PRETTY_NAME /etc/os-release \n",
    "```\n",
    "```\n",
    "PRETTY_NAME=\"Red Hat Enterprise Linux 8.9 (Ootpa)\"\n",
    "```\n",
    "\n",
    "```sh\n",
    "bash-4.4$ ls /usr/bin | wc -l    # commands available\n",
    "```\n",
    "```\n",
    "526\n",
    "```\n",
    "```sh\n",
    "bash-4.4$ ps\n",
    "```\n",
    "```\n",
    "    PID TTY          TIME CMD\n",
    "      1 pts/0    00:00:00 bash\n",
    "      9 pts/0    00:00:00 ps\n",
    "```\n",
    "\n",
    "You can further explore the inside of the container to gain an understanding of what is going on within a container.\n",
    "\n",
    "When you are done, you exit the bash script, and the container shuts down. Since you ran with the `--rm` option, Podman removes all the container storage and deletes the container. The container image remains in `containers/storage`:\n",
    "\n",
    "```sh\n",
    "$ sudo ls /var/lib/containers/storage/\n",
    "defaultNetworkBackend  libpod  mounts  overlay  overlay-containers  overlay-images  overlay-layers  storage.lock  tmp  userns.lock\n",
    "\n",
    "$ sudo tree /var/lib/containers/storage/\n",
    "/var/lib/containers/storage/\n",
    "├── defaultNetworkBackend\n",
    "├── libpod\n",
    "│   └── bolt_state.db\n",
    "├── mounts\n",
    "├── overlay\n",
    "│   └── l\n",
    "├── overlay-containers\n",
    "│   └── containers.lock\n",
    "├── overlay-images\n",
    "│   └── images.lock\n",
    "├── overlay-layers\n",
    "│   └── layers.lock\n",
    "├── storage.lock\n",
    "├── tmp\n",
    "└── userns.lock\n",
    "\n",
    "9 directories, 7 files\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fac305-a27c-44eb-947b-5ddfd0bd05f0",
   "metadata": {},
   "source": [
    "### Running the containerized application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c2dfcd-291b-4e27-902e-5f1565f0f5c8",
   "metadata": {},
   "source": [
    "#### `podman run`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced9235-7862-4d65-a548-81b8c61bccdc",
   "metadata": {},
   "source": [
    "First, remove the `-ti` and the `--rm` options, since you want the container to remain running when the podman command exits. You are not a shell running within the container interactively, since it is just running the containerized web service:\n",
    "\n",
    "```sh\n",
    "$ podman run -d -p 8080:8080 --name myapp registry.access.redhat.com/ubi8/httpd-24\n",
    "37a1d2e31dbf4fa311a5ca6453f53106eaae2d8b9b9da264015cc3f8864fac22\n",
    "```\n",
    "\n",
    "- `-d` (`--detach`) option tells Podman to launch the container and then detach from it. Basically, run the container in the background. The Podman command actually exits and leaves the container running. Chapter 6 goes much deeper into what is going on behind the scenes;\n",
    "\n",
    "- `-p` (`--publish`) option tells Podman to publish or bind the container port `8080` to the host port `8080` when the container is running. With the `-p` option, the field before the colon refers to the host port, while the field after the colon refers to the container port. In this case, you see that the ports are the same. If you specify only one port, Podman considers this port a container port and randomly picks a host port on which the container port is bound. You can use the `podman port` command to discover which ports are bound to a container;\n",
    "\n",
    "```sh\n",
    "- $ podman port myapp\n",
    "8080/tcp -> 0.0.0.0:8080\n",
    "```\n",
    "\n",
    "i.e. the port `8080/tcp` inside the container is bound to all of the host networks (`0.0.0.0`) at port `8080`.\n",
    "\n",
    "By default, containers are created within their own **network namespace**, meaning they are not bound to the host network but to their virtualized network. Suppose I execute the container without the `-p` option. In that case, the Apache server within the container binds to the network interface within the container’s network namespace, but Apache is not bound to the host network.\n",
    "\n",
    "Only processes within the container are able to connect to port `8080` to communicate with the web server. By executing the command with the `-p` option, Podman connects the port from inside the container to the host network at the specified port. The connection allows external processes like a web browser to read from the web service.\n",
    "\n",
    "> NOTE: If you are running containers in rootless mode, covered in **chapter 3**, Podman users are by default not permitted to bind to ports `< 1024` by the kernel. Some containers want to bind to lower ports like port `80`, which is allowed inside the container, but `-p 80:80` fails, since `80` is less than `1024`. Using `-p 8080:80` causes Podman to bind the host’s port `8080` to port `80` within the container. The [upstream Podman repo](http://mng.bz/69ry) contains troubleshooting information on problems like binding to ports less than `1024` and many others.\n",
    "\n",
    "The `-p` option can map port numbers inside the container to different port numbers outside the container.\n",
    "\n",
    "- `--name myapp` option. Specifying a name makes it easier to find the container, and it allows you to specify a name that can then be used for other commands (e.g., `podman stop myapp`). If you don’t specify a name, Podman automatically generates a unique container name along with a container ID. All of the Podman commands that interact with containers can use either the name or the ID.\n",
    "\n",
    "When the `podman run` command completes, the container is running. Since this container is running in detached mode, Podman prints out the container ID and exits, but the container remains running.\n",
    "\n",
    "Now that the container is running, you can launch a web browser to communicate with the web server inside of the container at localhost port `8080` (see figure 2.1):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b139644-97bd-4a49-b1b1-53dd2e89c55c",
   "metadata": {},
   "source": [
    "![Figure 2.1 Web browser window connecting to the ubi8/httpd-24 container running in Podman](../data/images/Screenshot_20240118_004318.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb41fcc-87d7-4c65-8874-523898b61086",
   "metadata": {},
   "source": [
    "Now imagine you want to start another container. You can execute a similar command with just a couple of changes:\n",
    "\n",
    "```sh\n",
    "$ podman run -d -p 8081:8080 --name myapp1 \\ \n",
    "➥ registry.access.redhat.com/ubi8/httpd-24\n",
    "fa41173e4568a8fa588690d3177150a454c63b53bdfa52865b5f8f7e4d7de1e1\n",
    "```\n",
    "\n",
    "Notice you need to change the name of the container to `myapp1`; otherwise, the `podman run command` fails with the `myapp` name because the container previously existed. Also you need to change the `-p` option to use `8081` for the host port because the previous container, myapp, is currently running and is bound to port `8080`. The second container isn’t allowed to bind to port 8080 until the first container exits.\n",
    "\n",
    "Some notable `podman run` options include the following:\n",
    "\n",
    "- `--user USERNAME` — This tells Podman to run the container as a specific user defined in the image. By default, Podman will run the container as `root`, unless the container image specifies a default user.\n",
    "- `--rm` — This automatically removes the container when it exits.\n",
    "- `--tty` (`-t`) — This allocates a pseudo `-tty` and attaches it to the standard input of the container.\n",
    "- `--interactive` (`-i`) — This connects stdin to the primary process of the container. These options give you an interactive shell within the container.\n",
    "\n",
    "> NOTE There are dozens of `podman run` options available, allowing you to change security features, namespaces, volumes, and so on. Some of these I use and explain throughout the book. Refer to the `podman-run` man page for a description of all of the options. Most of the `podman create` options defined in table 2.1 are also available for `podman run`.\n",
    "\n",
    "Use the `man podman-run` command for information about all options. Now that the container is up and running, it is time to stop the container and go to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59375545-6964-4f9c-8572-4a75abe2bc7d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-17T19:56:11.191140Z",
     "iopub.status.busy": "2024-01-17T19:56:11.190222Z",
     "iopub.status.idle": "2024-01-17T19:56:12.774928Z",
     "shell.execute_reply": "2024-01-17T19:56:12.774423Z",
     "shell.execute_reply.started": "2024-01-17T19:56:11.191055Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "podman-run(1)               General Commands Manual              podman-run(1)\n",
      "\n",
      "NAME\n",
      "       podman-run - Run a command in a new container\n",
      "\n",
      "SYNOPSIS\n",
      "       podman run [options] image [command [arg ...]]\n",
      "\n",
      "       podman container run [options] image [command [arg ...]]\n",
      "\n",
      "DESCRIPTION\n",
      "       Run  a process in a new container. podman run starts a process with its\n",
      "       own file system, its own networking, and its own isolated process tree.\n",
      "       The  image  which starts the process may define defaults related to the\n",
      "       process that will be run in the container, the  networking  to  expose,\n",
      "       and  more, but podman run gives final control to the operator or admin‐\n",
      "       istrator who starts the container from the image. For that reason  pod‐\n",
      "       man run has more options than any other Podman command.\n",
      "\n",
      "       If the image is not already loaded then podman run will pull the image,\n",
      "       and all image dependencies, from the repository in the same way running\n",
      "       podman pull image , before it starts the container from that image.\n",
      "\n",
      "       Several files will be automatically created within the container. These\n",
      "       include /etc/hosts, /etc/hostname, and /etc/resolv.conf to manage  net‐\n",
      "       working.   These  will  be  based  on  the host's version of the files,\n",
      "       though they can be customized with options  (for  example,  --dns  will\n",
      "       override  the host's DNS servers in the created resolv.conf). Addition‐\n",
      "       ally, a container environment file is created in each container to  in‐\n",
      "       dicate  to  programs  they are running in a container. This file is lo‐\n",
      "       cated at /run/.containerenv. When using the --privileged flag the .con‐\n",
      "       tainerenv  contains  name/value  pairs  indicating the container engine\n",
      "       version, whether the engine is running in rootless mode, the  container\n",
      "       name  and  id,  as  well as the image name and id that the container is\n",
      "       based on.\n",
      "\n",
      "       When   running   from   a   user   defined   network   namespace,   the\n",
      "       /etc/netns/NSNAME/resolv.conf  will  be  used  if  it exists, otherwise\n",
      "       /etc/resolv.conf will be used.\n",
      "\n",
      "       Default settings are defined in containers.conf. Most settings for  re‐\n",
      "       mote  connections  use  the  servers containers.conf, except when docu‐\n",
      "       mented in man pages.\n",
      "\n",
      "IMAGE\n",
      "       The image is specified using transport:path format. If no transport  is\n",
      "       specified,  the  docker  (container registry) transport will be used by\n",
      "       default. For remote Podman, including Mac and Windows (excluding  WSL2)\n",
      "       machines, docker is the only allowed transport.\n",
      "\n",
      "       dir:path\n",
      "         An existing local directory path storing the manifest, layer tarballs\n",
      "       and signatures as individual files. This is a non-standardized  format,\n",
      "       primarily useful for debugging or noninvasive container inspection.\n",
      "\n",
      "              $ podman save --format docker-dir fedora -o /tmp/fedora\n",
      "              $ podman run dir:/tmp/fedora echo hello\n",
      "\n",
      "       docker://docker-reference (Default)\n",
      "         An image reference stored in a remote container image registry. Exam‐\n",
      "       ple: \"quay.io/podman/stable:latest\".  The reference can include a  path\n",
      "       to  a  specific registry; if it does not, the registries listed in reg‐\n",
      "       istries.conf will be queried to find a  matching  image.   By  default,\n",
      "       credentials  from  podman  login  (stored  at $XDG_RUNTIME_DIR/contain‐\n",
      "       ers/auth.json by default) will be used to  authenticate;  otherwise  it\n",
      "       falls back to using credentials in $HOME/.docker/config.json.\n",
      "\n",
      "              $ podman run registry.fedoraproject.org/fedora:latest echo hello\n",
      "\n",
      "       docker-archive:path[:docker-reference]  An  image  stored in the docker\n",
      "       save formatted file. docker-reference is only used when creating such a\n",
      "       file, and it must not contain a digest.\n",
      "\n",
      "              $ podman save --format docker-archive fedora -o /tmp/fedora\n",
      "              $ podman run docker-archive:/tmp/fedora echo hello\n",
      "\n",
      "       docker-daemon:docker-reference\n",
      "         An  image  in docker-reference format stored in the docker daemon in‐\n",
      "       ternal storage. The docker-reference can also be an image  ID  (docker-\n",
      "       daemon:algo:digest).\n",
      "\n",
      "              $ sudo docker pull fedora\n",
      "              $ sudo podman run docker-daemon:docker.io/library/fedora echo hello\n",
      "\n",
      "       oci-archive:path:tag\n",
      "         An image in a directory compliant with the \"Open Container Image Lay‐\n",
      "       out Specification\" at the specified path and specified with a tag.\n",
      "\n",
      "              $ podman save --format oci-archive fedora -o /tmp/fedora\n",
      "              $ podman run oci-archive:/tmp/fedora echo hello\n",
      "\n",
      "OPTIONS\n",
      "   --add-host=host:ip\n",
      "       Add a custom host-to-IP mapping (host:ip)\n",
      "\n",
      "       Add a line to /etc/hosts. The format is hostname:ip. The --add-host op‐\n",
      "       tion can be set multiple times. Conflicts with the --no-hosts option.\n",
      "\n",
      "   --annotation=key=value\n",
      "       Add  an  annotation  to  the container. This option can be set multiple\n",
      "       times.\n",
      "\n",
      "   --arch=ARCH\n",
      "       Override the architecture, defaults  to  hosts,  of  the  image  to  be\n",
      "       pulled. For example, arm.  Unless overridden, subsequent lookups of the\n",
      "       same image in the local storage will match this  architecture,  regard‐\n",
      "       less of the host.\n",
      "\n",
      "   --attach, -a=stdin | stdout | stderr\n",
      "       Attach to STDIN, STDOUT or STDERR.\n",
      "\n",
      "       In  foreground  mode (the default when -d is not specified), podman run\n",
      "       can start the process in the container and attach the  console  to  the\n",
      "       process's  standard input, output, and error. It can even pretend to be\n",
      "       a TTY (this is what most  command-line  executables  expect)  and  pass\n",
      "       along  signals. The -a option can be set for each of stdin, stdout, and\n",
      "       stderr.\n",
      "\n",
      "   --authfile=path\n",
      "       Path of the authentication file. Default is ${XDG_RUNTIME_DIR}/contain‐\n",
      "       ers/auth.json,  which  is set using podman login.  If the authorization\n",
      "       state is not found there, $HOME/.docker/config.json is  checked,  which\n",
      "       is set using docker login.\n",
      "\n",
      "       Note:  There is also the option to override the default path of the au‐\n",
      "       thentication file by setting the REGISTRY_AUTH_FILE  environment  vari‐\n",
      "       able. This can be done with export REGISTRY_AUTH_FILE=path.\n",
      "\n",
      "   --blkio-weight=weight\n",
      "       Block IO relative weight. The weight is a value between 10 and 1000.\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --blkio-weight-device=device:weight\n",
      "       Block IO relative device weight.\n",
      "\n",
      "   --cap-add=capability\n",
      "       Add Linux capabilities.\n",
      "\n",
      "   --cap-drop=capability\n",
      "       Drop Linux capabilities.\n",
      "\n",
      "   --cgroup-conf=KEY=VALUE\n",
      "       When  running on cgroup v2, specify the cgroup file to write to and its\n",
      "       value. For example --cgroup-conf=memory.high=1073741824 sets  the  mem‐\n",
      "       ory.high limit to 1GB.\n",
      "\n",
      "   --cgroup-parent=path\n",
      "       Path  to  cgroups under which the cgroup for the container will be cre‐\n",
      "       ated. If the path is not absolute, the path is considered to  be  rela‐\n",
      "       tive  to  the cgroups path of the init process. Cgroups will be created\n",
      "       if they do not already exist.\n",
      "\n",
      "   --cgroupns=mode\n",
      "       Set the cgroup namespace mode for the container.\n",
      "\n",
      "              • host: use the host's cgroup namespace inside the container.\n",
      "\n",
      "              • container:id: join the namespace of the specified container.\n",
      "\n",
      "              • private: create a new cgroup namespace.\n",
      "\n",
      "              • ns:path: join the namespace at the specified path.\n",
      "\n",
      "       If the host uses cgroups v1, the default is set to host. On cgroups v2,\n",
      "       the default is private.\n",
      "\n",
      "   --cgroups=how\n",
      "       Determines whether the container will create CGroups.\n",
      "\n",
      "       Default is enabled.\n",
      "\n",
      "       The  enabled  option  will create a new cgroup under the cgroup-parent.\n",
      "       The disabled option will force the container to not create CGroups, and\n",
      "       thus  conflicts  with  CGroup options (--cgroupns and --cgroup-parent).\n",
      "       The no-conmon option disables a new CGroup only for the conmon process.\n",
      "       The  split option splits the current CGroup in two sub-cgroups: one for\n",
      "       conmon and one for the container payload. It is  not  possible  to  set\n",
      "       --cgroup-parent with split.\n",
      "\n",
      "   --chrootdirs=path\n",
      "       Path  to  a  directory inside the container that should be treated as a\n",
      "       chroot directory.  Any Podman  managed  file  (e.g.,  /etc/resolv.conf,\n",
      "       /etc/hosts,  etc/hostname) that is mounted into the root directory will\n",
      "       be mounted into that location as well.  Multiple directories should  be\n",
      "       separated with a comma.\n",
      "\n",
      "   --cidfile=file\n",
      "       Write the container ID to file.\n",
      "\n",
      "   --conmon-pidfile=file\n",
      "       Write the pid of the conmon process to a file. As conmon runs in a sep‐\n",
      "       arate process than Podman, this is  necessary  when  using  systemd  to\n",
      "       restart  Podman containers.  (This option is not available with the re‐\n",
      "       mote Podman client, including Mac  and  Windows  (excluding  WSL2)  ma‐\n",
      "       chines)\n",
      "\n",
      "   --cpu-period=limit\n",
      "       Set  the CPU period for the Completely Fair Scheduler (CFS), which is a\n",
      "       duration in microseconds. Once the container's CPU quota is used up, it\n",
      "       will not be scheduled to run until the current period ends. Defaults to\n",
      "       100000 microseconds.\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --cpu-quota=limit\n",
      "       Limit the CPU Completely Fair Scheduler (CFS) quota.\n",
      "\n",
      "       Limit  the  container's  CPU usage. By default, containers run with the\n",
      "       full CPU resource. The limit is a number in microseconds. If  a  number\n",
      "       is  provided,  the  container will be allowed to use that much CPU time\n",
      "       until the CPU period ends (controllable via --cpu-period).\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --cpu-rt-period=microseconds\n",
      "       Limit the CPU real-time period in microseconds.\n",
      "\n",
      "       Limit the container's Real Time CPU usage. This option tells the kernel\n",
      "       to restrict the container's Real Time CPU usage to  the  period  speci‐\n",
      "       fied.\n",
      "\n",
      "       This option is only supported on cgroups V1 rootful systems.\n",
      "\n",
      "   --cpu-rt-runtime=microseconds\n",
      "       Limit the CPU real-time runtime in microseconds.\n",
      "\n",
      "       Limit  the containers Real Time CPU usage. This option tells the kernel\n",
      "       to limit the amount of time in a given CPU period Real Time  tasks  may\n",
      "       consume.  Ex: Period of 1,000,000us and Runtime of 950,000us means that\n",
      "       this container could consume 95% of available CPU and leave the remain‐\n",
      "       ing 5% to normal priority tasks.\n",
      "\n",
      "       The  sum of all runtimes across containers cannot exceed the amount al‐\n",
      "       lotted to the parent cgroup.\n",
      "\n",
      "       This option is only supported on cgroups V1 rootful systems.\n",
      "\n",
      "   --cpu-shares, -c=shares\n",
      "       CPU shares (relative weight).\n",
      "\n",
      "       By default, all containers get the same proportion of CPU cycles.  This\n",
      "       proportion  can  be  modified  by  changing  the  container's CPU share\n",
      "       weighting relative to the combined weight of all the  running  contain‐\n",
      "       ers.  Default weight is 1024.\n",
      "\n",
      "       The  proportion  will  only apply when CPU-intensive processes are run‐\n",
      "       ning.  When tasks in one container are idle, other containers  can  use\n",
      "       the left-over CPU time. The actual amount of CPU time will vary depend‐\n",
      "       ing on the number of containers running on the system.\n",
      "\n",
      "       For example, consider three containers, one has a cpu-share of 1024 and\n",
      "       two others have a cpu-share setting of 512. When processes in all three\n",
      "       containers attempt to use 100% of CPU, the first  container  would  re‐\n",
      "       ceive  50% of the total CPU time. If a fourth container is added with a\n",
      "       cpu-share of 1024, the first container only gets 33% of  the  CPU.  The\n",
      "       remaining containers receive 16.5%, 16.5% and 33% of the CPU.\n",
      "\n",
      "       On a multi-core system, the shares of CPU time are distributed over all\n",
      "       CPU cores. Even if a container is limited to  less  than  100%  of  CPU\n",
      "       time, it can use 100% of each individual CPU core.\n",
      "\n",
      "       For example, consider a system with more than three cores.  If the con‐\n",
      "       tainer C0 is started with --cpu-shares=512 running one process, and an‐\n",
      "       other  container  C1 with --cpu-shares=1024 running two processes, this\n",
      "       can result in the following division of CPU shares:\n",
      "\n",
      "       ┌────┬───────────┬─────┬──────────────┐\n",
      "       │PID │ container │ CPU │ CPU share    │\n",
      "       ├────┼───────────┼─────┼──────────────┤\n",
      "       │100 │ C0        │ 0   │ 100% of CPU0 │\n",
      "       ├────┼───────────┼─────┼──────────────┤\n",
      "       │101 │ C1        │ 1   │ 100% of CPU1 │\n",
      "       ├────┼───────────┼─────┼──────────────┤\n",
      "       │102 │ C1        │ 2   │ 100% of CPU2 │\n",
      "       └────┴───────────┴─────┴──────────────┘\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --cpus=number\n",
      "       Number of CPUs. The default is 0.0 which means no limit. This is short‐\n",
      "       hand for --cpu-period and --cpu-quota,  so  you  may  only  set  either\n",
      "       --cpus or --cpu-period and --cpu-quota.\n",
      "\n",
      "       On  some  systems,  changing the CPU limits may not be allowed for non-\n",
      "       root users. For more  details,  see  https://github.com/containers/pod‐\n",
      "       man/blob/main/troubleshooting.md#26-running-containers-with-resource-\n",
      "       limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --cpuset-cpus=number\n",
      "       CPUs in which to allow execution. Can be specified as a comma-separated\n",
      "       list  (e.g.  0,1),  as  a  range (e.g. 0-3), or any combination thereof\n",
      "       (e.g. 0-3,7,11-15).\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --cpuset-mems=nodes\n",
      "       Memory nodes (MEMs) in which to allow execution (0-3, 0,1). Only effec‐\n",
      "       tive on NUMA systems.\n",
      "\n",
      "       If there are four memory nodes  on  the  system  (0-3),  use  --cpuset-\n",
      "       mems=0,1  then processes in the container will only use memory from the\n",
      "       first two memory nodes.\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --detach, -d\n",
      "       Detached  mode:  run  the container in the background and print the new\n",
      "       container ID. The default is false.\n",
      "\n",
      "       At any time you can run podman ps in the other shell to view a list  of\n",
      "       the  running  containers. You can reattach to a detached container with\n",
      "       podman attach.\n",
      "\n",
      "       When attached in the tty mode, you can detach from the  container  (and\n",
      "       leave  it  running)  using a configurable key sequence. The default se‐\n",
      "       quence is ctrl-p,ctrl-q.  Specify the key sequence using the  --detach-\n",
      "       keys  option, or configure it in the containers.conf file: see contain‐\n",
      "       ers.conf(5) for more information.\n",
      "\n",
      "   --detach-keys=sequence\n",
      "       Specify the key sequence for detaching a container. Format is a  single\n",
      "       character [a-Z] or one or more ctrl-<value> characters where <value> is\n",
      "       one of: a-z, @, ^, [, , or _. Specifying \"\" will disable this  feature.\n",
      "       The default is ctrl-p,ctrl-q.\n",
      "\n",
      "       This option can also be set in containers.conf(5) file.\n",
      "\n",
      "   --device=host-device[:container-device][:permissions]\n",
      "       Add  a host device to the container. Optional permissions parameter can\n",
      "       be used to specify device permissions by combining r for  read,  w  for\n",
      "       write, and m for mknod(2).\n",
      "\n",
      "       Example: --device=/dev/sdc:/dev/xvdc:rwm.\n",
      "\n",
      "       Note: if host-device is a symbolic link then it will be resolved first.\n",
      "       The container will only store the major and minor numbers of  the  host\n",
      "       device.\n",
      "\n",
      "       Podman may load kernel modules required for using the specified device.\n",
      "       The devices that Podman will  load  modules  for  when  necessary  are:\n",
      "       /dev/fuse.\n",
      "\n",
      "       In  rootless mode, the new device is bind mounted in the container from\n",
      "       the host rather than Podman creating it within the container space. Be‐\n",
      "       cause  the bind mount retains its SELinux label on SELinux systems, the\n",
      "       container can get permission denied when accessing the mounted  device.\n",
      "       Modify  SELinux  settings  to allow containers to use all device labels\n",
      "       via the following command:\n",
      "\n",
      "       $ sudo setsebool -P  container_use_devices=true\n",
      "\n",
      "       Note: if the user only has access rights via a group, accessing the de‐\n",
      "       vice  from  inside  a rootless container will fail. Use the --group-add\n",
      "       keep-groups flag to pass the user's supplementary group access into the\n",
      "       container.\n",
      "\n",
      "   --device-cgroup-rule=\"type major:minor mode\"\n",
      "       Add  a rule to the cgroup allowed devices list. The rule is expected to\n",
      "       be in the format specified in the Linux kernel documentation  (Documen‐\n",
      "       tation/cgroup-v1/devices.txt):\n",
      "              - type: a (all), c (char), or b (block);\n",
      "              - major and minor: either a number, or * for all;\n",
      "              - mode: a composition of r (read), w (write), and m (mknod(2)).\n",
      "\n",
      "   --device-read-bps=path:rate\n",
      "       Limit  read  rate  (in  bytes per second) from a device (e.g. --device-\n",
      "       read-bps=/dev/sda:1mb).\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --device-read-iops=path:rate\n",
      "       Limit read rate (in IO operations per second) from a device (e.g. --de‐\n",
      "       vice-read-iops=/dev/sda:1000).\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --device-write-bps=path:rate\n",
      "       Limit  write  rate  (in  bytes  per second) to a device (e.g. --device-\n",
      "       write-bps=/dev/sda:1mb).\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --device-write-iops=path:rate\n",
      "       Limit  write rate (in IO operations per second) to a device (e.g. --de‐\n",
      "       vice-write-iops=/dev/sda:1000).\n",
      "\n",
      "       On some systems, changing the resource limits may not  be  allowed  for\n",
      "       non-root  users.  For  more  details,  see  https://github.com/contain‐\n",
      "       ers/podman/blob/main/troubleshooting.md#26-running-containers-with-re‐\n",
      "       source-limits-fails-with-a-permissions-error\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --disable-content-trust\n",
      "       This  is  a  Docker-specific  option to disable image verification to a\n",
      "       container registry and is not supported by Podman.  This  option  is  a\n",
      "       NOOP and provided solely for scripting compatibility.\n",
      "\n",
      "   --dns=ipaddr\n",
      "       Set custom DNS servers.\n",
      "\n",
      "       This option can be used to override the DNS configuration passed to the\n",
      "       container. Typically this is necessary when the host DNS  configuration\n",
      "       is  invalid  for the container (e.g., 127.0.0.1). When this is the case\n",
      "       the --dns flag is necessary for every run.\n",
      "\n",
      "       The special value none can be specified to disable creation of /etc/re‐\n",
      "       solv.conf in the container by Podman.  The /etc/resolv.conf file in the\n",
      "       image will be used without changes.\n",
      "\n",
      "       This option cannot be combined with --network that is set  to  none  or\n",
      "       container:id.\n",
      "\n",
      "   --dns-option=option\n",
      "       Set  custom  DNS  options. Invalid if using --dns-option with --network\n",
      "       that is set to none or container:id.\n",
      "\n",
      "   --dns-search=domain\n",
      "       Set custom DNS search  domains.  Invalid  if  using  --dns-search  with\n",
      "       --network  that  is set to none or container:id.  Use --dns-search=. if\n",
      "       you don't wish to set the search domain.\n",
      "\n",
      "   --entrypoint=\"command\" | '[\"command\", arg1 , ...]'\n",
      "       Overwrite the default ENTRYPOINT of the image.\n",
      "\n",
      "       This option allows you to overwrite the default entrypoint of  the  im‐\n",
      "       age.\n",
      "\n",
      "       The ENTRYPOINT of an image is similar to a COMMAND because it specifies\n",
      "       what executable to run when the container starts, but it is (purposely)\n",
      "       more  difficult  to  override. The ENTRYPOINT gives a container its de‐\n",
      "       fault nature or behavior, so that when you set an  ENTRYPOINT  you  can\n",
      "       run  the container as if it were that binary, complete with default op‐\n",
      "       tions, and you can pass in more options via the COMMAND. But, sometimes\n",
      "       an operator may want to run something else inside the container, so you\n",
      "       can override the default ENTRYPOINT at runtime by using a  --entrypoint\n",
      "       and a string to specify the new ENTRYPOINT.\n",
      "\n",
      "       You need to specify multi option commands in the form of a json string.\n",
      "\n",
      "   --env, -e=env\n",
      "       Set environment variables.\n",
      "\n",
      "       This  option  allows arbitrary environment variables that are available\n",
      "       for the process to be launched inside of the container. If an  environ‐\n",
      "       ment  variable is specified without a value, Podman will check the host\n",
      "       environment for a value and set the variable only if it is set  on  the\n",
      "       host.  As  a  special  case,  if an environment variable ending in * is\n",
      "       specified without a value, Podman will search the host environment  for\n",
      "       variables  starting with the prefix and will add those variables to the\n",
      "       container.\n",
      "\n",
      "       See Environment ⟨#environment⟩ note below for precedence and examples.\n",
      "\n",
      "   --env-file=file\n",
      "       Read in a line-delimited file of environment variables.\n",
      "\n",
      "       See Environment ⟨#environment⟩ note below for precedence and examples.\n",
      "\n",
      "   --env-host\n",
      "       Use host environment inside of the container. See Environment note  be‐\n",
      "       low  for precedence. (This option is not available with the remote Pod‐\n",
      "       man client, including Mac and Windows (excluding WSL2) machines)\n",
      "\n",
      "   --env-merge=env\n",
      "       Preprocess default environment variables for the containers. For  exam‐\n",
      "       ple if image contains environment variable hello=world user can prepro‐\n",
      "       cess it using --env-merge hello=${hello}-some  so  new  value  will  be\n",
      "       hello=world-some.\n",
      "\n",
      "   --expose=port\n",
      "       Expose  a port, or a range of ports (e.g. --expose=3300-3310) to set up\n",
      "       port redirection on the host system.\n",
      "\n",
      "   --gidmap=container_gid:host_gid:amount\n",
      "       Run the container in a new user namespace using the supplied  GID  map‐\n",
      "       ping. This option conflicts with the --userns and --subgidname options.\n",
      "       This option provides a way to map host GIDs to container  GIDs  in  the\n",
      "       same  way as --uidmap maps host UIDs to container UIDs. For details see\n",
      "       --uidmap.\n",
      "\n",
      "       Note: the --gidmap flag cannot be called in conjunction with the  --pod\n",
      "       flag as a gidmap cannot be set on the container level when in a pod.\n",
      "\n",
      "   --group-add=group | keep-groups\n",
      "       Assign  additional  groups  to the primary user running within the con‐\n",
      "       tainer process.\n",
      "\n",
      "              • keep-groups is a special flag that tells Podman  to  keep  the\n",
      "                supplementary group access.\n",
      "\n",
      "       Allows  container to use the user's supplementary group access. If file\n",
      "       systems or devices are only accessible by the  rootless  user's  group,\n",
      "       this  flag tells the OCI runtime to pass the group access into the con‐\n",
      "       tainer. Currently only available with the crun OCI runtime. Note: keep-\n",
      "       groups  is  exclusive,  you cannot add any other groups with this flag.\n",
      "       (Not available for remote commands, including Mac and Windows  (exclud‐\n",
      "       ing WSL2) machines)\n",
      "\n",
      "   --health-cmd=\"command\" | '[\"command\", arg1 , ...]'\n",
      "       Set  or  alter  a healthcheck command for a container. The command is a\n",
      "       command to be executed inside your container that determines your  con‐\n",
      "       tainer health. The command is required for other healthcheck options to\n",
      "       be applied. A value of none disables existing healthchecks.\n",
      "\n",
      "       Multiple options can be passed in the form of a JSON array;  otherwise,\n",
      "       the command will be interpreted as an argument to /bin/sh -c.\n",
      "\n",
      "   --health-interval=interval\n",
      "       Set an interval for the healthchecks. An interval of disable results in\n",
      "       no automatic timer setup. The default is 30s.\n",
      "\n",
      "   --health-on-failure=action\n",
      "       Action to take once the container transitions to  an  unhealthy  state.\n",
      "       The default is none.\n",
      "\n",
      "              • none: Take no action.\n",
      "\n",
      "              • kill: Kill the container.\n",
      "\n",
      "              • restart:  Restart  the  container.  Do not combine the restart\n",
      "                action with the --restart flag.  When running inside of a sys‐\n",
      "                temd  unit,  consider using the kill or stop action instead to\n",
      "                make use of systemd's restart policy.\n",
      "\n",
      "              • stop: Stop the container.\n",
      "\n",
      "   --health-retries=retries\n",
      "       The number of retries allowed before a healthcheck is considered to  be\n",
      "       unhealthy. The default value is 3.\n",
      "\n",
      "   --health-start-period=period\n",
      "       The  initialization time needed for a container to bootstrap. The value\n",
      "       can be expressed in time format like 2m3s. The default value is 0s.\n",
      "\n",
      "   --health-timeout=timeout\n",
      "       The maximum time allowed to complete the healthcheck before an interval\n",
      "       is  considered failed. Like start-period, the value can be expressed in\n",
      "       a time format such as 1m22s. The default value is 30s.\n",
      "\n",
      "   --help\n",
      "       Print usage statement\n",
      "\n",
      "   --hostname, -h=name\n",
      "       Container host name\n",
      "\n",
      "       Sets the container host name that is available  inside  the  container.\n",
      "       Can  only be used with a private UTS namespace --uts=private (default).\n",
      "       If --pod is specified and the pod shares the  UTS  namespace  (default)\n",
      "       the pod's hostname will be used.\n",
      "\n",
      "   --hostuser=name\n",
      "       Add  a  user account to /etc/passwd from the host to the container. The\n",
      "       Username or UID must exist on the host system.\n",
      "\n",
      "   --http-proxy\n",
      "       By default proxy environment variables are passed into the container if\n",
      "       set  for  the Podman process. This can be disabled by setting the value\n",
      "       to false.  The environment  variables  passed  in  include  http_proxy,\n",
      "       https_proxy,  ftp_proxy,  no_proxy, and also the upper case versions of\n",
      "       those. This option is only needed when the host system must use a proxy\n",
      "       but the container should not use any proxy. Proxy environment variables\n",
      "       specified for the container in any other way will override  the  values\n",
      "       that would have been passed through from the host. (Other ways to spec‐\n",
      "       ify the proxy for the container include passing  the  values  with  the\n",
      "       --env  flag,  or  hard  coding the proxy environment at container build\n",
      "       time.)  (This option is not available with the  remote  Podman  client,\n",
      "       including Mac and Windows (excluding WSL2) machines)\n",
      "\n",
      "       Defaults to true.\n",
      "\n",
      "   --image-volume=bind | tmpfs | ignore\n",
      "       Tells Podman how to handle the builtin image volumes. Default is bind.\n",
      "\n",
      "              • bind:  An  anonymous  named volume will be created and mounted\n",
      "                into the container.\n",
      "\n",
      "              • tmpfs: The volume is mounted onto the container  as  a  tmpfs,\n",
      "                which  allows the users to create content that disappears when\n",
      "                the container is stopped.\n",
      "\n",
      "              • ignore: All volumes are just ignored and no action is taken.\n",
      "\n",
      "   --init\n",
      "       Run an init inside the container that forwards signals and  reaps  pro‐\n",
      "       cesses.   The  container-init  binary  is  mounted at /run/podman-init.\n",
      "       Mounting over /run will hence break container execution.\n",
      "\n",
      "   --init-path=path\n",
      "       Path to the container-init binary.\n",
      "\n",
      "   --interactive, -i\n",
      "       When set to true, keep stdin open even if not attached. The default  is\n",
      "       false.\n",
      "\n",
      "   --ip=ipv4\n",
      "       Specify   a   static  IPv4  address  for  the  container,  for  example\n",
      "       10.88.64.128.  This option can only be used if the container is  joined\n",
      "       to only a single network - i.e., --network=network-name is used at most\n",
      "       once - and if the container is not joining another container's  network\n",
      "       namespace  via  --network=container:id.  The address must be within the\n",
      "       network's IP address pool (default 10.88.0.0/16).\n",
      "\n",
      "       To specify multiple static IP addresses  per  container,  set  multiple\n",
      "       networks  using the --network option with a static IP address specified\n",
      "       for each using the ip mode for that option.\n",
      "\n",
      "   --ip6=ipv6\n",
      "       Specify  a  static  IPv6  address  for  the  container,   for   example\n",
      "       fd46:db93:aa76:ac37::10.  This option can only be used if the container\n",
      "       is joined to only a single network -  i.e.,  --network=network-name  is\n",
      "       used  at  most  once - and if the container is not joining another con‐\n",
      "       tainer's network namespace  via  --network=container:id.   The  address\n",
      "       must be within the network's IPv6 address pool.\n",
      "\n",
      "       To  specify  multiple static IPv6 addresses per container, set multiple\n",
      "       networks using the --network option with a static IPv6  address  speci‐\n",
      "       fied for each using the ip6 mode for that option.\n",
      "\n",
      "   --ipc=ipc\n",
      "       Set  the IPC namespace mode for a container. The default is to create a\n",
      "       private IPC namespace.\n",
      "\n",
      "              • \"\": Use Podman's default, defined in containers.conf.\n",
      "\n",
      "              • container:id: reuses another container's shared memory,  sema‐\n",
      "                phores, and message queues\n",
      "\n",
      "              • host:  use  the  host's shared memory, semaphores, and message\n",
      "                queues inside the container. Note: the  host  mode  gives  the\n",
      "                container  full access to local shared memory and is therefore\n",
      "                considered insecure.\n",
      "\n",
      "              • none:  private IPC namespace, with /dev/shm not mounted.\n",
      "\n",
      "              • ns:path: path to an IPC namespace to join.\n",
      "\n",
      "              • private: private IPC  namespace.   =  shareable:  private  IPC\n",
      "                namespace  with  a possibility to share it with other contain‐\n",
      "                ers.\n",
      "\n",
      "   --label, -l=key=value\n",
      "       Add metadata to a container.\n",
      "\n",
      "   --label-file=file\n",
      "       Read in a line-delimited file of labels.\n",
      "\n",
      "   --link-local-ip=ip\n",
      "       Not implemented.\n",
      "\n",
      "   --log-driver=driver\n",
      "       Logging driver for the container. Currently available options are  k8s-\n",
      "       file,  journald,  none  and passthrough, with json-file aliased to k8s-\n",
      "       file for scripting compatibility. (Default journald).\n",
      "\n",
      "       The podman info command below will display the default  log-driver  for\n",
      "       the system.\n",
      "\n",
      "              $ podman info --format '{{ .Host.LogDriver }}'\n",
      "              journald\n",
      "\n",
      "       The passthrough driver passes down the standard streams (stdin, stdout,\n",
      "       stderr) to the container.  It is not allowed  with  the  remote  Podman\n",
      "       client,  including  Mac and Windows (excluding WSL2) machines, and on a\n",
      "       tty, since it is vulnerable to attacks via TIOCSTI.\n",
      "\n",
      "   --log-opt=name=value\n",
      "       Logging driver specific options.\n",
      "\n",
      "       Set custom logging configuration. The following *name*s are supported:\n",
      "\n",
      "       path: specify a path to the log file\n",
      "           (e.g. --log-opt path=/var/log/container/mycontainer.json);\n",
      "\n",
      "       max-size: specify a max size of the log file\n",
      "           (e.g. --log-opt max-size=10mb);\n",
      "\n",
      "       tag: specify a custom log tag for the container\n",
      "           (e.g. --log-opt tag=\"{{.ImageName}}\".  It supports the same keys as\n",
      "       podman  inspect  --format.   This option is currently supported only by\n",
      "       the journald log driver.\n",
      "\n",
      "   --mac-address=address\n",
      "       Container network interface MAC address (e.g.  92:d0:c6:0a:29:33)  This\n",
      "       option  can  only  be  used if the container is joined to only a single\n",
      "       network - i.e., --network=network-name is used at most once  -  and  if\n",
      "       the  container is not joining another container's network namespace via\n",
      "       --network=container:id.\n",
      "\n",
      "       Remember that the MAC address in an Ethernet network  must  be  unique.\n",
      "       The  IPv6  link-local address will be based on the device's MAC address\n",
      "       according to RFC4862.\n",
      "\n",
      "       To specify multiple static MAC addresses per  container,  set  multiple\n",
      "       networks using the --network option with a static MAC address specified\n",
      "       for each using the mac mode for that option.\n",
      "\n",
      "   --memory, -m=number[unit]\n",
      "       Memory limit. A unit can be b (bytes), k (kibibytes), m (mebibytes), or\n",
      "       g (gibibytes).\n",
      "\n",
      "       Allows  the  memory  available to a container to be constrained. If the\n",
      "       host supports swap memory, then the -m memory  setting  can  be  larger\n",
      "       than  physical  RAM.  If  a limit of 0 is specified (not using -m), the\n",
      "       container's memory is not limited. The actual limit may be  rounded  up\n",
      "       to  a  multiple of the operating system's page size (the value would be\n",
      "       very large, that's millions of trillions).\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --memory-reservation=number[unit]\n",
      "       Memory  soft  limit.  A  unit  can  be  b  (bytes),  k  (kibibytes),  m\n",
      "       (mebibytes), or g (gibibytes).\n",
      "\n",
      "       After  setting  memory reservation, when the system detects memory con‐\n",
      "       tention or low memory, containers are forced to restrict their consump‐\n",
      "       tion  to  their  reservation.  So you should always set the value below\n",
      "       --memory, otherwise the hard limit will take  precedence.  By  default,\n",
      "       memory reservation will be the same as memory limit.\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --memory-swap=number[unit]\n",
      "       A  limit  value  equal to memory plus swap.  A unit can be b (bytes), k\n",
      "       (kibibytes), m (mebibytes), or g (gibibytes).\n",
      "\n",
      "       Must be used with the -m (--memory) flag.  The  argument  value  should\n",
      "       always be larger than that of\n",
      "        -m (--memory) By default, it is set to double the value of --memory.\n",
      "\n",
      "       Set number to -1 to enable unlimited swap.\n",
      "\n",
      "       This option is not supported on cgroups V1 rootless systems.\n",
      "\n",
      "   --memory-swappiness=number\n",
      "       Tune  a  container's memory swappiness behavior. Accepts an integer be‐\n",
      "       tween 0 and 100.\n",
      "\n",
      "       This flag is only supported on cgroups V1 rootful systems.\n",
      "\n",
      "   --mount=type=TYPE,TYPE-SPECIFIC-OPTION[,...]\n",
      "       Attach a filesystem mount to the container\n",
      "\n",
      "       Current supported mount TYPEs are bind, volume, image,  tmpfs  and  de‐\n",
      "       vpts. [1] ⟨#Footnote1⟩\n",
      "\n",
      "                 e.g.\n",
      "\n",
      "                 type=bind,source=/path/on/host,destination=/path/in/container\n",
      "\n",
      "                 type=bind,src=/path/on/host,dst=/path/in/container,relabel=shared\n",
      "\n",
      "                 type=bind,src=/path/on/host,dst=/path/in/container,relabel=shared,U=true\n",
      "\n",
      "                 type=volume,source=vol1,destination=/path/in/container,ro=true\n",
      "\n",
      "                 type=tmpfs,tmpfs-size=512M,destination=/path/in/container\n",
      "\n",
      "                 type=image,source=fedora,destination=/fedora-image,rw=true\n",
      "\n",
      "                 type=devpts,destination=/dev/pts\n",
      "\n",
      "                 Common Options:\n",
      "\n",
      "                    · src, source: mount source spec for bind and volume. Mandatory for bind.\n",
      "\n",
      "                    · dst, destination, target: mount destination spec.\n",
      "\n",
      "                 Options specific to volume:\n",
      "\n",
      "                    · ro, readonly: true or false (default).\n",
      "\n",
      "                    . U, chown: true or false (default). Change recursively the owner and group of the source volume based on the UID and GID of the container.\n",
      "\n",
      "                    · idmap: true or false (default).  If specified, create an idmapped mount to the target user namespace in the container.\n",
      "\n",
      "                 Options specific to image:\n",
      "\n",
      "                    · rw, readwrite: true or false (default).\n",
      "\n",
      "                 Options specific to bind:\n",
      "\n",
      "                    · ro, readonly: true or false (default).\n",
      "\n",
      "                    · bind-propagation: shared, slave, private, unbindable, rshared, rslave, runbindable, or rprivate(default). See also mount(2).\n",
      "\n",
      "                    . bind-nonrecursive: do not set up a recursive bind mount. By default it is recursive.\n",
      "\n",
      "                    . relabel: shared, private.\n",
      "\n",
      "                    · idmap: true or false (default).  If specified, create an idmapped mount to the target user namespace in the container.\n",
      "\n",
      "                    . U, chown: true or false (default). Change recursively the owner and group of the source volume based on the UID and GID of the container.\n",
      "\n",
      "                 Options specific to tmpfs:\n",
      "\n",
      "                    · ro, readonly: true or false (default).\n",
      "\n",
      "                    · tmpfs-size: Size of the tmpfs mount in bytes. Unlimited by default in Linux.\n",
      "\n",
      "                    · tmpfs-mode: File mode of the tmpfs in octal. (e.g. 700 or 0700.) Defaults to 1777 in Linux.\n",
      "\n",
      "                    · tmpcopyup: Enable copyup from the image directory at the same location to the tmpfs. Used by default.\n",
      "\n",
      "                    · notmpcopyup: Disable copying files from the image to the tmpfs.\n",
      "\n",
      "                    . U, chown: true or false (default). Change recursively the owner and group of the source volume based on the UID and GID of the container.\n",
      "\n",
      "                 Options specific to devpts:\n",
      "\n",
      "                    · uid: UID of the file owner (default 0).\n",
      "\n",
      "                    · gid: GID of the file owner (default 0).\n",
      "\n",
      "                    · mode: permission mask for the file (default 600).\n",
      "\n",
      "                    · max: maximum number of PTYs (default 1048576).\n",
      "\n",
      "   --name=name\n",
      "       Assign a name to the container.\n",
      "\n",
      "       The operator can identify a container in three ways:\n",
      "\n",
      "              • UUID                      long                      identifier\n",
      "                (“f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778”);\n",
      "\n",
      "              • UUID short identifier (“f78375b1c487”);\n",
      "\n",
      "              • Name (“jonah”).\n",
      "\n",
      "       Podman  generates  a  UUID for each container, and if a name is not as‐\n",
      "       signed to the container with --name then  it  will  generate  a  random\n",
      "       string  name.  The name is useful any place you need to identify a con‐\n",
      "       tainer.  This works for both background and foreground containers.\n",
      "\n",
      "   --network=mode, --net\n",
      "       Set the network mode for the container.\n",
      "\n",
      "       Valid mode values are:\n",
      "\n",
      "              • bridge[:OPTIONS,...]: Create a network stack  on  the  default\n",
      "                bridge. This is the default for rootful containers. It is pos‐\n",
      "                sible to specify these additional options:\n",
      "\n",
      "                • alias=name: Add network-scoped alias for the container.\n",
      "\n",
      "                • ip=IPv4: Specify a static ipv4 address for this container.\n",
      "\n",
      "                • ip=IPv6: Specify a static ipv6 address for this container.\n",
      "\n",
      "                • mac=MAC: Specify a static mac address for this container.\n",
      "\n",
      "                • interface_name: Specify a name for the created  network  in‐\n",
      "                  terface inside the container.\n",
      "\n",
      "       For  example to set a static ipv4 address and a static mac address, use\n",
      "       --network bridge:ip=10.88.0.10,mac=44:33:22:11:00:99.  - <network  name\n",
      "       or  ID>[:OPTIONS,...]:  Connect  to a user-defined network; this is the\n",
      "       network name or ID from a network created by podman network create. Us‐\n",
      "       ing the network name implies the bridge network mode. It is possible to\n",
      "       specify the same options described under the bridge mode above. You can\n",
      "       use the --network option multiple times to specify additional networks.\n",
      "       - none: Create a network namespace for the container but do not config‐\n",
      "       ure  network  interfaces for it, thus the container has no network con‐\n",
      "       nectivity.  - container:id: Reuse another container's network stack.  -\n",
      "       host:  Do  not  create  a network namespace, the container will use the\n",
      "       host's network. Note: The host mode gives the container full access  to\n",
      "       local  system  services such as D-bus and is therefore considered inse‐\n",
      "       cure.  - ns:path: Path to a network namespace to join.  - private: Cre‐\n",
      "       ate  a  new  namespace for the container. This will use the bridge mode\n",
      "       for  rootful  containers  and  slirp4netns  for   rootless   ones.    -\n",
      "       slirp4netns[:OPTIONS,...]:  use slirp4netns(1) to create a user network\n",
      "       stack. This is the default for rootless containers. It is  possible  to\n",
      "       specify  these  additional  options,  they  can  also  be set with net‐\n",
      "       work_cmd_options in containers.conf:\n",
      "         - allow_host_loopback=true|false: Allow slirp4netns to reach the host\n",
      "       loopback IP (default is 10.0.2.2 or the second IP from slirp4netns cidr\n",
      "       subnet when changed, see the cidr option below). The default is false.\n",
      "         - mtu=MTU: Specify the MTU to  use  for  this  network.  (Default  is\n",
      "       65520).\n",
      "         -  cidr=CIDR:  Specify  ip range to use for this network. (Default is\n",
      "       10.0.2.0/24).\n",
      "         - enable_ipv6=true|false: Enable IPv6. Default is true. (Required for\n",
      "       outbound_addr6).\n",
      "         -  outbound_addr=INTERFACE:  Specify  the  outbound  interface  slirp\n",
      "       should bind to (ipv4 traffic only).\n",
      "         - outbound_addr=IPv4: Specify the outbound ipv4 address slirp  should\n",
      "       bind to.\n",
      "         -  outbound_addr6=INTERFACE:  Specify  the  outbound  interface slirp\n",
      "       should bind to (ipv6 traffic only).\n",
      "         - outbound_addr6=IPv6: Specify the outbound ipv6 address slirp should\n",
      "       bind to.\n",
      "         -  port_handler=rootlesskit: Use rootlesskit for port forwarding. De‐\n",
      "       fault.\n",
      "         Note: Rootlesskit changes the source IP address of  incoming  packets\n",
      "       to   an   IP  address  in  the  container  network  namespace,  usually\n",
      "       10.0.2.100. If your application requires the real  source  IP  address,\n",
      "       e.g. web server logs, use the slirp4netns port handler. The rootlesskit\n",
      "       port handler is also used for rootless  containers  when  connected  to\n",
      "       user-defined networks.\n",
      "         -  port_handler=slirp4netns:  Use the slirp4netns port forwarding, it\n",
      "       is slower than rootlesskit but preserves the correct source IP address.\n",
      "       This port handler cannot be used for user-defined networks.\n",
      "\n",
      "       Invalid  if  using  --dns, --dns-option, or --dns-search with --network\n",
      "       set to none or container:id.\n",
      "\n",
      "       If used together with --pod, the container will not join the pod's net‐\n",
      "       work namespace.\n",
      "\n",
      "   --network-alias=alias\n",
      "       Add a network-scoped alias for the container, setting the alias for all\n",
      "       networks that the container joins. To set a name only  for  a  specific\n",
      "       network,  use the alias option as described under the --network option.\n",
      "       If the network has DNS enabled (podman  network  inspect  -f  {{.DNSEn‐\n",
      "       abled}}  <name>),  these aliases can be used for name resolution on the\n",
      "       given network. This option can be specified multiple times.  NOTE: When\n",
      "       using  CNI  a  container  will only have access to aliases on the first\n",
      "       network that  it  joins.  This  limitation  does  not  exist  with  ne‐\n",
      "       tavark/aardvark-dns.\n",
      "\n",
      "   --no-healthcheck\n",
      "       Disable any defined healthchecks for container.\n",
      "\n",
      "   --no-hosts\n",
      "       Do  not  create  /etc/hosts for the container.  By default, Podman will\n",
      "       manage /etc/hosts, adding the container's own IP address and any  hosts\n",
      "       from  --add-host.  --no-hosts disables this, and the image's /etc/hosts\n",
      "       will be preserved unmodified.\n",
      "\n",
      "       This option conflicts with --add-host.\n",
      "\n",
      "   --oom-kill-disable\n",
      "       Whether to disable OOM Killer for the container or not.\n",
      "\n",
      "       This flag is not supported on cgroups V2 systems.\n",
      "\n",
      "   --oom-score-adj=num\n",
      "       Tune the host's OOM preferences for  containers  (accepts  values  from\n",
      "       -1000 to 1000).\n",
      "\n",
      "   --os=OS\n",
      "       Override  the OS, defaults to hosts, of the image to be pulled. For ex‐\n",
      "       ample, windows.  Unless overridden, subsequent lookups of the same  im‐\n",
      "       age in the local storage will match this OS, regardless of the host.\n",
      "\n",
      "   --passwd\n",
      "       Allow  Podman to add entries to /etc/passwd and /etc/group when used in\n",
      "       conjunction with the --user option.  This is used to override the  Pod‐\n",
      "       man  provided  user setup in favor of entrypoint configurations such as\n",
      "       libnss-extrausers.\n",
      "\n",
      "   --passwd-entry=ENTRY\n",
      "       Customize the entry that is written to the /etc/passwd file within  the\n",
      "       container when --passwd is used.\n",
      "\n",
      "       The variables $USERNAME, $UID, $GID, $NAME, $HOME are automatically re‐\n",
      "       placed with their value at runtime.\n",
      "\n",
      "   --personality=persona\n",
      "       Personality sets the execution domain via Linux personality(2).\n",
      "\n",
      "   --pid=mode\n",
      "       Set the PID namespace mode for the container.  The default is to create\n",
      "       a private PID namespace for the container.\n",
      "\n",
      "              • container:id: join another container's PID namespace;\n",
      "\n",
      "              • host: use the host's PID namespace for the container. Note the\n",
      "                host mode gives the container full access to local PID and  is\n",
      "                therefore considered insecure;\n",
      "\n",
      "              • ns:path: join the specified PID namespace;\n",
      "\n",
      "              • private: create a new namespace for the container (default).\n",
      "\n",
      "   --pidfile=path\n",
      "       When the pidfile location is specified, the container process' PID will\n",
      "       be written to the pidfile. (This option is not available with  the  re‐\n",
      "       mote  Podman  client,  including  Mac  and Windows (excluding WSL2) ma‐\n",
      "       chines) If the pidfile option is not specified, the container  process'\n",
      "       PID  will  be written to /run/containers/storage/${storage-driver}-con‐\n",
      "       tainers/$CID/userdata/pidfile.\n",
      "\n",
      "       After the container is started, the location for  the  pidfile  can  be\n",
      "       discovered with the following podman inspect command:\n",
      "\n",
      "              $ podman inspect --format '{{ .PidFile }}' $CID\n",
      "              /run/containers/storage/${storage-driver}-containers/$CID/userdata/pidfile\n",
      "\n",
      "   --pids-limit=limit\n",
      "       Tune  the  container's pids limit. Set to -1 to have unlimited pids for\n",
      "       the container. The default is  4096  on  systems  that  support  \"pids\"\n",
      "       cgroup controller.\n",
      "\n",
      "   --platform=OS/ARCH\n",
      "       Specify  the  platform for selecting the image.  (Conflicts with --arch\n",
      "       and --os) The --platform option can be used to override the current ar‐\n",
      "       chitecture and operating system.  Unless overridden, subsequent lookups\n",
      "       of the same image in the local storage will match  this  platform,  re‐\n",
      "       gardless of the host.\n",
      "\n",
      "   --pod=name\n",
      "       Run  container  in  an existing pod. If you want Podman to make the pod\n",
      "       for you, prefix the pod name with new:.  To make a pod with more granu‐\n",
      "       lar  options,  use the podman pod create command before creating a con‐\n",
      "       tainer.  If a container is run with a pod, and the pod  has  an  infra-\n",
      "       container, the infra-container will be started before the container is.\n",
      "\n",
      "   --pod-id-file=file\n",
      "       Run  container in an existing pod and read the pod's ID from the speci‐\n",
      "       fied file.  If a container is run within a pod, and the pod has an  in‐\n",
      "       fra-container, the infra-container will be started before the container\n",
      "       is.\n",
      "\n",
      "   --preserve-fds=N\n",
      "       Pass down to the process N additional file descriptors (in addition  to\n",
      "       0,  1,  2).   The total FDs will be 3+N.  (This option is not available\n",
      "       with the remote Podman client, including  Mac  and  Windows  (excluding\n",
      "       WSL2) machines)\n",
      "\n",
      "   --privileged\n",
      "       Give extended privileges to this container. The default is false.\n",
      "\n",
      "       By default, Podman containers are unprivileged (=false) and cannot, for\n",
      "       example, modify parts of the operating system. This is because  by  de‐\n",
      "       fault  a container is only allowed limited access to devices. A \"privi‐\n",
      "       leged\" container is given the  same  access  to  devices  as  the  user\n",
      "       launching the container.\n",
      "\n",
      "       A privileged container turns off the security features that isolate the\n",
      "       container from the host. Dropped Capabilities, limited  devices,  read-\n",
      "       only mount points, Apparmor/SELinux separation, and Seccomp filters are\n",
      "       all disabled.\n",
      "\n",
      "       Rootless containers cannot have more privileges than the  account  that\n",
      "       launched them.\n",
      "\n",
      "   --publish, -p=[[ip:][hostPort]:]containerPort[/protocol]\n",
      "       Publish a container's port, or range of ports, to the host.\n",
      "\n",
      "       Both  hostPort  and containerPort can be specified as a range of ports.\n",
      "       When specifying ranges for both, the number of container ports  in  the\n",
      "       range must match the number of host ports in the range.\n",
      "\n",
      "       If  host IP is set to 0.0.0.0 or not set at all, the port will be bound\n",
      "       on all IPs on the host.\n",
      "\n",
      "       By default, Podman will publish TCP ports. To publish a  UDP  port  in‐\n",
      "       stead,  give  udp  as  protocol. To publish both TCP and UDP ports, set\n",
      "       --publish twice, with tcp, and udp as protocols  respectively.  Rootful\n",
      "       containers can also publish ports using the sctp protocol.\n",
      "\n",
      "       Host   port  does  not  have  to  be  specified  (e.g.  podman  run  -p\n",
      "       127.0.0.1::80).  If it is not, the container port will be randomly  as‐\n",
      "       signed a port on the host.\n",
      "\n",
      "       Use podman port to see the actual mapping: podman port $CONTAINER $CON‐\n",
      "       TAINERPORT.\n",
      "\n",
      "       Note: If a container will be run within a pod, it is not  necessary  to\n",
      "       publish  the  port for the containers in the pod. The port must only be\n",
      "       published by the pod itself. Pod network stacks act  like  the  network\n",
      "       stack  on  the  host - you have a variety of containers in the pod, and\n",
      "       programs in the container, all sharing a single interface  and  IP  ad‐\n",
      "       dress, and associated ports. If one container binds to a port, no other\n",
      "       container can use that port within the pod while it is in use. Contain‐\n",
      "       ers  in  the pod can also communicate over localhost by having one con‐\n",
      "       tainer bind to localhost in the pod, and another connect to that port.\n",
      "\n",
      "   --publish-all, -P\n",
      "       Publish all exposed ports to random ports on the host  interfaces.  The\n",
      "       default is false.\n",
      "\n",
      "       When set to true, publish all exposed ports to the host interfaces.  If\n",
      "       the operator uses -P (or -p) then Podman will make the exposed port ac‐\n",
      "       cessible on the host and the ports will be available to any client that\n",
      "       can reach the host.\n",
      "\n",
      "       When using this option, Podman will bind any exposed port to  a  random\n",
      "       port   on   the   host  within  an  ephemeral  port  range  defined  by\n",
      "       /proc/sys/net/ipv4/ip_local_port_range.  To find  the  mapping  between\n",
      "       the host ports and the exposed ports, use podman port.\n",
      "\n",
      "   --pull=policy\n",
      "       Pull image policy. The default is missing.\n",
      "\n",
      "              • always:  Always  pull the image and throw an error if the pull\n",
      "                fails.\n",
      "\n",
      "              • missing: Pull the image only if it could not be found  in  the\n",
      "                local containers storage.  Throw an error if no image could be\n",
      "                found and the pull fails.\n",
      "\n",
      "              • never: Never pull the image but use the  one  from  the  local\n",
      "                containers  storage.   Throw  an  error  if  no image could be\n",
      "                found.\n",
      "\n",
      "              • newer: Pull if the image on the registry is newer than the one\n",
      "                in the local containers storage.  An image is considered to be\n",
      "                newer when the digests  are  different.   Comparing  the  time\n",
      "                stamps  is  prone  to errors.  Pull errors are suppressed if a\n",
      "                local image was found.\n",
      "\n",
      "   --quiet, -q\n",
      "       Suppress output information when pulling images\n",
      "\n",
      "   --read-only\n",
      "       Mount the container's root filesystem as read-only.\n",
      "\n",
      "       By default a container will have its root filesystem writable  allowing\n",
      "       processes  to write files anywhere. By specifying the --read-only flag,\n",
      "       the container will have its root filesystem mounted as  read-only  pro‐\n",
      "       hibiting any writes.\n",
      "\n",
      "   --read-only-tmpfs\n",
      "       If  container  is  running in --read-only mode, then mount a read-write\n",
      "       tmpfs on /run, /tmp, and /var/tmp. The default is true.\n",
      "\n",
      "   --replace\n",
      "       If another container with the same name already exists, replace and re‐\n",
      "       move it. The default is false.\n",
      "\n",
      "   --requires=container\n",
      "       Specify  one  or more requirements.  A requirement is a dependency con‐\n",
      "       tainer that will be started before this container.  Containers  can  be\n",
      "       specified  by  name  or ID, with multiple containers being separated by\n",
      "       commas.\n",
      "\n",
      "   --restart=policy\n",
      "       Restart policy to follow when containers exit.  Restart policy will not\n",
      "       take  effect  if  a  container is stopped via the podman kill or podman\n",
      "       stop commands.\n",
      "\n",
      "       Valid policy values are:\n",
      "\n",
      "              • no                       : Do not restart containers on exit\n",
      "\n",
      "              • on-failure[:max_retries] : Restart containers when  they  exit\n",
      "                with  a non-zero exit code, retrying indefinitely or until the\n",
      "                optional max_retries count is hit\n",
      "\n",
      "              • always                   : Restart containers when they  exit,\n",
      "                regardless of status, retrying indefinitely\n",
      "\n",
      "              • unless-stopped           : Identical to always\n",
      "\n",
      "       Please note that restart will not restart containers after a system re‐\n",
      "       boot.  If this functionality is required in your environment,  you  can\n",
      "       invoke Podman from a systemd.unit(5) file, or create an init script for\n",
      "       whichever init system is in  use.   To  generate  systemd  unit  files,\n",
      "       please see podman generate systemd.\n",
      "\n",
      "   --rm\n",
      "       Automatically remove the container when it exits. The default is false.\n",
      "\n",
      "   --rmi\n",
      "       After  exit of the container, remove the image unless another container\n",
      "       is using it. The default is false.\n",
      "\n",
      "   --rootfs\n",
      "       If specified, the first argument refers to an exploded container on the\n",
      "       file system.\n",
      "\n",
      "       This  is  useful to run a container without requiring any image manage‐\n",
      "       ment, the rootfs of the container is assumed to be managed externally.\n",
      "\n",
      "       Overlay Rootfs Mounts\n",
      "\n",
      "       The :O flag tells Podman to mount the directory from the rootfs path as\n",
      "       storage using the overlay file system. The container processes can mod‐\n",
      "       ify content within the mount point which is  stored  in  the  container\n",
      "       storage in a separate directory. In overlay terms, the source directory\n",
      "       will be the lower, and the container storage directory will be the  up‐\n",
      "       per.  Modifications to the mount point are destroyed when the container\n",
      "       finishes executing, similar to a tmpfs mount point being unmounted.\n",
      "\n",
      "       Note: On SELinux systems, the rootfs needs the correct label, which  is\n",
      "       by default unconfined_u:object_r:container_file_t:s0.\n",
      "\n",
      "   --sdnotify=container | conmon | ignore\n",
      "       Determines  how  to  use  the NOTIFY_SOCKET, as passed with systemd and\n",
      "       Type=notify.\n",
      "\n",
      "       Default is container, which means allow the OCI runtime  to  proxy  the\n",
      "       socket  into  the  container to receive ready notification. Podman will\n",
      "       set the MAINPID to conmon's pid.  The conmon  option  sets  MAINPID  to\n",
      "       conmon's  pid,  and  sends  READY  when  the container has started. The\n",
      "       socket is never passed to the runtime or the container.  The ignore op‐\n",
      "       tion  removes  NOTIFY_SOCKET  from the environment for itself and child\n",
      "       processes, for the case where some other process above Podman uses  NO‐\n",
      "       TIFY_SOCKET and Podman should not use it.\n",
      "\n",
      "   --seccomp-policy=policy\n",
      "       Specify the policy to select the seccomp profile. If set to image, Pod‐\n",
      "       man will look for a \"io.containers.seccomp.profile\" label in  the  con‐\n",
      "       tainer-image  config and use its value as a seccomp profile. Otherwise,\n",
      "       Podman will follow the default policy by applying the  default  profile\n",
      "       unless  specified otherwise via --security-opt seccomp as described be‐\n",
      "       low.\n",
      "\n",
      "       Note that this feature is experimental and may change in the future.\n",
      "\n",
      "   --secret=secret[,opt=opt ...]\n",
      "       Give the container access to a secret. Can be specified multiple times.\n",
      "\n",
      "       A secret is a blob of sensitive data which a container needs at runtime\n",
      "       but  should  not  be  stored in the image or in source control, such as\n",
      "       usernames and passwords, TLS certificates and keys, SSH keys  or  other\n",
      "       important generic strings or binary content (up to 500 kb in size).\n",
      "\n",
      "       When  secrets  are  specified as type mount, the secrets are copied and\n",
      "       mounted into the container when a container is created.   When  secrets\n",
      "       are  specified  as  type  env, the secret will be set as an environment\n",
      "       variable within the container.  Secrets are written in the container at\n",
      "       the  time  of container creation, and modifying the secret using podman\n",
      "       secret commands after the container is created will not affect the  se‐\n",
      "       cret inside the container.\n",
      "\n",
      "       Secrets and its storage are managed using the podman secret command.\n",
      "\n",
      "       Secret Options\n",
      "\n",
      "              • type=mount|env    : How the secret will be exposed to the con‐\n",
      "                tainer. Default mount.\n",
      "\n",
      "              • target=target     : Target of secret. Defaults to secret name.\n",
      "\n",
      "              • uid=0             : UID of secret. Defaults to 0. Mount secret\n",
      "                type only.\n",
      "\n",
      "              • gid=0             : GID of secret. Defaults to 0. Mount secret\n",
      "                type only.\n",
      "\n",
      "              • mode=0            : Mode of secret. Defaults  to  0444.  Mount\n",
      "                secret type only.\n",
      "\n",
      "   --security-opt=option\n",
      "       Security Options\n",
      "\n",
      "              • apparmor=unconfined  :  Turn  off apparmor confinement for the\n",
      "                container\n",
      "\n",
      "              • apparmor=your-profile : Set the apparmor  confinement  profile\n",
      "                for the container\n",
      "\n",
      "              • label=user:USER:  Set  the  label  user for the container pro‐\n",
      "                cesses\n",
      "\n",
      "              • label=role:ROLE: Set the label role  for  the  container  pro‐\n",
      "                cesses\n",
      "\n",
      "              • label=type:TYPE:  Set the label process type for the container\n",
      "                processes\n",
      "\n",
      "              • label=level:LEVEL: Set the label level for the container  pro‐\n",
      "                cesses\n",
      "\n",
      "              • label=filetype:TYPE_:  Set  the  label  file type for the con‐\n",
      "                tainer files\n",
      "\n",
      "              • label=disable: Turn off label separation for the container\n",
      "\n",
      "       Note: Labeling can be  disabled  for  all  containers  by  setting  la‐\n",
      "       bel=false  in  the  containers.conf (/etc/containers/containers.conf or\n",
      "       $HOME/.config/containers/containers.conf) file.\n",
      "\n",
      "              • mask=/path/1:/path/2: The paths to mask separated by a  colon.\n",
      "                A masked path cannot be accessed inside the container.\n",
      "\n",
      "              • no-new-privileges:  Disable  container  processes from gaining\n",
      "                additional privileges\n",
      "\n",
      "              • seccomp=unconfined: Turn off seccomp confinement for the  con‐\n",
      "                tainer.\n",
      "\n",
      "              • seccomp=profile.json:  JSON  file to be used as a seccomp fil‐\n",
      "                ter. Note that the io.podman.annotations.seccomp annotation is\n",
      "                set with the specified value as shown in podman inspect.\n",
      "\n",
      "              • proc-opts=OPTIONS : Comma-separated list of options to use for\n",
      "                the /proc mount. More details for the possible  mount  options\n",
      "                are specified in the proc(5) man page.\n",
      "\n",
      "              • unmask=ALL   or   /path/1:/path/2,  or  shell  expanded  paths\n",
      "                (/proc/*): Paths to unmask separated by a  colon.  If  set  to\n",
      "                ALL,  it  will  unmask  all  the paths that are masked or made\n",
      "                read-only  by  default.   The   default   masked   paths   are\n",
      "                /proc/acpi,   /proc/kcore,   /proc/keys,  /proc/latency_stats,\n",
      "                /proc/sched_debug,        /proc/scsi,        /proc/timer_list,\n",
      "                /proc/timer_stats,  /sys/firmware,  and /sys/fs/selinux..  The\n",
      "                default paths that are read-only are /proc/asound,  /proc/bus,\n",
      "                /proc/fs,     /proc/irq,    /proc/sys,    /proc/sysrq-trigger,\n",
      "                /sys/fs/cgroup.\n",
      "\n",
      "       Note: Labeling can be  disabled  for  all  containers  by  setting  la‐\n",
      "       bel=false in the containers.conf(5) file.\n",
      "\n",
      "   --shm-size=number[unit]\n",
      "       Size   of  /dev/shm.  A  unit  can  be  b  (bytes),  k  (kibibytes),  m\n",
      "       (mebibytes), or g (gibibytes).  If the unit is omitted, the system uses\n",
      "       bytes.  If  the  size  is omitted, the default is 64m.  When size is 0,\n",
      "       there is no limit on the amount of memory used  for  IPC  by  the  con‐\n",
      "       tainer.  This option conflicts with --ipc=host.\n",
      "\n",
      "   --sig-proxy\n",
      "       Proxy  received  signals  to the container process (non-TTY mode only).\n",
      "       SIGCHLD, SIGSTOP, and SIGKILL are not proxied.\n",
      "\n",
      "       The default is true.\n",
      "\n",
      "   --stop-signal=signal\n",
      "       Signal to stop a container. Default is SIGTERM.\n",
      "\n",
      "   --stop-timeout=seconds\n",
      "       Timeout to stop a container. Default is 10.  Remote connections use lo‐\n",
      "       cal containers.conf for defaults\n",
      "\n",
      "   --subgidname=name\n",
      "       Run  the  container  in a new user namespace using the map with name in\n",
      "       the /etc/subgid file.  If running rootless, the user needs to have  the\n",
      "       right  to  use  the  mapping.  See subgid(5).  This flag conflicts with\n",
      "       --userns and --gidmap.\n",
      "\n",
      "   --subuidname=name\n",
      "       Run the container in a new user namespace using the map  with  name  in\n",
      "       the  /etc/subuid file.  If running rootless, the user needs to have the\n",
      "       right to use the mapping. See  subuid(5).   This  flag  conflicts  with\n",
      "       --userns and --uidmap.\n",
      "\n",
      "   --sysctl=name=value\n",
      "       Configure namespaced kernel parameters at runtime.\n",
      "\n",
      "       For the IPC namespace, the following sysctls are allowed:\n",
      "\n",
      "              • kernel.msgmax\n",
      "\n",
      "              • kernel.msgmnb\n",
      "\n",
      "              • kernel.msgmni\n",
      "\n",
      "              • kernel.sem\n",
      "\n",
      "              • kernel.shmall\n",
      "\n",
      "              • kernel.shmmax\n",
      "\n",
      "              • kernel.shmmni\n",
      "\n",
      "              • kernel.shm_rmid_forced\n",
      "\n",
      "              • Sysctls beginning with fs.mqueue.*\n",
      "\n",
      "       Note:  if  you use the --ipc=host option, the above sysctls are not al‐\n",
      "       lowed.\n",
      "\n",
      "       For the network namespace, only sysctls beginning with  net.*  are  al‐\n",
      "       lowed.\n",
      "\n",
      "       Note:  if  you use the --network=host option, the above sysctls are not\n",
      "       allowed.\n",
      "\n",
      "   --systemd=true | false | always\n",
      "       Run container in systemd mode. The default is true.\n",
      "\n",
      "       The value always enforces the systemd mode is enforced without  looking\n",
      "       at  the  executable name. Otherwise, if set to true and the command you\n",
      "       are running inside the container is systemd, /usr/sbin/init, /sbin/init\n",
      "       or /usr/local/sbin/init.\n",
      "\n",
      "       Running the container in systemd mode causes the following changes:\n",
      "\n",
      "              • Podman mounts tmpfs file systems on the following directories\n",
      "\n",
      "                • /run\n",
      "\n",
      "                • /run/lock\n",
      "\n",
      "                • /tmp\n",
      "\n",
      "                • /sys/fs/cgroup/systemd\n",
      "\n",
      "                • /var/lib/journal\n",
      "\n",
      "              • Podman sets the default stop signal to SIGRTMIN+3.\n",
      "\n",
      "              • Podman  sets  container_uuid  environment variable in the con‐\n",
      "                tainer to the first 32 characters of the container id.\n",
      "\n",
      "       This allows systemd to run in a confined container without any  modifi‐\n",
      "       cations.\n",
      "\n",
      "       Note  that  on SELinux systems, systemd attempts to write to the cgroup\n",
      "       file system. Containers writing to the cgroup file system are denied by\n",
      "       default.   The container_manage_cgroup boolean must be enabled for this\n",
      "       to be allowed on an SELinux separated system.\n",
      "\n",
      "              setsebool -P container_manage_cgroup true\n",
      "\n",
      "   --timeout=seconds\n",
      "       Maximum time a container is allowed to run before conmon sends  it  the\n",
      "       kill  signal.   By  default  containers will run until they exit or are\n",
      "       stopped by podman stop.\n",
      "\n",
      "   --tls-verify\n",
      "       Require HTTPS and verify certificates when contacting  registries  (de‐\n",
      "       fault:  true).   If  explicitly  set  to true, TLS verification will be\n",
      "       used.  If set to false, TLS verification will  not  be  used.   If  not\n",
      "       specified,  TLS verification will be used unless the target registry is\n",
      "       listed as an insecure registry in containers-registries.conf(5)\n",
      "\n",
      "   --tmpfs=fs\n",
      "       Create a tmpfs mount.\n",
      "\n",
      "       Mount a temporary filesystem (tmpfs) mount into a container, for  exam‐\n",
      "       ple:\n",
      "\n",
      "              $ podman run -d --tmpfs /tmp:rw,size=787448k,mode=1777 my_image\n",
      "\n",
      "       This command mounts a tmpfs at /tmp within the container. The supported\n",
      "       mount options are the same as the Linux default mount flags. If you  do\n",
      "       not  specify  any  options,  the  system  uses  the  following options:\n",
      "       rw,noexec,nosuid,nodev.\n",
      "\n",
      "   --tty, -t\n",
      "       Allocate a pseudo-TTY. The default is false.\n",
      "\n",
      "       When set to true, Podman will allocate a pseudo-tty and attach  to  the\n",
      "       standard  input of the container. This can be used, for example, to run\n",
      "       a throwaway interactive shell.\n",
      "\n",
      "       NOTE: The --tty flag prevents redirection of standard output.  It  com‐\n",
      "       bines  STDOUT  and STDERR, it can insert control characters, and it can\n",
      "       hang pipes. This option should only be used when run interactively in a\n",
      "       terminal. When feeding input to Podman, use -i only, not -it.\n",
      "\n",
      "              echo \"asdf\" | podman run --rm -i someimage /bin/cat\n",
      "\n",
      "   --tz=timezone\n",
      "       Set  timezone  in  container. This flag takes area-based timezones, GMT\n",
      "       time, as well as local, which sets the timezone  in  the  container  to\n",
      "       match  the  host machine. See /usr/share/zoneinfo/ for valid timezones.\n",
      "       Remote connections use local containers.conf for defaults\n",
      "\n",
      "   --uidmap=container_uid:from_uid:amount\n",
      "       Run the container in a new user namespace using the supplied  UID  map‐\n",
      "       ping. This option conflicts with the --userns and --subuidname options.\n",
      "       This option provides a way to map host UIDs to container UIDs.  It  can\n",
      "       be passed several times to map different ranges.\n",
      "\n",
      "       The  _fromuid  value is based upon the user running the command, either\n",
      "       rootful    or    rootless    users.     *    rootful    user:      con‐\n",
      "       tainer_uid:host_uid:amount  *  rootless  user: container_uid:intermedi‐\n",
      "       ate_uid:amount\n",
      "\n",
      "       When podman run is called by a privileged  user,  the  option  --uidmap\n",
      "       works as a direct mapping between host UIDs and container UIDs.\n",
      "\n",
      "       host UID -> container UID\n",
      "\n",
      "       The  amount  specifies  the  number  of  consecutive  UIDs that will be\n",
      "       mapped.  If for example amount is 4 the mapping would look like:\n",
      "\n",
      "       |    host  UID      |     container  UID     |  |  -               |  -\n",
      "       | | _fromuid     | _containeruid     | | _fromuid + 1 | _containeruid +\n",
      "       1 | | _fromuid + 2 | _containeruid + 2 | | _fromuid + 3 | _containeruid\n",
      "       + 3 |\n",
      "\n",
      "       When  podman  run is called by an unprivileged user (i.e. running root‐\n",
      "       less), the value _fromuid is interpreted as an \"intermediate  UID\".  In\n",
      "       the rootless case, host UIDs are not mapped directly to container UIDs.\n",
      "       Instead the mapping happens over two mapping steps:\n",
      "\n",
      "       host UID -> intermediate UID -> container UID\n",
      "\n",
      "       The --uidmap option only influences the second mapping step.\n",
      "\n",
      "       The first mapping step is derived by Podman from the  contents  of  the\n",
      "       file /etc/subuid and the UID of the user calling Podman.\n",
      "\n",
      "       First mapping step:\n",
      "\n",
      "       | host UID                                         | intermediate UID |\n",
      "       | -                                                |                - |\n",
      "       | UID for the user starting Podman                 |                0 |\n",
      "       | 1st subordinate UID for the user starting Podman |                1 |\n",
      "       | 2nd subordinate UID for the user starting Podman |                2 |\n",
      "       | 3rd subordinate UID for the user starting Podman |                3 |\n",
      "       | nth subordinate UID for the user starting Podman |                n |\n",
      "\n",
      "       To  be  able to use intermediate UIDs greater than zero, the user needs\n",
      "       to have subordinate UIDs configured in /etc/subuid. See subuid(5).\n",
      "\n",
      "       The second mapping step is configured with --uidmap.\n",
      "\n",
      "       If for example amount is 5 the second mapping step would look like:\n",
      "\n",
      "       |   intermediate UID   |    container UID    | | -                    |\n",
      "       -                    |  |  _fromuid            |  _containeruid     | |\n",
      "       _fromuid + 1       | _containeruid + 1 | | _fromuid + 2        |  _con‐\n",
      "       taineruid + 2 | | _fromuid + 3       | _containeruid + 3 | | _fromuid +\n",
      "       4       | _containeruid + 4 |\n",
      "\n",
      "       When running as rootless, Podman will use all the ranges configured  in\n",
      "       the /etc/subuid file.\n",
      "\n",
      "       The  current user ID is mapped to UID=0 in the rootless user namespace.\n",
      "       Every additional range is added sequentially afterward:\n",
      "\n",
      "       |     host                  |rootless   user   namespace    |    length\n",
      "       |    |    -                        |    -                         |   -\n",
      "       |   |    $UID                     |    0                         |    1\n",
      "       |     |     1                         |     $FIRST_RANGE_ID           |\n",
      "       $FIRST_RANGE_LENGTH  |  |  1+$FIRST_RANGE_LENGTH   |   $SECOND_RANGE_ID\n",
      "       | $SECOND_RANGE_LENGTH|\n",
      "\n",
      "       Even  if  a  user  does  not have any subordinate UIDs in  /etc/subuid,\n",
      "       --uidmap could still be used to map the normal UID of  the  user  to  a\n",
      "       container  UID by running podman run --uidmap $container_uid:0:1 --user\n",
      "       $container_uid ....\n",
      "\n",
      "       Note: the --uidmap flag cannot be called in conjunction with the  --pod\n",
      "       flag as a uidmap cannot be set on the container level when in a pod.\n",
      "\n",
      "   --ulimit=option\n",
      "       Ulimit options. You can use host to copy the current configuration from\n",
      "       the host.\n",
      "\n",
      "   --umask=umask\n",
      "       Set the umask inside the container. Defaults to 0022.   Remote  connec‐\n",
      "       tions use local containers.conf for defaults\n",
      "\n",
      "   --unsetenv=env\n",
      "       Unset default environment variables for the container. Default environ‐\n",
      "       ment variables include variables provided natively by Podman,  environ‐\n",
      "       ment  variables configured by the image, and environment variables from\n",
      "       containers.conf.\n",
      "\n",
      "   --unsetenv-all\n",
      "       Unset all default environment variables for the container. Default  en‐\n",
      "       vironment  variables include variables provided natively by Podman, en‐\n",
      "       vironment variables configured by the image, and environment  variables\n",
      "       from containers.conf.\n",
      "\n",
      "   --user, -u=user[:group]\n",
      "       Sets the username or UID used and, optionally, the groupname or GID for\n",
      "       the specified command. Both user and group may be symbolic or numeric.\n",
      "\n",
      "       Without this argument, the command will run as the  user  specified  in\n",
      "       the  container  image.  Unless overridden by a USER command in the Con‐\n",
      "       tainerfile or by a value passed to this option, this user generally de‐\n",
      "       faults to root.\n",
      "\n",
      "       When  a  user  namespace is not in use, the UID and GID used within the\n",
      "       container and on the host will match. When user namespaces are in  use,\n",
      "       however, the UID and GID in the container may correspond to another UID\n",
      "       and GID on the host. In rootless containers, for example, a user  name‐\n",
      "       space  is always used, and root in the container will by default corre‐\n",
      "       spond to the UID and GID of the user invoking Podman.\n",
      "\n",
      "   --userns=mode\n",
      "       Set the user namespace mode for the container. It defaults to the  POD‐\n",
      "       MAN_USERNS  environment  variable. An empty value (\"\") means user name‐\n",
      "       spaces are disabled unless an explicit mapping is set with the --uidmap\n",
      "       and --gidmap options.\n",
      "\n",
      "       This  option  is incompatible with --gidmap, --uidmap, --subuidname and\n",
      "       --subgidname.\n",
      "\n",
      "       Rootless user --userns=Key mappings:\n",
      "\n",
      "       ┌────────┬───────────┬─────────────────────┐\n",
      "       │Key     │ Host User │ Container User      │\n",
      "       ├────────┼───────────┼─────────────────────┤\n",
      "       │\"\"      │ $UID      │ 0 (Default User ac‐ │\n",
      "       │        │           │ count   mapped   to │\n",
      "       │        │           │ root user  in  con‐ │\n",
      "       │        │           │ tainer.)            │\n",
      "       ├────────┼───────────┼─────────────────────┤\n",
      "       │keep-id │ $UID      │ $UID  (Map user ac‐ │\n",
      "       │        │           │ count to  same  UID │\n",
      "       │        │           │ within container.)  │\n",
      "       ├────────┼───────────┼─────────────────────┤\n",
      "       │auto    │ $UID      │ nil  (Host User UID │\n",
      "       │        │           │ is not mapped  into │\n",
      "       │        │           │ container.)         │\n",
      "       ├────────┼───────────┼─────────────────────┤\n",
      "       │nomap   │ $UID      │ nil  (Host User UID │\n",
      "       │        │           │ is not mapped  into │\n",
      "       │        │           │ container.)         │\n",
      "       └────────┴───────────┴─────────────────────┘\n",
      "\n",
      "       Valid mode values are:\n",
      "\n",
      "       auto[:OPTIONS,...]: automatically create a unique user namespace.\n",
      "\n",
      "       The  --userns=auto  flag,  requires that the user name containers and a\n",
      "       range of subordinate user ids that the Podman container is  allowed  to\n",
      "       use be specified in the /etc/subuid and /etc/subgid files.\n",
      "\n",
      "       Example: containers:2147483647:2147483648.\n",
      "\n",
      "       Podman  allocates  unique  ranges  of UIDs and GIDs from the containers\n",
      "       subordinate user ids. The size of the ranges is based on the number  of\n",
      "       UIDs required in the image. The number of UIDs and GIDs can be overrid‐\n",
      "       den with the size option.\n",
      "\n",
      "       The rootless option --userns=keep-id uses all the subuids  and  subgids\n",
      "       of  the user. Using --userns=auto when starting new containers will not\n",
      "       work  as  long  as  any  containers  exist  that  were   started   with\n",
      "       --userns=keep-id.\n",
      "\n",
      "       Valid auto options:\n",
      "\n",
      "              • gidmapping=_CONTAINER_GID:HOSTGID:SIZE: to force a GID mapping\n",
      "                to be present in the user namespace.\n",
      "\n",
      "              • size=SIZE: to specify an explicit size for the automatic  user\n",
      "                namespace. e.g. --userns=auto:size=8192. If size is not speci‐\n",
      "                fied, auto will estimate a size for the user namespace.\n",
      "\n",
      "              • uidmapping=_CONTAINER_UID:HOSTUID:SIZE: to force a UID mapping\n",
      "                to be present in the user namespace.\n",
      "\n",
      "       container:id: join the user namespace of the specified container.\n",
      "\n",
      "       host: run in the user namespace of the caller. The processes running in\n",
      "       the container will have the same privileges on the host  as  any  other\n",
      "       process launched by the calling user (default).\n",
      "\n",
      "       keep-id:  creates  a  user  namespace where the current rootless user's\n",
      "       UID:GID are mapped to the same values in the container. This option  is\n",
      "       not allowed for containers created by the root user.\n",
      "\n",
      "       Valid keep-id options:\n",
      "\n",
      "              • uid=UID:  override  the  UID inside the container that will be\n",
      "                used to map the current rootless user to.\n",
      "\n",
      "              • gid=GID: override the GID inside the container  that  will  be\n",
      "                used to map the current rootless user to.\n",
      "\n",
      "       nomap:  creates  a  user  namespace  where  the current rootless user's\n",
      "       UID:GID are not mapped into the container. This option is  not  allowed\n",
      "       for containers created by the root user.\n",
      "\n",
      "       ns:namespace: run the container in the given existing user namespace.\n",
      "\n",
      "   --uts=mode\n",
      "       Set  the UTS namespace mode for the container. The following values are\n",
      "       supported:\n",
      "\n",
      "              • host: use the host's UTS namespace inside the container.\n",
      "\n",
      "              • private: create a new namespace for the container (default).\n",
      "\n",
      "              • ns:[path]: run the container in the given existing  UTS  name‐\n",
      "                space.\n",
      "\n",
      "              • container:[container]: join the UTS namespace of the specified\n",
      "                container.\n",
      "\n",
      "   --variant=VARIANT\n",
      "       Use VARIANT instead of the default architecture  variant  of  the  con‐\n",
      "       tainer  image.  Some images can use multiple variants of the arm archi‐\n",
      "       tectures, such as arm/v5 and arm/v7.\n",
      "\n",
      "   --volume, -v=[[SOURCE-VOLUME|HOST-DIR:]CONTAINER-DIR[:OPTIONS]]\n",
      "       Create a bind mount. If -v /HOST-DIR:/CONTAINER-DIR is specified,  Pod‐\n",
      "       man bind mounts /HOST-DIR from the host into /CONTAINER-DIR in the Pod‐\n",
      "       man container. Similarly, -v  SOURCE-VOLUME:/CONTAINER-DIR  will  mount\n",
      "       the  named  volume  from  the host into the container. If no such named\n",
      "       volume exists, Podman will create one. If no source is given, the  vol‐\n",
      "       ume will be created as an anonymously named volume with a randomly gen‐\n",
      "       erated name, and will be removed when the container is removed via  the\n",
      "       --rm flag or the podman rm --volumes command.\n",
      "\n",
      "       (Note  when using the remote client, including Mac and Windows (exclud‐\n",
      "       ing WSL2) machines, the volumes will be mounted from the remote server,\n",
      "       not necessarily the client machine.)\n",
      "\n",
      "       The OPTIONS is a comma-separated list and can be: [1] ⟨#Footnote1⟩\n",
      "\n",
      "              • rw|ro\n",
      "\n",
      "              • z|Z\n",
      "\n",
      "              • [O]\n",
      "\n",
      "              • [U]\n",
      "\n",
      "              • [no]copy\n",
      "\n",
      "              • [no]dev\n",
      "\n",
      "              • [no]exec\n",
      "\n",
      "              • [no]suid\n",
      "\n",
      "              • [r]bind\n",
      "\n",
      "              • [r]shared|[r]slave|[r]private[r]unbindable\n",
      "\n",
      "       The  CONTAINER-DIR must be an absolute path such as /src/docs. The vol‐\n",
      "       ume will be mounted into the container at this directory.\n",
      "\n",
      "       If a volume source is specified, it must be a path on the host  or  the\n",
      "       name  of a named volume. Host paths are allowed to be absolute or rela‐\n",
      "       tive; relative paths are resolved relative to the directory  Podman  is\n",
      "       run  in.  If  the  source  does not exist, Podman will return an error.\n",
      "       Users must pre-create the source files or directories.\n",
      "\n",
      "       Any source that does not begin with a . or / will  be  treated  as  the\n",
      "       name  of  a named volume. If a volume with that name does not exist, it\n",
      "       will be created.  Volumes created with names  are  not  anonymous,  and\n",
      "       they  are  not  removed  by the --rm option and the podman rm --volumes\n",
      "       command.\n",
      "\n",
      "       Specify multiple -v options to mount one or more volumes  into  a  con‐\n",
      "       tainer.\n",
      "\n",
      "       Write Protected Volume Mounts\n",
      "\n",
      "       Add  :ro  or  :rw  option  to mount a volume in read-only or read-write\n",
      "       mode, respectively. By default, the  volumes  are  mounted  read-write.\n",
      "       See examples.\n",
      "\n",
      "       Chowning Volume Mounts\n",
      "\n",
      "       By default, Podman does not change the owner and group of source volume\n",
      "       directories mounted into containers. If a container is created in a new\n",
      "       user  namespace, the UID and GID in the container may correspond to an‐\n",
      "       other UID and GID on the host.\n",
      "\n",
      "       The :U suffix tells Podman to use the correct host UID and GID based on\n",
      "       the  UID  and GID within the container, to change recursively the owner\n",
      "       and group of the source volume.\n",
      "\n",
      "       Warning use with caution since this will modify the host filesystem.\n",
      "\n",
      "       Labeling Volume Mounts\n",
      "\n",
      "       Labeling systems like SELinux require that proper labels are placed  on\n",
      "       volume  content mounted into a container. Without a label, the security\n",
      "       system might prevent the processes running inside  the  container  from\n",
      "       using the content. By default, Podman does not change the labels set by\n",
      "       the OS.\n",
      "\n",
      "       To change a label in the container context, add either of two  suffixes\n",
      "       :z  or  :Z  to  the volume mount. These suffixes tell Podman to relabel\n",
      "       file objects on the shared volumes. The z option tells Podman that  two\n",
      "       containers  share  the  volume  content. As a result, Podman labels the\n",
      "       content with a shared content label. Shared  volume  labels  allow  all\n",
      "       containers  to  read/write content.  The Z option tells Podman to label\n",
      "       the content with a private unshared label.  Only the current  container\n",
      "       can use a private volume.\n",
      "\n",
      "       Note:  Do  not  relabel system files and directories. Relabeling system\n",
      "       content might cause other confined services on your  machine  to  fail.\n",
      "       For  these  types  of containers we recommend disabling SELinux separa‐\n",
      "       tion.  The option --security-opt label=disable disables SELinux separa‐\n",
      "       tion  for  the container.  For example if a user wanted to volume mount\n",
      "       their entire home directory into a  container,  they  need  to  disable\n",
      "       SELinux separation.\n",
      "\n",
      "                 $ podman run --security-opt label=disable -v $HOME:/home/user fedora touch /home/user/file\n",
      "\n",
      "       Overlay Volume Mounts\n",
      "\n",
      "       The :O flag tells Podman to mount the directory from the host as a tem‐\n",
      "       porary storage using the overlay file system. The  container  processes\n",
      "       can  modify  content  within the mountpoint which is stored in the con‐\n",
      "       tainer storage in a separate directory. In overlay  terms,  the  source\n",
      "       directory  will  be the lower, and the container storage directory will\n",
      "       be the upper. Modifications to the mount point are destroyed  when  the\n",
      "       container  finishes executing, similar to a tmpfs mount point being un‐\n",
      "       mounted.\n",
      "\n",
      "       For advanced users,  the  overlay  option  also  supports  custom  non-\n",
      "       volatile  upperdir  and  workdir for the overlay mount. Custom upperdir\n",
      "       and workdir can be fully managed by the users  themselves,  and  Podman\n",
      "       will   not   remove   it   on  lifecycle  completion.   Example  :O,up‐\n",
      "       perdir=/some/upper,workdir=/some/work\n",
      "\n",
      "       Subsequent executions of the container will see the original source di‐\n",
      "       rectory  content,  any  changes  from  previous container executions no\n",
      "       longer exist.\n",
      "\n",
      "       One use case of the overlay mount is sharing the package cache from the\n",
      "       host into the container to allow speeding up builds.\n",
      "\n",
      "       Note:\n",
      "\n",
      "               - The `O` flag conflicts with other options listed above.\n",
      "\n",
      "       Content mounted into the container is labeled with the private label.\n",
      "              On SELinux systems, labels in the source directory must be read‐\n",
      "       able by the  container label. Usually containers can read/execute  con‐\n",
      "       tainer_share_t and can read/write container_file_t. If unable to change\n",
      "       the labels on a source volume, SELinux  container  separation  must  be\n",
      "       disabled for the  container to work.\n",
      "            -  The source directory mounted into the container with an overlay\n",
      "       mount should not be modified, it can cause unexpected failures.  It  is\n",
      "       recommended  to  not  modify the directory until the container finishes\n",
      "       running.\n",
      "\n",
      "       Mounts propagation\n",
      "\n",
      "       By default bind mounted volumes are private. That means any mounts done\n",
      "       inside  the  container  will not be visible on host and vice versa. One\n",
      "       can change this behavior by specifying a volume mount propagation prop‐\n",
      "       erty.  Making  a volume shared mounts done under that volume inside the\n",
      "       container will be visible on host and vice versa. Making a volume slave\n",
      "       enables  only one way mount propagation and that is mounts done on host\n",
      "       under that volume will be visible inside container but  not  the  other\n",
      "       way around. [1] ⟨#Footnote1⟩\n",
      "\n",
      "       To  control  mount  propagation  property  of  a volume one can use the\n",
      "       [r]shared, [r]slave, [r]private or the [r]unbindable propagation  flag.\n",
      "       Propagation property can be specified only for bind mounted volumes and\n",
      "       not for internal volumes or named volumes.  For  mount  propagation  to\n",
      "       work  the  source  mount  point  (the  mount  point where source dir is\n",
      "       mounted on) has to have the right propagation  properties.  For  shared\n",
      "       volumes,  the  source  mount point has to be shared. And for slave vol‐\n",
      "       umes, the source mount point has to be either  shared  or  slave.   [1]\n",
      "       ⟨#Footnote1⟩\n",
      "\n",
      "       To  recursively  mount  a  volume  and all of its submounts into a con‐\n",
      "       tainer, use the rbind option. By default the bind option is  used,  and\n",
      "       submounts  of  the  source  directory will not be mounted into the con‐\n",
      "       tainer.\n",
      "\n",
      "       Mounting the volume with the nosuid options means  that  SUID  applica‐\n",
      "       tions  on the volume will not be able to change their privilege. By de‐\n",
      "       fault volumes are mounted with nosuid.\n",
      "\n",
      "       Mounting the volume with the noexec option means that no executables on\n",
      "       the volume will be able to be executed within the container.\n",
      "\n",
      "       Mounting  the volume with the nodev option means that no devices on the\n",
      "       volume will be able to be used by processes within  the  container.  By\n",
      "       default volumes are mounted with nodev.\n",
      "\n",
      "       If  the HOST-DIR is a mount point, then dev, suid, and exec options are\n",
      "       ignored by the kernel.\n",
      "\n",
      "       Use df HOST-DIR to figure out the source mount,  then  use  findmnt  -o\n",
      "       TARGET,PROPAGATION  source-mount-dir  to figure out propagation proper‐\n",
      "       ties of source mount. If findmnt(1) utility is not available, then  one\n",
      "       can   look   at   the  mount  entry  for  the  source  mount  point  in\n",
      "       /proc/self/mountinfo. Look at the \"optional  fields\"  and  see  if  any\n",
      "       propagation  properties  are  specified.   In there, shared:N means the\n",
      "       mount is shared, master:N means mount  is  slave,  and  if  nothing  is\n",
      "       there, the mount is private. [1] ⟨#Footnote1⟩\n",
      "\n",
      "       To  change  propagation  properties of a mount point, use mount(8) com‐\n",
      "       mand. For example, if one wants to bind mount  source  directory  /foo,\n",
      "       one  can  do  mount  --bind  /foo /foo and mount --make-private --make-\n",
      "       shared /foo. This will convert /foo into a shared mount point. Alterna‐\n",
      "       tively, one can directly change propagation properties of source mount.\n",
      "       Say / is source mount for /foo, then use mount --make-shared / to  con‐\n",
      "       vert / into a shared mount.\n",
      "\n",
      "       Note:  if  the  user  only has access rights via a group, accessing the\n",
      "       volume from inside a rootless container will fail.\n",
      "\n",
      "       Use the --group-add keep-groups option to pass the user's supplementary\n",
      "       group access into the container.\n",
      "\n",
      "   --volumes-from=CONTAINER[:OPTIONS]\n",
      "       Mount  volumes  from  the specified container(s). Used to share volumes\n",
      "       between containers. The options is a comma-separated list with the fol‐\n",
      "       lowing available elements:\n",
      "\n",
      "              • rw|ro\n",
      "\n",
      "              • z\n",
      "\n",
      "       Mounts  already  mounted  volumes  from a source container onto another\n",
      "       container. CONTAINER may be a name or ID.  To share a volume,  use  the\n",
      "       --volumes-from option when running the target container. Volumes can be\n",
      "       shared even if the source container is not running.\n",
      "\n",
      "       By default, Podman mounts the volumes in the same mode  (read-write  or\n",
      "       read-only)  as  it  is  mounted  in  the source container.  This can be\n",
      "       changed by adding a ro or rw option.\n",
      "\n",
      "       Labeling systems like SELinux require that proper labels are placed  on\n",
      "       volume  content mounted into a container. Without a label, the security\n",
      "       system might prevent the processes running inside  the  container  from\n",
      "       using the content. By default, Podman does not change the labels set by\n",
      "       the OS.\n",
      "\n",
      "       To change a label in the container context, add z to the volume  mount.\n",
      "       This suffix tells Podman to relabel file objects on the shared volumes.\n",
      "       The z option tells Podman that two entities share the  volume  content.\n",
      "       As  a  result,  Podman  labels the content with a shared content label.\n",
      "       Shared volume labels allow all containers to read/write content.\n",
      "\n",
      "       If the location of the volume from the source container  overlaps  with\n",
      "       data residing on a target container, then the volume hides that data on\n",
      "       the target.\n",
      "\n",
      "   --workdir, -w=dir\n",
      "       Working directory inside the container.\n",
      "\n",
      "       The default working directory for running binaries within  a  container\n",
      "       is the root directory (/).  The image developer can set a different de‐\n",
      "       fault with the WORKDIR instruction. The operator can override the work‐\n",
      "       ing directory by using the -w option.\n",
      "\n",
      "Exit Status\n",
      "       The exit code from podman run gives information about why the container\n",
      "       failed to run or why it exited. When podman run exits with  a  non-zero\n",
      "       code, the exit codes follow the chroot(1) standard, see below:\n",
      "\n",
      "       125 The error is with Podman itself\n",
      "\n",
      "              $ podman run --foo busybox; echo $?\n",
      "              Error: unknown flag: --foo\n",
      "              125\n",
      "\n",
      "       126 The contained command cannot be invoked\n",
      "\n",
      "              $ podman run busybox /etc; echo $?\n",
      "              Error: container_linux.go:346: starting container process caused \"exec: \\\"/etc\\\": permission denied\": OCI runtime error\n",
      "              126\n",
      "\n",
      "       127 The contained command cannot be found\n",
      "\n",
      "              $ podman run busybox foo; echo $?\n",
      "              Error: container_linux.go:346: starting container process caused \"exec: \\\"foo\\\": executable file not found in $PATH\": OCI runtime error\n",
      "              127\n",
      "\n",
      "       Exit code contained command exit code\n",
      "\n",
      "              $ podman run busybox /bin/sh -c 'exit 3'; echo $?\n",
      "              3\n",
      "\n",
      "EXAMPLES\n",
      "   Running container in read-only mode\n",
      "       During  container  image development, containers often need to write to\n",
      "       the image content. Installing packages into /usr, for example. In  pro‐\n",
      "       duction, applications seldom need to write to the image.  Container ap‐\n",
      "       plications write to volumes if they need to write to  file  systems  at\n",
      "       all.  Applications can be made more secure by running them in read-only\n",
      "       mode using the --read-only switch.  This protects the container's image\n",
      "       from  modification. Read-only containers may still need to write tempo‐\n",
      "       rary data. The best way to handle this is to mount tmpfs directories on\n",
      "       /run and /tmp.\n",
      "\n",
      "              $ podman run --read-only -i -t fedora /bin/bash\n",
      "\n",
      "              $ podman run --read-only --read-only-tmpfs=false --tmpfs /run -i -t fedora /bin/bash\n",
      "\n",
      "   Exposing log messages from the container to the host's log\n",
      "       If  you  want  messages that are logged in your container to show up in\n",
      "       the host's syslog/journal then you should bind mount the  /dev/log  di‐\n",
      "       rectory as follows.\n",
      "\n",
      "              $ podman run -v /dev/log:/dev/log -i -t fedora /bin/bash\n",
      "\n",
      "       From inside the container you can test this by sending a message to the\n",
      "       log.\n",
      "\n",
      "              (bash)# logger \"Hello from my container\"\n",
      "\n",
      "       Then exit and check the journal.\n",
      "\n",
      "              (bash)# exit\n",
      "\n",
      "              $ journalctl -b | grep Hello\n",
      "\n",
      "       This should list the message sent to logger.\n",
      "\n",
      "   Attaching to one or more from STDIN, STDOUT, STDERR\n",
      "       If you do not specify -a, Podman will attach everything (stdin, stdout,\n",
      "       stderr).   You  can  specify  to  which  of  the three standard streams\n",
      "       (stdin, stdout, stderr) you'd like to connect instead, as in:\n",
      "\n",
      "              $ podman run -a stdin -a stdout -i -t fedora /bin/bash\n",
      "\n",
      "   Sharing IPC between containers\n",
      "       Using             shm_server.c             available              here:\n",
      "       https://www.cs.cf.ac.uk/Dave/C/node27.html\n",
      "\n",
      "       Testing --ipc=host mode:\n",
      "\n",
      "       Host  shows a shared memory segment with 7 pids attached, happens to be\n",
      "       from httpd:\n",
      "\n",
      "              $ sudo ipcs -m\n",
      "\n",
      "              ------ Shared Memory Segments --------\n",
      "              key        shmid      owner      perms      bytes      nattch     status\n",
      "              0x01128e25 0          root       600        1000       7\n",
      "\n",
      "       Now run a regular container, and it correctly does NOT see  the  shared\n",
      "       memory segment from the host:\n",
      "\n",
      "              $ podman run -it shm ipcs -m\n",
      "\n",
      "              ------ Shared Memory Segments --------\n",
      "              key        shmid      owner      perms      bytes      nattch     status\n",
      "\n",
      "       Run  a  container  with  the new --ipc=host option, and it now sees the\n",
      "       shared memory segment from the host httpd:\n",
      "\n",
      "              $ podman run -it --ipc=host shm ipcs -m\n",
      "\n",
      "              ------ Shared Memory Segments --------\n",
      "              key        shmid      owner      perms      bytes      nattch     status\n",
      "              0x01128e25 0          root       600        1000       7\n",
      "\n",
      "       Testing --ipc=container:id mode:\n",
      "\n",
      "       Start a container with a program to create a shared memory segment:\n",
      "\n",
      "              $ podman run -it shm bash\n",
      "              $ sudo shm/shm_server &\n",
      "              $ sudo ipcs -m\n",
      "\n",
      "              ------ Shared Memory Segments --------\n",
      "              key        shmid      owner      perms      bytes      nattch     status\n",
      "              0x0000162e 0          root       666        27         1\n",
      "\n",
      "       Create a 2nd container correctly shows no shared  memory  segment  from\n",
      "       1st container:\n",
      "\n",
      "              $ podman run shm ipcs -m\n",
      "\n",
      "              ------ Shared Memory Segments --------\n",
      "              key        shmid      owner      perms      bytes      nattch     status\n",
      "\n",
      "       Create  a  3rd  container  using  the --ipc=container:id option, now it\n",
      "       shows the shared memory segment from the first:\n",
      "\n",
      "              $ podman run -it --ipc=container:ed735b2264ac shm ipcs -m\n",
      "              $ sudo ipcs -m\n",
      "\n",
      "              ------ Shared Memory Segments --------\n",
      "              key        shmid      owner      perms      bytes      nattch     status\n",
      "              0x0000162e 0          root       666        27         1\n",
      "\n",
      "   Mapping Ports for External Usage\n",
      "       The exposed port of an application can be mapped to a host  port  using\n",
      "       the  -p  flag.  For example, an httpd port 80 can be mapped to the host\n",
      "       port 8080 using the following:\n",
      "\n",
      "              $ podman run -p 8080:80 -d -i -t fedora/httpd\n",
      "\n",
      "   Mounting External Volumes\n",
      "       To mount a host directory as a container volume, specify  the  absolute\n",
      "       path to the directory and the absolute path for the container directory\n",
      "       separated by a colon. If the source is a  named  volume  maintained  by\n",
      "       Podman,  it  is recommended to use its name rather than the path to the\n",
      "       volume. Otherwise the volume will be considered as an orphan and  wiped\n",
      "       if you execute podman volume prune:\n",
      "\n",
      "              $ podman run -v /var/db:/data1 -i -t fedora bash\n",
      "\n",
      "              $ podman run -v data:/data2 -i -t fedora bash\n",
      "\n",
      "              $ podman run -v /var/cache/dnf:/var/cache/dnf:O -ti fedora dnf -y update\n",
      "\n",
      "              $ podman run -d -e MYSQL_ROOT_PASSWORD=root --user mysql --userns=keep-id -v ~/data:/var/lib/mysql:z,U mariadb\n",
      "\n",
      "       Using  --mount  flags  to mount a host directory as a container folder,\n",
      "       specify the absolute path to the directory or the volume name, and  the\n",
      "       absolute path within the container directory:\n",
      "\n",
      "              $ podman run --mount type=bind,src=/var/db,target=/data1 busybox sh\n",
      "\n",
      "              $ podman run --mount type=bind,src=volume-name,target=/data1 busybox sh\n",
      "\n",
      "       When  using  SELinux,  be  aware that the host has no knowledge of con‐\n",
      "       tainer SELinux policy. Therefore, in the above example, if SELinux pol‐\n",
      "       icy  is  enforced,  the  /var/db  directory is not writable to the con‐\n",
      "       tainer. A \"Permission Denied\" message will occur and an avc: message in\n",
      "       the host's syslog.\n",
      "\n",
      "       To  work  around  this, at time of writing this man page, the following\n",
      "       command needs to be run in order for the proper SELinux policy type la‐\n",
      "       bel to be attached to the host directory:\n",
      "\n",
      "              $ chcon -Rt svirt_sandbox_file_t /var/db\n",
      "\n",
      "       Now,  writing to the /data1 volume in the container will be allowed and\n",
      "       the changes will also be reflected on the host in /var/db.\n",
      "\n",
      "   Using alternative security labeling\n",
      "       You can override the default labeling  scheme  for  each  container  by\n",
      "       specifying  the  --security-opt  flag. For example, you can specify the\n",
      "       MCS/MLS level, a requirement for MLS systems. Specifying the  level  in\n",
      "       the following command allows you to share the same content between con‐\n",
      "       tainers.\n",
      "\n",
      "              podman run --security-opt label=level:s0:c100,c200 -i -t fedora bash\n",
      "\n",
      "       An MLS example might be:\n",
      "\n",
      "              $ podman run --security-opt label=level:TopSecret -i -t rhel7 bash\n",
      "\n",
      "       To disable the security labeling for this container versus running with\n",
      "       the\n",
      "\n",
      "   --permissive flag, use the following command:\n",
      "              $ podman run --security-opt label=disable -i -t fedora bash\n",
      "\n",
      "       If  you  want  a tighter security policy on the processes within a con‐\n",
      "       tainer, you can specify an alternate type for the container. You  could\n",
      "       run  a container that is only allowed to listen on Apache ports by exe‐\n",
      "       cuting the following command:\n",
      "\n",
      "              $ podman run --security-opt label=type:svirt_apache_t -i -t centos bash\n",
      "\n",
      "       Note you would have to write policy defining a svirt_apache_t type.\n",
      "\n",
      "       To mask additional specific paths in the container, specify  the  paths\n",
      "       separated  by  a  colon  using  the mask option with the --security-opt\n",
      "       flag.\n",
      "\n",
      "              $ podman run --security-opt mask=/foo/bar:/second/path fedora bash\n",
      "\n",
      "       To unmask all the paths that are masked by default, set the unmask  op‐\n",
      "       tion  to  ALL.  Or  to only unmask specific paths, specify the paths as\n",
      "       shown above with the mask option.\n",
      "\n",
      "              $ podman run --security-opt unmask=ALL fedora bash\n",
      "\n",
      "       To unmask all the paths that start with /proc, set the unmask option to\n",
      "       /proc/*.\n",
      "\n",
      "              $ podman run --security-opt unmask=/proc/* fedora bash\n",
      "\n",
      "              $ podman run --security-opt unmask=/foo/bar:/sys/firmware fedora bash\n",
      "\n",
      "   Setting device weight\n",
      "       If  you  want to set /dev/sda device weight to 200, you can specify the\n",
      "       device weight by --blkio-weight-device flag. Use the following command:\n",
      "\n",
      "              $ podman run -it --blkio-weight-device \"/dev/sda:200\" ubuntu\n",
      "\n",
      "   Using a podman container with input from a pipe\n",
      "              $ echo \"asdf\" | podman run --rm -i --entrypoint /bin/cat someimage\n",
      "              asdf\n",
      "\n",
      "   Setting automatic user namespace separated containers\n",
      "              # podman run --userns=auto:size=65536 ubi8-micro cat /proc/self/uid_map\n",
      "              0 2147483647      65536\n",
      "              # podman run --userns=auto:size=65536 ubi8-micro cat /proc/self/uid_map\n",
      "              0 2147549183      65536\n",
      "\n",
      "   Setting Namespaced Kernel Parameters (Sysctls)\n",
      "       The --sysctl sets namespaced kernel parameters (sysctls)  in  the  con‐\n",
      "       tainer. For example, to turn on IP forwarding in the containers network\n",
      "       namespace, run this command:\n",
      "\n",
      "              $ podman run --sysctl net.ipv4.ip_forward=1 someimage\n",
      "\n",
      "       Note that not all sysctls  are  namespaced.  Podman  does  not  support\n",
      "       changing  sysctls  inside of a container that also modify the host sys‐\n",
      "       tem. As the kernel evolves we expect to see more sysctls become  names‐\n",
      "       paced.\n",
      "\n",
      "       See the definition of the --sysctl option above for the current list of\n",
      "       supported sysctls.\n",
      "\n",
      "   Set UID/GID mapping in a new user namespace\n",
      "       Running a container in a new user namespace requires a mapping  of  the\n",
      "       uids and gids from the host.\n",
      "\n",
      "              $ podman run --uidmap 0:30000:7000 --gidmap 0:30000:7000 fedora echo hello\n",
      "\n",
      "   Configuring Storage Options from the command line\n",
      "       Podman  allows  for the configuration of storage by changing the values\n",
      "       in the /etc/container/storage.conf or by  using  global  options.  This\n",
      "       shows  how to set up and use fuse-overlayfs for a one-time run of busy‐\n",
      "       box using global options.\n",
      "\n",
      "              podman --log-level=debug --storage-driver overlay --storage-opt \"overlay.mount_program=/usr/bin/fuse-overlayfs\" run busybox /bin/sh\n",
      "\n",
      "   Configure timezone in a container\n",
      "              $ podman run --tz=local alpine date\n",
      "              $ podman run --tz=Asia/Shanghai alpine date\n",
      "              $ podman run --tz=US/Eastern alpine date\n",
      "\n",
      "   Adding dependency containers\n",
      "       The first container, container1, is not started initially, but must  be\n",
      "       running  before  container2  will  start.   The podman run command will\n",
      "       start the container automatically before starting container2.\n",
      "\n",
      "              $ podman create --name container1 -t -i fedora bash\n",
      "              $ podman run --name container2 --requires container1 -t -i fedora bash\n",
      "\n",
      "       Multiple containers can be required.\n",
      "\n",
      "              $ podman create --name container1 -t -i fedora bash\n",
      "              $ podman create --name container2 -t -i fedora bash\n",
      "              $ podman run --name container3 --requires container1,container2 -t -i fedora bash\n",
      "\n",
      "   Configure keep supplemental groups for access to volume\n",
      "              $ podman run -v /var/lib/design:/var/lib/design --group-add keep-groups ubi8\n",
      "\n",
      "   Configure execution domain for containers using personality flag\n",
      "              $ podman run --name container1 --personality=LINUX32 fedora bash\n",
      "\n",
      "   Run a container with external rootfs mounted as an overlay\n",
      "              $ podman run --name container1 --rootfs /path/to/rootfs:O bash\n",
      "\n",
      "   Handling Timezones in java applications in a container.\n",
      "       In order to use a timezone other than UTC when running a Java  applica‐\n",
      "       tion within a container, the TZ environment variable must be set within\n",
      "       the container. Java applications will ignore the  value  set  with  the\n",
      "       --tz option.\n",
      "\n",
      "              # Example run\n",
      "              podman run -ti --rm  -e TZ=EST mytzimage\n",
      "              lrwxrwxrwx. 1 root root 29 Nov  3 08:51 /etc/localtime -> ../usr/share/zoneinfo/Etc/UTC\n",
      "              Now with default timezone:\n",
      "              Fri Nov 19 18:10:55 EST 2021\n",
      "              Java default sees the following timezone:\n",
      "              2021-11-19T18:10:55.651130-05:00\n",
      "              Forcing UTC:\n",
      "              Fri Nov 19 23:10:55 UTC 2021\n",
      "\n",
      "   Run  a  container  connected  to two networks (called net1 and net2) with a\n",
      "       static ip\n",
      "              $ podman run --network net1:ip=10.89.1.5 --network net2:ip=10.89.10.10 alpine ip addr\n",
      "\n",
      "   Rootless Containers\n",
      "       Podman runs as a non-root user on most systems. This  feature  requires\n",
      "       that  a  new  enough  version of shadow-utils be installed. The shadow-\n",
      "       utils package must include the newuidmap(1) and  newgidmap(1)  executa‐\n",
      "       bles.\n",
      "\n",
      "       In  order  for  users to run rootless, there must be an entry for their\n",
      "       username in /etc/subuid and /etc/subgid which lists the UIDs for  their\n",
      "       user namespace.\n",
      "\n",
      "       Rootless  Podman  works  better  if  the fuse-overlayfs and slirp4netns\n",
      "       packages  are  installed.   The  fuse-overlayfs  package   provides   a\n",
      "       userspace  overlay  storage driver, otherwise users need to use the vfs\n",
      "       storage driver, which is diskspace expensive and does not perform well.\n",
      "       slirp4netns  is  required for VPN, without it containers need to be run\n",
      "       with the --network=host flag.\n",
      "\n",
      "ENVIRONMENT\n",
      "       Environment variables within containers can be set using multiple  dif‐\n",
      "       ferent  options,  in  the  following order of precedence (later entries\n",
      "       override earlier entries):\n",
      "\n",
      "              • Container image: Any environment variables  specified  in  the\n",
      "                container image.\n",
      "\n",
      "              • --http-proxy:  By  default, several environment variables will\n",
      "                be passed in from the host, such as http_proxy  and  no_proxy.\n",
      "                See --http-proxy for details.\n",
      "\n",
      "              • --env-host:  Host  environment of the process executing Podman\n",
      "                is added.\n",
      "\n",
      "              • --env-file: Any environment variables specified via env-files.\n",
      "                If multiple files are specified, then they override each other\n",
      "                in order of entry.\n",
      "\n",
      "              • --env: Any environment variables specified will override  pre‐\n",
      "                vious settings.\n",
      "\n",
      "       Run containers and set the environment ending with a *.  The trailing *\n",
      "       glob functionality is only active when no value is specified:\n",
      "\n",
      "              $ export ENV1=a\n",
      "              $ podman run --env 'ENV*' alpine env | grep ENV\n",
      "              ENV1=a\n",
      "              $ podman run --env 'ENV*=b' alpine env | grep ENV\n",
      "              ENV*=b\n",
      "\n",
      "CONMON\n",
      "       When Podman starts a container it actually executes the conmon program,\n",
      "       which  then executes the OCI Runtime.  Conmon is the container monitor.\n",
      "       It is a small program whose job is to watch the primary process of  the\n",
      "       container,  and  if  the  container  dies, save the exit code.  It also\n",
      "       holds open the tty of the container, so that  it  can  be  attached  to\n",
      "       later.  This  is  what  allows  Podman  to  run in detached mode (back‐\n",
      "       grounded), so Podman can exit but conmon continues to run.   Each  con‐\n",
      "       tainer has their own instance of conmon. Conmon waits for the container\n",
      "       to exit, gathers and saves the exit code, and then  launches  a  Podman\n",
      "       process to complete the container cleanup, by shutting down the network\n",
      "       and storage.   For more information on  conmon,  please  reference  the\n",
      "       conmon(8) man page.\n",
      "\n",
      "FILES\n",
      "       /etc/subuid\n",
      "\n",
      "       /etc/subgid\n",
      "\n",
      "       NOTE: Use the environment variable TMPDIR to change the temporary stor‐\n",
      "       age location of downloaded container images.  Podman  defaults  to  use\n",
      "       /var/tmp.\n",
      "\n",
      "SEE ALSO\n",
      "       podman(1),  podman-save(1), podman-ps(1), podman-attach(1), podman-pod-\n",
      "       create(1),  podman-port(1),  podman-start(1),  podman-kill(1),  podman-\n",
      "       stop(1),   podman-generate-systemd(1),  podman-rm(1),  subgid(5),  sub‐\n",
      "       uid(5),     containers.conf(5),     systemd.unit(5),      setsebool(8),\n",
      "       slirp4netns(1), fuse-overlayfs(1), proc(5), conmon(8), personality(2)\n",
      "\n",
      "HISTORY\n",
      "       September    2018,    updated    by    Kunal   Kushwaha   <kushwaha_ku‐\n",
      "       nal_v7@lab.ntt.co.jp>\n",
      "\n",
      "       October 2017, converted from Docker  documentation  to  Podman  by  Dan\n",
      "       Walsh for Podman <dwalsh@redhat.com>\n",
      "\n",
      "       November 2015, updated by Sally O'Malley <somalley@redhat.com>\n",
      "\n",
      "       June 2014, updated by Sven Dowideit <SvenDowideit@home.org.au>\n",
      "\n",
      "       April  2014,  Originally  compiled by William Henry <whenry@redhat.com>\n",
      "       based on docker.com source material and internal work.\n",
      "\n",
      "FOOTNOTES\n",
      "       1: The Podman project is committed to inclusivity, a core value of open\n",
      "       source. The master and slave mount propagation terminology used here is\n",
      "       problematic and divisive, and should be changed. However,  these  terms\n",
      "       are  currently  used  within the Linux kernel and must be used as-is at\n",
      "       this time. When the kernel maintainers rectify this usage, Podman  will\n",
      "       follow suit immediately.\n",
      "\n",
      "                                                                 podman-run(1)\n"
     ]
    }
   ],
   "source": [
    "man podman-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e7977-9077-41fb-aedb-4ff500337786",
   "metadata": {},
   "source": [
    "#### `podman create`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50305598-d243-4256-ab16-26d79811a5cd",
   "metadata": {},
   "source": [
    "The `podman create` command is almost identical to the `podman run` command. The `create` command pulls the image if it is not in container storage and configures the container information to make it ready to run but never executes the container. It is often used together with the `podman start` command described in section 2.1.4. You might want to create a container and then later use a systemd unit file to start and stop the container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed7495-3038-40a9-9ebd-0e7bb77466e7",
   "metadata": {},
   "source": [
    "### Stopping containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6864618-f0be-4992-b8d1-f2333509a721",
   "metadata": {},
   "source": [
    "#### podman stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94618a59-2530-485e-8dd8-967b9aeb212e",
   "metadata": {},
   "source": [
    "You have two containers running and have tested them by running a web browser against them. To continue the development by actually adding some content to the web page, you can stop the containers using the `podman stop` command:\n",
    "\n",
    "```sh\n",
    "$ podman stop myapp\n",
    "```\n",
    "\n",
    "The `stop` command stops the container started with the previous `podman run` command.\n",
    "\n",
    "When stopping a container, Podman examines the running container and sends a stop signal, usually `SIGTERM`, to the primary process (`PID1`) of the container, and then by default it waits `10` seconds for the container to stop. The stop signal tells the primary process within the container to exit gracefully. If the container doesn’t stop within `10` seconds, Podman sends the `SIGKILL` signal to the process, forcing the container to stop. The 10-second wait gives the processes in the container time to clean up and commit changes.\n",
    "\n",
    "The default stop signal can be changed for a container using the `podman run --stop-signal` option. Sometimes the primary or init process of a container ignores `SIGTERM` (e.g., containers that use systemd as the primary process inside a container). systemd ignores `SIGTERM` and specifies that it shuts down using the `SIGRTMIN+3 `(`signal #37`) signal. The stop signal can be embedded in container images, as I describe in section 2.3.\n",
    "\n",
    "Some containers ignore the `SIGTERM` stop signal, which means you have to wait 10 seconds for the container to exit. If you know the container ignores the default stop signal, and you don’t care about the container cleaning up, you can just add the `-t 0` option to podman stop to send the `SIGKILL` signal right away:\n",
    "\n",
    "```sh\n",
    "$ podman stop -t 0 myapp1\n",
    "myapp1\n",
    "```\n",
    "\n",
    "Some notable `Podman stop` options include the following:\n",
    "\n",
    "- `--time` (`-t`) — This sets the timeout; `-t 0` sends the `SIGKILL` without waiting for the container to stop.\n",
    "- `--latest` (`-l`) — This is a useful option to allow you to stop the last created container rather than having to use the container name or container ID. Most Podman commands that require you to specify a container name or ID also accept the `--latest` option. This is only available on Linux machines.\n",
    "- `--all` — This tells Podman to stop all running containers. Similarly to `--latest`, Podman commands that require a container name or container ID parameter also take the `--all` option.\n",
    "\n",
    "Use the `man podman-stop` command for information about all options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53762310-1501-43f6-9c83-8f16334dee46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:44:29.155970Z",
     "iopub.status.busy": "2024-01-17T21:44:29.154457Z",
     "iopub.status.idle": "2024-01-17T21:44:29.435808Z",
     "shell.execute_reply": "2024-01-17T21:44:29.434737Z",
     "shell.execute_reply.started": "2024-01-17T21:44:29.155887Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "podman-stop(1)              General Commands Manual             podman-stop(1)\n",
      "\n",
      "NAME\n",
      "       podman-stop - Stop one or more running containers\n",
      "\n",
      "SYNOPSIS\n",
      "       podman stop [options] container ...\n",
      "\n",
      "       podman container stop [options] container ...\n",
      "\n",
      "DESCRIPTION\n",
      "       Stops  one  or  more containers.  You may use container IDs or names as\n",
      "       input. The --time switch allows you to specify the number of seconds to\n",
      "       wait  before  forcibly stopping the container after the stop command is\n",
      "       issued to the container. The default is 10 seconds.  By  default,  con‐\n",
      "       tainers  are  stopped  with SIGTERM and then SIGKILL after the timeout.\n",
      "       The SIGTERM default can be overridden by the image used to  create  the\n",
      "       container and also via command line when creating the container.\n",
      "\n",
      "OPTIONS\n",
      "   --all, -a\n",
      "       Stop all running containers.  This does not include paused containers.\n",
      "\n",
      "   --cidfile=file\n",
      "       Read  container ID from the specified file and stop the container.  Can\n",
      "       be specified multiple times.\n",
      "\n",
      "   --filter, -f=filter\n",
      "       Filter what containers are going to be stopped.  Multiple  filters  can\n",
      "       be  given  with  multiple  uses of the --filter flag.  Filters with the\n",
      "       same key work inclusive with the only exception being  label  which  is\n",
      "       exclusive. Filters with different keys always work exclusive.\n",
      "\n",
      "       Valid filters are listed below:\n",
      "\n",
      "       ┌─────────┬───────────────────────────────┐\n",
      "       │Filter   │ Description                   │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │id       │ [ID]  Container's ID (accepts │\n",
      "       │         │ regex)                        │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │name     │ [Name] Container's name  (ac‐ │\n",
      "       │         │ cepts regex)                  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │label    │ [Key]  or  [Key=Value]  Label │\n",
      "       │         │ assigned to a container       │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │exited   │ [Int] Container's exit code   │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │status   │ [Status] Container's  status: │\n",
      "       │         │ 'created',          'exited', │\n",
      "       │         │ 'paused',   'running',   'un‐ │\n",
      "       │         │ known'                        │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │ancestor │ [ImageName]  Image or descen‐ │\n",
      "       │         │ dant used to create container │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │before   │ [ID]  or  [Name]   Containers │\n",
      "       │         │ created before this container │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │since    │ [ID]   or  [Name]  Containers │\n",
      "       │         │ created since this container  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │volume   │ [VolumeName] or  [Mountpoint‐ │\n",
      "       │         │ Destination]  Volume  mounted │\n",
      "       │         │ in container                  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │health   │ [Status] healthy or unhealthy │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │pod      │ [Pod] name or full or partial │\n",
      "       │         │ ID of pod                     │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │network  │ [Network]  name or full ID of │\n",
      "       │         │ network                       │\n",
      "       └─────────┴───────────────────────────────┘\n",
      "\n",
      "   --ignore, -i\n",
      "       Ignore errors when specified containers are not in the container store.\n",
      "       A  user  might  have decided to manually remove a container which would\n",
      "       lead to a failure during the ExecStop directive of  a  systemd  service\n",
      "       referencing that container.\n",
      "\n",
      "   --latest, -l\n",
      "       Instead  of  providing  the  container name or ID, use the last created\n",
      "       container. If you use methods other than Podman to run containers  such\n",
      "       as  CRI-O,  the  last  started  container could be from either of those\n",
      "       methods. (This option is not available with the remote  Podman  client,\n",
      "       including Mac and Windows (excluding WSL2) machines)\n",
      "\n",
      "   --time, -t=seconds\n",
      "       Seconds to wait before forcibly stopping the container.\n",
      "\n",
      "EXAMPLES\n",
      "       $ podman stop mywebserver\n",
      "\n",
      "       $ podman stop 860a4b235279\n",
      "\n",
      "       $ podman stop mywebserver 860a4b235279\n",
      "\n",
      "       $ podman stop --cidfile /home/user/cidfile-1\n",
      "\n",
      "       $ podman stop --cidfile /home/user/cidfile-1 --cidfile ./cidfile-2\n",
      "\n",
      "       $ podman stop --time 2 860a4b235279\n",
      "\n",
      "       $ podman stop -a\n",
      "\n",
      "       $ podman stop --latest\n",
      "\n",
      "SEE ALSO\n",
      "       podman(1), podman-rm(1)\n",
      "\n",
      "HISTORY\n",
      "       September  2018,  Originally  compiled by Brent Baude bbaude@redhat.com\n",
      "       ⟨mailto:bbaude@redhat.com⟩\n",
      "\n",
      "                                                                podman-stop(1)\n"
     ]
    }
   ],
   "source": [
    "man podman-stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247df6e-35b7-45c5-9805-e67a1318a5e1",
   "metadata": {},
   "source": [
    "#### `podman kill`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ef0f0-30c2-47ce-af22-805f39504d4d",
   "metadata": {},
   "source": [
    "Podman has a similar command, `podman kill`, which sends the specified kill signal. The `podman kill` command can be useful when you want to send signals into the container without actually stopping the container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a1e36-0160-46e5-9181-7622e0905816",
   "metadata": {},
   "source": [
    "### Starting containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d7baea-b781-40e9-9cc5-20d140627221",
   "metadata": {},
   "source": [
    "Eventually, your system will have lots of stopped containers, and sometimes you will need to restart them (e.g., if the system was rebooted). Another common use case is to first `create` a container and later `start` it.\n",
    "\n",
    "The container you created has now been stopped. Next, you may want to start it back up again using the command in the following listing:\n",
    "\n",
    "```sh\n",
    "$ podman start myapp\n",
    "myapp\n",
    "```\n",
    "\n",
    "The `podman start` command starts one or more containers. This command will output the container ID, indicating that your container is up and running. You can now reconnect to it with a web browser. One common use case for `podman start` is starting a container after a reboot to start all of the containers that were stopped during shutdown.\n",
    "\n",
    "Some favorite Podman start options include these:\n",
    "\n",
    "- `--all` — This starts all of the stopped containers in container storage.\n",
    "- `--attach` — This attaches your terminal to the output of the container.\n",
    "- `--interactive` (`-i`)—This attaches the terminal input to the container.\n",
    "\n",
    "Use the `man podman-start` command for information about all options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77940223-5816-4063-8e39-6ad024040fb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:35:06.052076Z",
     "iopub.status.busy": "2024-01-17T21:35:06.051593Z",
     "iopub.status.idle": "2024-01-17T21:35:06.337255Z",
     "shell.execute_reply": "2024-01-17T21:35:06.336183Z",
     "shell.execute_reply.started": "2024-01-17T21:35:06.052036Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "podman-start(1)             General Commands Manual            podman-start(1)\n",
      "\n",
      "NAME\n",
      "       podman-start - Start one or more containers\n",
      "\n",
      "SYNOPSIS\n",
      "       podman start [options] container ...\n",
      "\n",
      "       podman container start [options] container ...\n",
      "\n",
      "DESCRIPTION\n",
      "       Start  one  or  more containers.  You may use container IDs or names as\n",
      "       input.  The attach and interactive options cannot be used  to  override\n",
      "       the  --tty  and  --interactive options from when the container was cre‐\n",
      "       ated. If you attempt to start a running container with the --attach op‐\n",
      "       tion, podman will simply attach to the container.\n",
      "\n",
      "OPTIONS\n",
      "   --all\n",
      "       Start  all  the  containers  created by Podman, default is only running\n",
      "       containers.\n",
      "\n",
      "   --attach, -a\n",
      "       Attach container's STDOUT and STDERR.  The default is false.  This  op‐\n",
      "       tion cannot be used when starting multiple containers.\n",
      "\n",
      "   --detach-keys=sequence\n",
      "       Specify  the key sequence for detaching a container. Format is a single\n",
      "       character [a-Z] or one or more ctrl-<value> characters where <value> is\n",
      "       one  of: a-z, @, ^, [, , or _. Specifying \"\" will disable this feature.\n",
      "       The default is ctrl-p,ctrl-q.\n",
      "\n",
      "       This option can also be set in containers.conf(5) file.\n",
      "\n",
      "   --filter, -f\n",
      "       Filter what containers are going to be started  from  the  given  argu‐\n",
      "       ments.   Multiple filters can be given with multiple uses of the --fil‐\n",
      "       ter flag.  Filters with the same key work inclusive with the  only  ex‐\n",
      "       ception being label which is exclusive. Filters with different keys al‐\n",
      "       ways work exclusive.\n",
      "\n",
      "       Valid filters are listed below:\n",
      "\n",
      "       ┌─────────┬───────────────────────────────┐\n",
      "       │Filter   │ Description                   │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │id       │ [ID] Container's ID  (accepts │\n",
      "       │         │ regex)                        │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │name     │ [Name]  Container's name (ac‐ │\n",
      "       │         │ cepts regex)                  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │label    │ [Key]  or  [Key=Value]  Label │\n",
      "       │         │ assigned to a container       │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │exited   │ [Int] Container's exit code   │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │status   │ [Status]  Container's status: │\n",
      "       │         │ 'created',          'exited', │\n",
      "       │         │ 'paused',   'running',   'un‐ │\n",
      "       │         │ known'                        │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │ancestor │ [ImageName] Image or  descen‐ │\n",
      "       │         │ dant used to create container │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │before   │ [ID]   or  [Name]  Containers │\n",
      "       │         │ created before this container │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │since    │ [ID]  or  [Name]   Containers │\n",
      "       │         │ created since this container  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │volume   │ [VolumeName]  or [Mountpoint‐ │\n",
      "       │         │ Destination]  Volume  mounted │\n",
      "       │         │ in container                  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │health   │ [Status] healthy or unhealthy │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │pod      │ [Pod] name or full or partial │\n",
      "       │         │ ID of pod                     │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │network  │ [Network] name or full ID  of │\n",
      "       │         │ network                       │\n",
      "       └─────────┴───────────────────────────────┘\n",
      "\n",
      "   --interactive, -i\n",
      "       When  set to true, keep stdin open even if not attached. The default is\n",
      "       false.\n",
      "\n",
      "   --latest, -l\n",
      "       Instead of providing the container name or ID,  use  the  last  created\n",
      "       container.  If you use methods other than Podman to run containers such\n",
      "       as CRI-O, the last started container could  be  from  either  of  those\n",
      "       methods.  (This  option is not available with the remote Podman client,\n",
      "       including Mac and Windows (excluding WSL2) machines)\n",
      "\n",
      "   --sig-proxy\n",
      "       Proxy received signals to the container process  (non-TTY  mode  only).\n",
      "       SIGCHLD, SIGSTOP, and SIGKILL are not proxied.\n",
      "\n",
      "       The default is true when attaching, false otherwise.\n",
      "\n",
      "EXAMPLE\n",
      "       podman start mywebserver\n",
      "\n",
      "       podman start 860a4b231279 5421ab43b45\n",
      "\n",
      "       podman start --interactive --attach 860a4b231279\n",
      "\n",
      "       podman start -i -l\n",
      "\n",
      "SEE ALSO\n",
      "       podman(1)\n",
      "\n",
      "HISTORY\n",
      "       November  2018,  Originally  compiled  by Brent Baude bbaude@redhat.com\n",
      "       ⟨mailto:bbaude@redhat.com⟩\n",
      "\n",
      "                                                               podman-start(1)\n"
     ]
    }
   ],
   "source": [
    "man podman-start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad4a40-8632-4fff-b40c-d9fa73ff639f",
   "metadata": {},
   "source": [
    "### Listing containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca596d3-2ece-4df4-b148-22797ea2684f",
   "metadata": {},
   "source": [
    "After you’ve been using Podman for a while and have pulled down and run many different container images, you might want to figure out which containers are running or which containers you have in local storage. You will need to be able to list these containers.\n",
    "\n",
    "Use the `podman ps` command to list containers:\n",
    "\n",
    "```sh\n",
    "$ podman ps\n",
    "```\n",
    "```\n",
    "CONTAINER ID IMAGE                      COMMAND        CREATED \\ \n",
    "➥   STATUS         PORTS          NAMES\n",
    "b1255e94d084 registry.access.redhat.com/ubi8/httpd-24:latest /usr/bin/run-\\ \n",
    "➥ http... 6 minutes ago Up 4 minutes ago 0.0.0.0:8080->8080/tcp myapp\n",
    "```\n",
    "\n",
    "Notice the `podman ps` command by default lists the running containers. Use the `--all` option to see all of the containers:\n",
    "\n",
    "```sh\n",
    "$ podman ps --all\n",
    "```\n",
    "```\n",
    "CONTAINER ID IMAGE                       COMMAND        CREATED \\ \n",
    "➥   STATUS          PORTS          NAMES\n",
    "b1255e94d084 registry.access.redhat.com/ubi8/httpd-24:latest /usr/bin/run-\\\n",
    "➥ http... 9 minutes ago Up 8 minutes ago     0.0.0.0:8080->8080/tcp myapp\n",
    "3efee4d39965 registry.access.redhat.com/ubi8/httpd-24:latest /usr/bin/run-\\\n",
    "➥ http... 7 minutes ago Exited (0) 3 minutes ago 0.0.0.0:8081->8080/tcp myapp1\n",
    "```\n",
    "\n",
    "Some notable `podman ps` options include the following:\n",
    "\n",
    "- `--all` — This tells Podman to list all containers rather than just running containers.\n",
    "- `--quiet` — This tells Podman to only print the container IDs.\n",
    "- `--size` — This tells Podman to return the amount of disk space currently used for each container other than the images they are based on.\n",
    "\n",
    "Use the `man podman-ps` command for information about all options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65610d89-4edd-4694-a302-9f2541349139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-17T21:47:51.979819Z",
     "iopub.status.busy": "2024-01-17T21:47:51.978691Z",
     "iopub.status.idle": "2024-01-17T21:47:52.401110Z",
     "shell.execute_reply": "2024-01-17T21:47:52.399769Z",
     "shell.execute_reply.started": "2024-01-17T21:47:51.979785Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "podman-ps(1)                General Commands Manual               podman-ps(1)\n",
      "\n",
      "NAME\n",
      "       podman-ps - Prints out information about containers\n",
      "\n",
      "SYNOPSIS\n",
      "       podman ps [options]\n",
      "\n",
      "       podman container ps [options]\n",
      "\n",
      "       podman container list [options]\n",
      "\n",
      "       podman container ls [options]\n",
      "\n",
      "DESCRIPTION\n",
      "       podman  ps  lists  the  running containers on the system. Use the --all\n",
      "       flag to view all the containers information.  By default it lists:\n",
      "\n",
      "              • container id\n",
      "\n",
      "              • the name of the image the container is using\n",
      "\n",
      "              • the COMMAND the container is executing\n",
      "\n",
      "              • the time the container was created\n",
      "\n",
      "              • the status of the container\n",
      "\n",
      "              • port mappings the container is using\n",
      "\n",
      "              • alternative names for the container\n",
      "\n",
      "OPTIONS\n",
      "   --all, -a\n",
      "       Show all the containers created by Podman, default is only running con‐\n",
      "       tainers.\n",
      "\n",
      "       Note: Podman shares containers storage with other tools such as Buildah\n",
      "       and CRI-O. In some cases these external containers might also exist  in\n",
      "       the  same storage. Use the --external option to see these external con‐\n",
      "       tainers. External containers show the 'storage' status.\n",
      "\n",
      "   --external\n",
      "       Display external containers that are not controlled by Podman  but  are\n",
      "       stored  in containers storage.  These external containers are generally\n",
      "       created via other container technology such as Buildah or CRI-O and may\n",
      "       depend  on the same container images that Podman is also using.  Exter‐\n",
      "       nal containers are denoted with either a 'buildah' or 'storage' in  the\n",
      "       COMMAND and STATUS column of the ps output.\n",
      "\n",
      "   --filter, -f\n",
      "       Filter  what  containers are shown in the output.  Multiple filters can\n",
      "       be given with multiple uses of the --filter  flag.   Filters  with  the\n",
      "       same  key  work  inclusive with the only exception being label which is\n",
      "       exclusive. Filters with different keys always work exclusive.\n",
      "\n",
      "       Valid filters are listed below:\n",
      "\n",
      "       ┌─────────┬───────────────────────────────┐\n",
      "       │Filter   │ Description                   │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │id       │ [ID] Container's ID  (accepts │\n",
      "       │         │ regex)                        │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │name     │ [Name]  Container's name (ac‐ │\n",
      "       │         │ cepts regex)                  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │label    │ [Key]  or  [Key=Value]  Label │\n",
      "       │         │ assigned to a container       │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │exited   │ [Int] Container's exit code   │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │status   │ [Status]  Container's status: │\n",
      "       │         │ 'created',          'exited', │\n",
      "       │         │ 'paused',   'running',   'un‐ │\n",
      "       │         │ known'                        │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │ancestor │ [ImageName] Image or  descen‐ │\n",
      "       │         │ dant used to create container │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │before   │ [ID]   or  [Name]  Containers │\n",
      "       │         │ created before this container │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │since    │ [ID]  or  [Name]   Containers │\n",
      "       │         │ created since this container  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │volume   │ [VolumeName]  or [Mountpoint‐ │\n",
      "       │         │ Destination]  Volume  mounted │\n",
      "       │         │ in container                  │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │health   │ [Status] healthy or unhealthy │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │pod      │ [Pod] name or full or partial │\n",
      "       │         │ ID of pod                     │\n",
      "       ├─────────┼───────────────────────────────┤\n",
      "       │network  │ [Network] name or full ID  of │\n",
      "       │         │ network                       │\n",
      "       └─────────┴───────────────────────────────┘\n",
      "\n",
      "   --format=format\n",
      "       Pretty-print containers to JSON or using a Go template\n",
      "\n",
      "       Valid placeholders for the Go template are listed below:\n",
      "\n",
      "       ┌────────────┬─────────────────────────────┐\n",
      "       │Placeholder │ Description                 │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.ID         │ Container ID                │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Image      │ Image Name/ID               │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.ImageID    │ Image ID                    │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Command    │ Quoted command used         │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.CreatedAt  │ Creation time for container │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.RunningFor │ Time   elapsed  since  con‐ │\n",
      "       │            │ tainer was started          │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Status     │ Status of container         │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Pod        │ Pod the container is  asso‐ │\n",
      "       │            │ ciated with                 │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Ports      │ Exposed ports               │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Size       │ Size of container           │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Names      │ Name of container           │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Networks   │ Show all networks connected │\n",
      "       │            │ to the container            │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Labels     │ All the labels assigned  to │\n",
      "       │            │ the container               │\n",
      "       ├────────────┼─────────────────────────────┤\n",
      "       │.Mounts     │ Volumes mounted in the con‐ │\n",
      "       │            │ tainer                      │\n",
      "       └────────────┴─────────────────────────────┘\n",
      "\n",
      "   --help, -h\n",
      "       Print usage statement\n",
      "\n",
      "   --last, -n\n",
      "       Print the n last created containers (all states)\n",
      "\n",
      "   --latest, -l\n",
      "       Show the latest container created (all  states)  (This  option  is  not\n",
      "       available with the remote Podman client, including Mac and Windows (ex‐\n",
      "       cluding WSL2) machines)\n",
      "\n",
      "   --namespace, --ns\n",
      "       Display namespace information\n",
      "\n",
      "   --no-trunc\n",
      "       Do not truncate the output (default false).\n",
      "\n",
      "   --noheading\n",
      "       Omit the table headings from the listing of containers.\n",
      "\n",
      "   --pod, -p\n",
      "       Display the pods the containers are associated with\n",
      "\n",
      "   --quiet, -q\n",
      "       Print the numeric IDs of the containers only\n",
      "\n",
      "   --size, -s\n",
      "       Display the total file size\n",
      "\n",
      "   --sort=created\n",
      "       Sort by command, created, id, image, names, runningfor, size,  or  sta‐\n",
      "       tus\",  Note:  Choosing size will sort by size of rootFs, not alphabeti‐\n",
      "       cally like the rest of the options\n",
      "\n",
      "   --sync\n",
      "       Force a sync of container state with the OCI runtime.  In some cases, a\n",
      "       container's  state  in the runtime can become out of sync with Podman's\n",
      "       state.  This will update Podman's state based on what the  OCI  runtime\n",
      "       reports.  Forcibly syncing is much slower, but can resolve inconsistent\n",
      "       state issues.\n",
      "\n",
      "   --watch, -w\n",
      "       Refresh the output with current containers on an interval in seconds.\n",
      "\n",
      "EXAMPLES\n",
      "              $ podman ps -a\n",
      "              CONTAINER ID   IMAGE         COMMAND         CREATED       STATUS                    PORTS     NAMES\n",
      "              02f65160e14ca  redis:alpine  \"redis-server\"  19 hours ago  Exited (-1) 19 hours ago  6379/tcp  k8s_podsandbox1-redis_podsandbox1_redhat.test.crio_redhat-test-crio_0\n",
      "              69ed779d8ef9f  redis:alpine  \"redis-server\"  25 hours ago  Created                   6379/tcp  k8s_container1_podsandbox1_redhat.test.crio_redhat-test-crio_1\n",
      "\n",
      "              $ podman ps -a -s\n",
      "              CONTAINER ID   IMAGE         COMMAND         CREATED       STATUS                    PORTS     NAMES                                                                  SIZE\n",
      "              02f65160e14ca  redis:alpine  \"redis-server\"  20 hours ago  Exited (-1) 20 hours ago  6379/tcp  k8s_podsandbox1-redis_podsandbox1_redhat.test.crio_redhat-test-crio_0  27.49 MB\n",
      "              69ed779d8ef9f  redis:alpine  \"redis-server\"  25 hours ago  Created                   6379/tcp  k8s_container1_podsandbox1_redhat.test.crio_redhat-test-crio_1         27.49 MB\n",
      "\n",
      "              $ podman ps -a --format \"{{.ID}}  {{.Image}}  {{.Labels}}  {{.Mounts}}\"\n",
      "              02f65160e14ca  redis:alpine  tier=backend  proc,tmpfs,devpts,shm,mqueue,sysfs,cgroup,/var/run/,/var/run/\n",
      "              69ed779d8ef9f  redis:alpine  batch=no,type=small  proc,tmpfs,devpts,shm,mqueue,sysfs,cgroup,/var/run/,/var/run/\n",
      "\n",
      "              $ podman ps --ns -a\n",
      "              CONTAINER ID    NAMES                                                                   PID     CGROUP       IPC          MNT          NET          PIDNS        USER         UTS\n",
      "              3557d882a82e3   k8s_container2_podsandbox1_redhat.test.crio_redhat-test-crio_1          29910   4026531835   4026532585   4026532593   4026532508   4026532595   4026531837   4026532594\n",
      "              09564cdae0bec   k8s_container1_podsandbox1_redhat.test.crio_redhat-test-crio_1          29851   4026531835   4026532585   4026532590   4026532508   4026532592   4026531837   4026532591\n",
      "              a31ebbee9cee7   k8s_podsandbox1-redis_podsandbox1_redhat.test.crio_redhat-test-crio_0   29717   4026531835   4026532585   4026532587   4026532508   4026532589   4026531837   4026532588\n",
      "\n",
      "              $ podman ps -a --size --sort names\n",
      "              CONTAINER ID   IMAGE         COMMAND         CREATED       STATUS                    PORTS     NAMES\n",
      "              69ed779d8ef9f  redis:alpine  \"redis-server\"  25 hours ago  Created                   6379/tcp  k8s_container1_podsandbox1_redhat.test.crio_redhat-test-crio_1\n",
      "              02f65160e14ca  redis:alpine  \"redis-server\"  19 hours ago  Exited (-1) 19 hours ago  6379/tcp  k8s_podsandbox1-redis_podsandbox1_redhat.test.crio_redhat-test-crio_0\n",
      "\n",
      "              $ podman ps\n",
      "              CONTAINER ID  IMAGE                            COMMAND    CREATED        STATUS            PORTS                                                   NAMES\n",
      "              4089df24d4f3  docker.io/library/centos:latest  /bin/bash  2 minutes ago  Up 2 minutes ago  0.0.0.0:80->8080/tcp, 0.0.0.0:2000-2006->2000-2006/tcp  manyports\n",
      "              92f58933c28c  docker.io/library/centos:latest  /bin/bash  3 minutes ago  Up 3 minutes ago  192.168.99.100:1000-1006->1000-1006/tcp                 zen_sanderson\n",
      "\n",
      "              $ podman ps --external -a\n",
      "              CONTAINER ID  IMAGE                             COMMAND  CREATED      STATUS  PORTS  NAMES\n",
      "              69ed779d8ef9f  redis:alpine  \"redis-server\"  25 hours ago  Created                   6379/tcp  k8s_container1_podsandbox1_redhat.test.crio_redhat-test-crio_1\n",
      "              38a8a78596f9  docker.io/library/busybox:latest  buildah  2 hours ago  storage        busybox-working-container\n",
      "              fd7b786b5c32  docker.io/library/alpine:latest   buildah  2 hours ago  storage        alpine-working-container\n",
      "              f78620804e00  scratch                           buildah  2 hours ago  storage        working-container\n",
      "\n",
      "ps\n",
      "       Print a list of containers\n",
      "\n",
      "SEE ALSO\n",
      "       podman(1), buildah(1), crio(8)\n",
      "\n",
      "HISTORY\n",
      "       August 2017, Originally compiled by Urvashi Mohnani umohnani@redhat.com\n",
      "       ⟨mailto:umohnani@redhat.com⟩\n",
      "\n",
      "                                                                  podman-ps(1)\n"
     ]
    }
   ],
   "source": [
    "man podman-ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9b89e-5fc7-4067-8d91-e3d196e2ff26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f19f13f-46dd-4717-b130-daea22771b98",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cfec94c-cad1-4a34-8e49-129ba2577662",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21bcfb37-37c9-4d61-9afb-fbd81fa556e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca2f6cac-347d-48b6-8130-edbf8143ec83",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf379b0-a4ad-41ed-9be5-26f57672bf8d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "089ca43a-24fb-4259-a0e4-37c9478f435a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d288e84b-f0dc-4768-9c4b-5fd94a94a84c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c96e64a2-5d7a-4a56-89d0-98d9c7835588",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ff89cd9-b3a4-4e5d-ba84-7c0f91dd6789",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30dc3484-9086-4e52-9930-62150e8b1628",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acaad81f-4ac6-4c41-815d-3aad5164aaec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c56d4b-f648-43ac-9051-32115ecd00f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c70a4a44-558a-4268-a4c6-08b8600a2a1e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91e00518-2e49-469f-8727-0f9abdc94903",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a32f50d3-3f46-4e19-82bf-e5833fdfddcb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2184869-9ed7-43be-88d0-e6d59a98eee0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29c6b9f2-649b-4df9-8826-014313b2b2d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfb6309e-d045-475c-b0d2-4216f98b0ff1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "736e82ab-8af6-4984-a523-7f6afefa8071",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c1abb40-d11d-48a7-8603-f6bc1b6a3ce9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53b271f2-1d05-4511-94bd-dcadb6f9cdce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0db66a2f-1778-4e39-81f4-0135721962e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "158f66cd-05ed-4046-be9d-173f652089d8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0150f03a-738d-4b8a-9376-acd239f5f1ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea438671-b841-47f0-8a28-2d33cd890181",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c0e67c3-31bc-42da-a3d9-0f3910997a46",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
